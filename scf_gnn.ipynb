{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad5eaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 17:37:26.695002: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-11 17:37:26.804476: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754948246.853429 2249009 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754948246.867243 2249009 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754948246.954770 2249009 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754948246.954843 2249009 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754948246.954845 2249009 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754948246.954846 2249009 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-11 17:37:26.974850: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_enable_xla_devices=false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from spektral.data import Dataset, Graph\n",
    "from spektral.data.loaders import DisjointLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12491f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define this! The rest can remain untouched\n",
    "molecule = 'h2o'\n",
    "data_dir = Path(f'./{molecule}_energies_noise_scf_features')\n",
    "n_atoms = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ade6d1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3, 70)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "C = [] # xyz coordinates\n",
    "X = [] # calculated SCF matrix features\n",
    "Y = [] # calculated energies\n",
    "\n",
    "for file_path in data_dir.glob('*.npz'):\n",
    "    data_file = np.load(file_path)\n",
    "    try:\n",
    "        C.append(data_file['coords'])\n",
    "        X.append(data_file['features'])\n",
    "        Y.append(data_file['energy'])\n",
    "\n",
    "    except KeyError:\n",
    "        raise KeyError('wrong key for npz file!')\n",
    "# you must perform stacking, cannot just convert to array    \n",
    "N, n_atoms, n_features, channels = np.stack(X).shape\n",
    "X = np.stack(X).reshape(N, n_atoms, n_features * channels)  # (N, n_atoms, n_features * channels    )\n",
    "C = np.stack(C)\n",
    "Y = np.stack(Y)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7542001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hartree_to_kcal_per_mol(Y):\n",
    "    return Y * 627.50961\n",
    "\n",
    "Y = hartree_to_kcal_per_mol(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfbc371b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_mu: -47665.70225317801 y_sd: 0.6746812705039306\n",
      "(700, 3, 70) (700,) (700, 3, 3)\n",
      "(201, 3, 70) (201,) (201, 3, 3)\n",
      "(99, 3, 70) (99,) (99, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valtest, y_train, y_valtest, c_train, c_valtest = train_test_split(X, Y, C, test_size=0.3, random_state=42)\n",
    "x_val, x_test, y_val, y_test, c_val, c_test = train_test_split(x_valtest, y_valtest, c_valtest, test_size=0.33, random_state=42)\n",
    "\n",
    "# 1) compute from TRAIN ONLY\n",
    "y_mu = y_train.mean()\n",
    "y_sd = y_train.std() + 1e-8\n",
    "print(\"y_mu:\", y_mu, \"y_sd:\", y_sd )\n",
    "\n",
    "# 2) scale every split with the SAME mu/sd\n",
    "y_train_s = (y_train - y_mu) / y_sd\n",
    "y_val_s   = (y_val   - y_mu) / y_sd\n",
    "y_test_s  = (y_test  - y_mu) / y_sd  # if you have test\n",
    "\n",
    "\n",
    "print(x_train.shape, y_train.shape, c_train.shape)\n",
    "print(x_val.shape, y_val.shape, c_val.shape)\n",
    "print(x_test.shape, y_test.shape, c_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7ba132",
   "metadata": {},
   "source": [
    "Of course, we can define the edge features as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4363e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse \n",
    "\n",
    "def build_adjacency_from_xyz(coords, threshold=2.0):\n",
    "    \"\"\"\n",
    "    Given coords: (n_atoms, 3), returns (n_atoms, n_atoms) adjacency matrix\n",
    "    with 1s where Euclidean distance < threshold and 0 elsewhere (excluding self-loops)\n",
    "    \"\"\"\n",
    "    # n = coords.shape[0]\n",
    "    dists = np.linalg.norm(coords[:, None, :] - coords[None, :, :], axis=-1)\n",
    "    A = (dists < threshold).astype('float32')\n",
    "    np.fill_diagonal(A, 0.0)  # remove self-loops\n",
    "    # print(A)\n",
    "    return sparse.csr_matrix(A)  # return as sparse matrix for efficiency; spektral expects this forma or np array (more expensive)\n",
    "\n",
    "class SCFAtomGraphDataset(Dataset):\n",
    "    def __init__(self, X, Y, C,\n",
    "                 threshold=2.0, **kwargs):\n",
    "        \"\"\"\n",
    "        Dataset for SCF atom graphs.\n",
    "        \"\"\"\n",
    "        self.X = X.astype('float32')         # (N, n_atoms, n_features, 5)\n",
    "        self.Y = Y.astype('float32')         # (N,)\n",
    "        self.C = C.astype('float32')         # (N, n_atoms, 3)\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        graphs = []\n",
    "        for x, y, c in zip(self.X, self.Y, self.C):\n",
    "            A = build_adjacency_from_xyz(c, threshold=self.threshold)  # shape (n_atoms, n_atoms)\n",
    "            # try this\n",
    "            graphs.append(Graph(x=x, a=A, y=y))\n",
    "        return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61547725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.layers import GraphSageConv, GlobalSumPool\n",
    "'''\n",
    "tried: GCNConv (only accepts [x,a], cannot accept disjoint batches\n",
    "GCSConv (shape mismatch)\n",
    "GINConv (tf error)\n",
    "GraphSageConv + disable XLA flag + operate on CPU (forced). Both must be present for it work somehow.\n",
    "'''\n",
    "\n",
    "class GNNModel(tf.keras.Model):\n",
    "    def __init__(self, y_mean):\n",
    "        super().__init__()\n",
    "        he_init = tf.keras.initializers.HeNormal()\n",
    "\n",
    "        # ReLU and GeLU layers are best with HeNormal. Default is GlorotUniform, which isn't the most ideal; does not affect performance\n",
    "        self.conv1 = GraphSageConv(64, activation='relu', kernel_initializer=he_init, bias_initializer='zeros') \n",
    "        self.conv2 = GraphSageConv(64, activation='relu', kernel_initializer=he_init, bias_initializer='zeros')\n",
    "        self.pool = GlobalSumPool()\n",
    "        self.dense = tf.keras.layers.Dense(1, \n",
    "                                           kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05),\n",
    "                                           bias_initializer='zeros')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a, i = inputs\n",
    "        x = self.conv1([x, a])\n",
    "        x = self.conv2([x, a])\n",
    "        x = self.pool([x, i])\n",
    "        return self.dense(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26f9c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "def train_GNN(x_train, y_train, c_train,\n",
    "              x_val, y_val, c_val,\n",
    "              epochs=10, batch_size=32, threshold=2.5, verbose=0):\n",
    "    # Create dataset\n",
    "    train_dataset = SCFAtomGraphDataset(x_train, y_train, c_train, threshold=threshold)\n",
    "\n",
    "    # tried: SingleLoader (not compatible with N,3,3 data)\n",
    "    train_loader = DisjointLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    val_dataset = SCFAtomGraphDataset(x_val, y_val, c_val, threshold=threshold)\n",
    "    val_loader = DisjointLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    model = GNNModel(y_mean=y_train.mean())\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=50, min_lr=1e-6)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train\n",
    "    history = model.fit(train_loader.load(), steps_per_epoch=train_loader.steps_per_epoch,\n",
    "                        validation_data=val_loader.load(), validation_steps=val_loader.steps_per_epoch,\n",
    "                        epochs=epochs, verbose=verbose, callbacks=[lr_scheduler, early_stop])    \n",
    "    \n",
    "    return model, history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbc10a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "\u001b[1m14/22\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9756   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizhou_chen/miniconda3/envs/base-ml/lib/python3.12/site-packages/spektral/data/utils.py:221: UserWarning: you are shuffling a 'SCFAtomGraphDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.0054 - val_loss: 0.7386 - learning_rate: 0.0010\n",
      "Epoch 2/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0037 - val_loss: 0.7579 - learning_rate: 0.0010\n",
      "Epoch 3/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0021 - val_loss: 0.7526 - learning_rate: 0.0010\n",
      "Epoch 4/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0008 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 5/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0002 - val_loss: 0.7516 - learning_rate: 0.0010\n",
      "Epoch 6/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0012 - val_loss: 0.7518 - learning_rate: 0.0010\n",
      "Epoch 7/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0035 - val_loss: 0.7514 - learning_rate: 0.0010\n",
      "Epoch 8/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0002 - val_loss: 0.7590 - learning_rate: 0.0010\n",
      "Epoch 9/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0005 - val_loss: 0.7516 - learning_rate: 0.0010\n",
      "Epoch 10/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0014 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 11/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0005 - val_loss: 0.7521 - learning_rate: 0.0010\n",
      "Epoch 12/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0058 - val_loss: 0.7470 - learning_rate: 0.0010\n",
      "Epoch 13/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0018 - val_loss: 0.7586 - learning_rate: 0.0010\n",
      "Epoch 14/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0005 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 15/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0008 - val_loss: 0.7522 - learning_rate: 0.0010\n",
      "Epoch 16/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0010 - val_loss: 0.7491 - learning_rate: 0.0010\n",
      "Epoch 17/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0004 - val_loss: 0.7519 - learning_rate: 0.0010\n",
      "Epoch 18/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0019 - val_loss: 0.7549 - learning_rate: 0.0010\n",
      "Epoch 19/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0011 - val_loss: 0.7492 - learning_rate: 0.0010\n",
      "Epoch 20/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0006 - val_loss: 0.7537 - learning_rate: 0.0010\n",
      "Epoch 21/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0004 - val_loss: 0.7527 - learning_rate: 0.0010\n",
      "Epoch 22/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0002 - val_loss: 0.7509 - learning_rate: 0.0010\n",
      "Epoch 23/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0003 - val_loss: 0.7513 - learning_rate: 0.0010\n",
      "Epoch 24/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0003 - val_loss: 0.7541 - learning_rate: 0.0010\n",
      "Epoch 25/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0000 - val_loss: 0.7524 - learning_rate: 0.0010\n",
      "Epoch 26/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0001 - val_loss: 0.7518 - learning_rate: 0.0010\n",
      "Epoch 27/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0003 - val_loss: 0.7535 - learning_rate: 0.0010\n",
      "Epoch 28/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0002 - val_loss: 0.7528 - learning_rate: 0.0010\n",
      "Epoch 29/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0001 - val_loss: 0.7516 - learning_rate: 0.0010\n",
      "Epoch 30/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9999 - val_loss: 0.7501 - learning_rate: 0.0010\n",
      "Epoch 31/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0003 - val_loss: 0.7514 - learning_rate: 0.0010\n",
      "Epoch 32/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0004 - val_loss: 0.7508 - learning_rate: 0.0010\n",
      "Epoch 33/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0000 - val_loss: 0.7531 - learning_rate: 0.0010\n",
      "Epoch 34/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0012 - val_loss: 0.7529 - learning_rate: 0.0010\n",
      "Epoch 35/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0000 - val_loss: 0.7516 - learning_rate: 0.0010\n",
      "Epoch 36/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0006 - val_loss: 0.7526 - learning_rate: 0.0010\n",
      "Epoch 37/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0005 - val_loss: 0.7494 - learning_rate: 0.0010\n",
      "Epoch 38/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0005 - val_loss: 0.7501 - learning_rate: 0.0010\n",
      "Epoch 39/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0001 - val_loss: 0.7530 - learning_rate: 0.0010\n",
      "Epoch 40/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0001 - val_loss: 0.7508 - learning_rate: 0.0010\n",
      "Epoch 41/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9998 - val_loss: 0.7523 - learning_rate: 0.0010\n",
      "Epoch 42/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 - val_loss: 0.7517 - learning_rate: 0.0010\n",
      "Epoch 43/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0001 - val_loss: 0.7530 - learning_rate: 0.0010\n",
      "Epoch 44/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0002 - val_loss: 0.7543 - learning_rate: 0.0010\n",
      "Epoch 45/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0005 - val_loss: 0.7514 - learning_rate: 0.0010\n",
      "Epoch 46/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0005 - val_loss: 0.7498 - learning_rate: 0.0010\n",
      "Epoch 47/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0005 - val_loss: 0.7505 - learning_rate: 0.0010\n",
      "Epoch 48/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0007 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 49/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0008 - val_loss: 0.7517 - learning_rate: 0.0010\n",
      "Epoch 50/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0002 - val_loss: 0.7516 - learning_rate: 0.0010\n",
      "Epoch 51/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9999 - val_loss: 0.7519 - learning_rate: 0.0010\n",
      "Epoch 52/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9997 - val_loss: 0.7522 - learning_rate: 5.0000e-04\n",
      "Epoch 53/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9998 - val_loss: 0.7518 - learning_rate: 5.0000e-04\n",
      "Epoch 54/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9996 - val_loss: 0.7526 - learning_rate: 5.0000e-04\n",
      "Epoch 55/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 - val_loss: 0.7539 - learning_rate: 5.0000e-04\n",
      "Epoch 56/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9998 - val_loss: 0.7523 - learning_rate: 5.0000e-04\n",
      "Epoch 57/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 - val_loss: 0.7532 - learning_rate: 5.0000e-04\n",
      "Epoch 58/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 - val_loss: 0.7511 - learning_rate: 5.0000e-04\n",
      "Epoch 59/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9999 - val_loss: 0.7511 - learning_rate: 5.0000e-04\n",
      "Epoch 60/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9996 - val_loss: 0.7518 - learning_rate: 5.0000e-04\n",
      "Epoch 61/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9996 - val_loss: 0.7521 - learning_rate: 5.0000e-04\n",
      "Epoch 62/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0000 - val_loss: 0.7509 - learning_rate: 5.0000e-04\n",
      "Epoch 63/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0011 - val_loss: 0.7493 - learning_rate: 5.0000e-04\n",
      "Epoch 64/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9999 - val_loss: 0.7540 - learning_rate: 5.0000e-04\n",
      "Epoch 65/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0003 - val_loss: 0.7547 - learning_rate: 5.0000e-04\n",
      "Epoch 66/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9995 - val_loss: 0.7519 - learning_rate: 5.0000e-04\n",
      "Epoch 67/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9996 - val_loss: 0.7512 - learning_rate: 5.0000e-04\n",
      "Epoch 68/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9995 - val_loss: 0.7515 - learning_rate: 5.0000e-04\n",
      "Epoch 69/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9996 - val_loss: 0.7507 - learning_rate: 5.0000e-04\n",
      "Epoch 70/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9996 - val_loss: 0.7533 - learning_rate: 5.0000e-04\n",
      "Epoch 71/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0001 - val_loss: 0.7527 - learning_rate: 5.0000e-04\n",
      "Epoch 72/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9992 - val_loss: 0.7506 - learning_rate: 5.0000e-04\n",
      "Epoch 73/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9992 - val_loss: 0.7505 - learning_rate: 5.0000e-04\n",
      "Epoch 74/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0007 - val_loss: 0.7493 - learning_rate: 5.0000e-04\n",
      "Epoch 75/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9997 - val_loss: 0.7541 - learning_rate: 5.0000e-04\n",
      "Epoch 76/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9993 - val_loss: 0.7540 - learning_rate: 5.0000e-04\n",
      "Epoch 77/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9994 - val_loss: 0.7493 - learning_rate: 5.0000e-04\n",
      "Epoch 78/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9992 - val_loss: 0.7497 - learning_rate: 5.0000e-04\n",
      "Epoch 79/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9986 - val_loss: 0.7521 - learning_rate: 5.0000e-04\n",
      "Epoch 80/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9993 - val_loss: 0.7508 - learning_rate: 5.0000e-04\n",
      "Epoch 81/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0022 - val_loss: 0.7559 - learning_rate: 5.0000e-04\n",
      "Epoch 82/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9980 - val_loss: 0.7506 - learning_rate: 5.0000e-04\n",
      "Epoch 83/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9987 - val_loss: 0.7487 - learning_rate: 5.0000e-04\n",
      "Epoch 84/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9990 - val_loss: 0.7481 - learning_rate: 5.0000e-04\n",
      "Epoch 85/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9981 - val_loss: 0.7497 - learning_rate: 5.0000e-04\n",
      "Epoch 86/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9975 - val_loss: 0.7536 - learning_rate: 5.0000e-04\n",
      "Epoch 87/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9975 - val_loss: 0.7460 - learning_rate: 5.0000e-04\n",
      "Epoch 88/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9962 - val_loss: 0.7497 - learning_rate: 5.0000e-04\n",
      "Epoch 89/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9919 - val_loss: 0.7442 - learning_rate: 5.0000e-04\n",
      "Epoch 90/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9738 - val_loss: 0.7395 - learning_rate: 5.0000e-04\n",
      "Epoch 91/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9909 - val_loss: 0.7288 - learning_rate: 5.0000e-04\n",
      "Epoch 92/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9849 - val_loss: 0.7249 - learning_rate: 5.0000e-04\n",
      "Epoch 93/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9918 - val_loss: 0.7244 - learning_rate: 5.0000e-04\n",
      "Epoch 94/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9658 - val_loss: 0.7096 - learning_rate: 5.0000e-04\n",
      "Epoch 95/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9332 - val_loss: 0.6687 - learning_rate: 5.0000e-04\n",
      "Epoch 96/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8149 - val_loss: 0.5847 - learning_rate: 5.0000e-04\n",
      "Epoch 97/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6819 - val_loss: 0.4647 - learning_rate: 5.0000e-04\n",
      "Epoch 98/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7697 - val_loss: 0.6917 - learning_rate: 5.0000e-04\n",
      "Epoch 99/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6876 - val_loss: 0.6993 - learning_rate: 5.0000e-04\n",
      "Epoch 100/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6317 - val_loss: 0.5614 - learning_rate: 5.0000e-04\n",
      "Epoch 101/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4945 - val_loss: 0.5735 - learning_rate: 5.0000e-04\n",
      "Epoch 102/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4746 - val_loss: 0.4650 - learning_rate: 5.0000e-04\n",
      "Epoch 103/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4592 - val_loss: 0.3730 - learning_rate: 5.0000e-04\n",
      "Epoch 104/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5543 - val_loss: 0.6138 - learning_rate: 5.0000e-04\n",
      "Epoch 105/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4905 - val_loss: 0.3953 - learning_rate: 5.0000e-04\n",
      "Epoch 106/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4560 - val_loss: 0.4942 - learning_rate: 5.0000e-04\n",
      "Epoch 107/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5340 - val_loss: 0.3674 - learning_rate: 5.0000e-04\n",
      "Epoch 108/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4117 - val_loss: 0.3731 - learning_rate: 5.0000e-04\n",
      "Epoch 109/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4022 - val_loss: 0.3599 - learning_rate: 5.0000e-04\n",
      "Epoch 110/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4011 - val_loss: 0.3590 - learning_rate: 5.0000e-04\n",
      "Epoch 111/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4112 - val_loss: 0.4082 - learning_rate: 5.0000e-04\n",
      "Epoch 112/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4450 - val_loss: 0.3852 - learning_rate: 5.0000e-04\n",
      "Epoch 113/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4005 - val_loss: 0.3520 - learning_rate: 5.0000e-04\n",
      "Epoch 114/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3850 - val_loss: 0.3653 - learning_rate: 5.0000e-04\n",
      "Epoch 115/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4094 - val_loss: 0.4032 - learning_rate: 5.0000e-04\n",
      "Epoch 116/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3879 - val_loss: 0.3553 - learning_rate: 5.0000e-04\n",
      "Epoch 117/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3739 - val_loss: 0.3746 - learning_rate: 5.0000e-04\n",
      "Epoch 118/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3804 - val_loss: 0.3590 - learning_rate: 5.0000e-04\n",
      "Epoch 119/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4070 - val_loss: 0.3514 - learning_rate: 5.0000e-04\n",
      "Epoch 120/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3910 - val_loss: 0.3366 - learning_rate: 5.0000e-04\n",
      "Epoch 121/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5461 - val_loss: 0.5190 - learning_rate: 5.0000e-04\n",
      "Epoch 122/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4040 - val_loss: 0.4345 - learning_rate: 5.0000e-04\n",
      "Epoch 123/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4106 - val_loss: 0.3554 - learning_rate: 5.0000e-04\n",
      "Epoch 124/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5081 - val_loss: 0.5879 - learning_rate: 5.0000e-04\n",
      "Epoch 125/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4156 - val_loss: 0.3472 - learning_rate: 5.0000e-04\n",
      "Epoch 126/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3793 - val_loss: 0.3961 - learning_rate: 5.0000e-04\n",
      "Epoch 127/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3671 - val_loss: 0.3616 - learning_rate: 5.0000e-04\n",
      "Epoch 128/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3493 - val_loss: 0.3254 - learning_rate: 5.0000e-04\n",
      "Epoch 129/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3893 - val_loss: 0.3343 - learning_rate: 5.0000e-04\n",
      "Epoch 130/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3686 - val_loss: 0.5798 - learning_rate: 5.0000e-04\n",
      "Epoch 131/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4035 - val_loss: 0.3248 - learning_rate: 5.0000e-04\n",
      "Epoch 132/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3395 - val_loss: 0.3236 - learning_rate: 5.0000e-04\n",
      "Epoch 133/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3387 - val_loss: 0.3613 - learning_rate: 5.0000e-04\n",
      "Epoch 134/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4106 - val_loss: 0.3171 - learning_rate: 5.0000e-04\n",
      "Epoch 135/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4342 - val_loss: 0.3743 - learning_rate: 5.0000e-04\n",
      "Epoch 136/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3674 - val_loss: 0.3120 - learning_rate: 5.0000e-04\n",
      "Epoch 137/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3642 - val_loss: 0.3160 - learning_rate: 5.0000e-04\n",
      "Epoch 138/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3132 - val_loss: 0.3500 - learning_rate: 5.0000e-04\n",
      "Epoch 139/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3300 - val_loss: 0.3706 - learning_rate: 5.0000e-04\n",
      "Epoch 140/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3145 - val_loss: 0.3068 - learning_rate: 5.0000e-04\n",
      "Epoch 141/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3262 - val_loss: 0.3056 - learning_rate: 5.0000e-04\n",
      "Epoch 142/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3607 - val_loss: 0.3630 - learning_rate: 5.0000e-04\n",
      "Epoch 143/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5561 - val_loss: 0.4314 - learning_rate: 5.0000e-04\n",
      "Epoch 144/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3601 - val_loss: 0.2887 - learning_rate: 5.0000e-04\n",
      "Epoch 145/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3253 - val_loss: 0.4828 - learning_rate: 5.0000e-04\n",
      "Epoch 146/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3546 - val_loss: 0.3301 - learning_rate: 5.0000e-04\n",
      "Epoch 147/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3021 - val_loss: 0.2785 - learning_rate: 5.0000e-04\n",
      "Epoch 148/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2907 - val_loss: 0.2738 - learning_rate: 5.0000e-04\n",
      "Epoch 149/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2992 - val_loss: 0.2840 - learning_rate: 5.0000e-04\n",
      "Epoch 150/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3122 - val_loss: 0.2993 - learning_rate: 5.0000e-04\n",
      "Epoch 151/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2968 - val_loss: 0.2732 - learning_rate: 5.0000e-04\n",
      "Epoch 152/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3041 - val_loss: 0.3403 - learning_rate: 5.0000e-04\n",
      "Epoch 153/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3572 - val_loss: 0.2883 - learning_rate: 5.0000e-04\n",
      "Epoch 154/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2911 - val_loss: 0.2762 - learning_rate: 5.0000e-04\n",
      "Epoch 155/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2657 - val_loss: 0.2432 - learning_rate: 5.0000e-04\n",
      "Epoch 156/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2599 - val_loss: 0.2688 - learning_rate: 5.0000e-04\n",
      "Epoch 157/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2651 - val_loss: 0.2374 - learning_rate: 5.0000e-04\n",
      "Epoch 158/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2367 - val_loss: 0.2917 - learning_rate: 5.0000e-04\n",
      "Epoch 159/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2595 - val_loss: 0.2235 - learning_rate: 5.0000e-04\n",
      "Epoch 160/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2519 - val_loss: 0.2572 - learning_rate: 5.0000e-04\n",
      "Epoch 161/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2590 - val_loss: 0.2675 - learning_rate: 5.0000e-04\n",
      "Epoch 162/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2540 - val_loss: 0.3039 - learning_rate: 5.0000e-04\n",
      "Epoch 163/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2618 - val_loss: 0.2257 - learning_rate: 5.0000e-04\n",
      "Epoch 164/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2599 - val_loss: 0.2289 - learning_rate: 5.0000e-04\n",
      "Epoch 165/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2248 - val_loss: 0.2347 - learning_rate: 5.0000e-04\n",
      "Epoch 166/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2112 - val_loss: 0.2345 - learning_rate: 5.0000e-04\n",
      "Epoch 167/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1965 - val_loss: 0.1910 - learning_rate: 5.0000e-04\n",
      "Epoch 168/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2104 - val_loss: 0.2193 - learning_rate: 5.0000e-04\n",
      "Epoch 169/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1950 - val_loss: 0.2041 - learning_rate: 5.0000e-04\n",
      "Epoch 170/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1998 - val_loss: 0.1651 - learning_rate: 5.0000e-04\n",
      "Epoch 171/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1818 - val_loss: 0.1639 - learning_rate: 5.0000e-04\n",
      "Epoch 172/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1777 - val_loss: 0.1933 - learning_rate: 5.0000e-04\n",
      "Epoch 173/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2025 - val_loss: 0.2651 - learning_rate: 5.0000e-04\n",
      "Epoch 174/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2093 - val_loss: 0.1811 - learning_rate: 5.0000e-04\n",
      "Epoch 175/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1619 - val_loss: 0.2024 - learning_rate: 5.0000e-04\n",
      "Epoch 176/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1709 - val_loss: 0.3072 - learning_rate: 5.0000e-04\n",
      "Epoch 177/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2069 - val_loss: 0.1736 - learning_rate: 5.0000e-04\n",
      "Epoch 178/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1637 - val_loss: 0.1347 - learning_rate: 5.0000e-04\n",
      "Epoch 179/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1429 - val_loss: 0.1253 - learning_rate: 5.0000e-04\n",
      "Epoch 180/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1490 - val_loss: 0.2489 - learning_rate: 5.0000e-04\n",
      "Epoch 181/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1880 - val_loss: 0.1651 - learning_rate: 5.0000e-04\n",
      "Epoch 182/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1489 - val_loss: 0.1221 - learning_rate: 5.0000e-04\n",
      "Epoch 183/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1648 - val_loss: 0.2226 - learning_rate: 5.0000e-04\n",
      "Epoch 184/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2948 - val_loss: 0.1581 - learning_rate: 5.0000e-04\n",
      "Epoch 185/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1867 - val_loss: 0.1512 - learning_rate: 5.0000e-04\n",
      "Epoch 186/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1581 - val_loss: 0.1291 - learning_rate: 5.0000e-04\n",
      "Epoch 187/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1382 - val_loss: 0.1334 - learning_rate: 5.0000e-04\n",
      "Epoch 188/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2091 - val_loss: 0.2584 - learning_rate: 5.0000e-04\n",
      "Epoch 189/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1865 - val_loss: 0.1637 - learning_rate: 5.0000e-04\n",
      "Epoch 190/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1313 - val_loss: 0.1111 - learning_rate: 5.0000e-04\n",
      "Epoch 191/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1128 - val_loss: 0.1427 - learning_rate: 5.0000e-04\n",
      "Epoch 192/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1275 - val_loss: 0.1051 - learning_rate: 5.0000e-04\n",
      "Epoch 193/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1285 - val_loss: 0.1320 - learning_rate: 5.0000e-04\n",
      "Epoch 194/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1327 - val_loss: 0.1013 - learning_rate: 5.0000e-04\n",
      "Epoch 195/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1137 - val_loss: 0.0924 - learning_rate: 5.0000e-04\n",
      "Epoch 196/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1061 - val_loss: 0.1007 - learning_rate: 5.0000e-04\n",
      "Epoch 197/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1252 - val_loss: 0.1283 - learning_rate: 5.0000e-04\n",
      "Epoch 198/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1201 - val_loss: 0.0937 - learning_rate: 5.0000e-04\n",
      "Epoch 199/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0947 - val_loss: 0.0825 - learning_rate: 5.0000e-04\n",
      "Epoch 200/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0994 - val_loss: 0.0830 - learning_rate: 5.0000e-04\n",
      "Epoch 201/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1504 - val_loss: 0.2403 - learning_rate: 5.0000e-04\n",
      "Epoch 202/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1362 - val_loss: 0.0791 - learning_rate: 5.0000e-04\n",
      "Epoch 203/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1092 - val_loss: 0.1908 - learning_rate: 5.0000e-04\n",
      "Epoch 204/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1248 - val_loss: 0.1625 - learning_rate: 5.0000e-04\n",
      "Epoch 205/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0909 - val_loss: 0.0787 - learning_rate: 5.0000e-04\n",
      "Epoch 206/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0974 - val_loss: 0.1099 - learning_rate: 5.0000e-04\n",
      "Epoch 207/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0833 - val_loss: 0.0657 - learning_rate: 5.0000e-04\n",
      "Epoch 208/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0797 - val_loss: 0.0652 - learning_rate: 5.0000e-04\n",
      "Epoch 209/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0957 - val_loss: 0.0673 - learning_rate: 5.0000e-04\n",
      "Epoch 210/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0791 - val_loss: 0.1055 - learning_rate: 5.0000e-04\n",
      "Epoch 211/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1089 - val_loss: 0.0934 - learning_rate: 5.0000e-04\n",
      "Epoch 212/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1317 - val_loss: 0.0657 - learning_rate: 5.0000e-04\n",
      "Epoch 213/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0806 - val_loss: 0.0770 - learning_rate: 5.0000e-04\n",
      "Epoch 214/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0677 - val_loss: 0.0674 - learning_rate: 5.0000e-04\n",
      "Epoch 215/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0757 - val_loss: 0.0558 - learning_rate: 5.0000e-04\n",
      "Epoch 216/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0617 - val_loss: 0.1022 - learning_rate: 5.0000e-04\n",
      "Epoch 217/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0583 - val_loss: 0.0575 - learning_rate: 5.0000e-04\n",
      "Epoch 218/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0686 - val_loss: 0.1138 - learning_rate: 5.0000e-04\n",
      "Epoch 219/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1256 - val_loss: 0.1399 - learning_rate: 5.0000e-04\n",
      "Epoch 220/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1125 - val_loss: 0.0686 - learning_rate: 5.0000e-04\n",
      "Epoch 221/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0718 - val_loss: 0.0590 - learning_rate: 5.0000e-04\n",
      "Epoch 222/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0587 - val_loss: 0.0583 - learning_rate: 5.0000e-04\n",
      "Epoch 223/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0619 - val_loss: 0.1144 - learning_rate: 5.0000e-04\n",
      "Epoch 224/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0885 - val_loss: 0.1199 - learning_rate: 5.0000e-04\n",
      "Epoch 225/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0730 - val_loss: 0.0506 - learning_rate: 5.0000e-04\n",
      "Epoch 226/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0543 - val_loss: 0.0615 - learning_rate: 5.0000e-04\n",
      "Epoch 227/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0631 - val_loss: 0.0533 - learning_rate: 5.0000e-04\n",
      "Epoch 228/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1033 - val_loss: 0.0685 - learning_rate: 5.0000e-04\n",
      "Epoch 229/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0782 - val_loss: 0.0632 - learning_rate: 5.0000e-04\n",
      "Epoch 230/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0610 - val_loss: 0.0704 - learning_rate: 5.0000e-04\n",
      "Epoch 231/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1525 - val_loss: 0.1401 - learning_rate: 5.0000e-04\n",
      "Epoch 232/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2092 - val_loss: 0.0567 - learning_rate: 5.0000e-04\n",
      "Epoch 233/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0961 - val_loss: 0.1254 - learning_rate: 5.0000e-04\n",
      "Epoch 234/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0925 - val_loss: 0.0512 - learning_rate: 5.0000e-04\n",
      "Epoch 235/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0591 - val_loss: 0.0549 - learning_rate: 5.0000e-04\n",
      "Epoch 236/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0691 - val_loss: 0.0514 - learning_rate: 5.0000e-04\n",
      "Epoch 237/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0604 - val_loss: 0.0528 - learning_rate: 5.0000e-04\n",
      "Epoch 238/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0560 - val_loss: 0.0495 - learning_rate: 5.0000e-04\n",
      "Epoch 239/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0506 - val_loss: 0.0545 - learning_rate: 5.0000e-04\n",
      "Epoch 240/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0505 - val_loss: 0.0444 - learning_rate: 5.0000e-04\n",
      "Epoch 241/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0457 - val_loss: 0.0565 - learning_rate: 5.0000e-04\n",
      "Epoch 242/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0510 - val_loss: 0.0522 - learning_rate: 5.0000e-04\n",
      "Epoch 243/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0448 - val_loss: 0.0449 - learning_rate: 5.0000e-04\n",
      "Epoch 244/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0648 - val_loss: 0.0624 - learning_rate: 5.0000e-04\n",
      "Epoch 245/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1446 - val_loss: 0.1464 - learning_rate: 5.0000e-04\n",
      "Epoch 246/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1052 - val_loss: 0.0562 - learning_rate: 5.0000e-04\n",
      "Epoch 247/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0543 - val_loss: 0.0438 - learning_rate: 5.0000e-04\n",
      "Epoch 248/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0396 - val_loss: 0.0480 - learning_rate: 5.0000e-04\n",
      "Epoch 249/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0499 - val_loss: 0.0370 - learning_rate: 5.0000e-04\n",
      "Epoch 250/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0407 - val_loss: 0.0443 - learning_rate: 5.0000e-04\n",
      "Epoch 251/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0407 - val_loss: 0.0482 - learning_rate: 5.0000e-04\n",
      "Epoch 252/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0430 - val_loss: 0.0593 - learning_rate: 5.0000e-04\n",
      "Epoch 253/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0599 - val_loss: 0.0380 - learning_rate: 5.0000e-04\n",
      "Epoch 254/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0460 - val_loss: 0.0413 - learning_rate: 5.0000e-04\n",
      "Epoch 255/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0450 - val_loss: 0.0938 - learning_rate: 5.0000e-04\n",
      "Epoch 256/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0552 - val_loss: 0.0379 - learning_rate: 5.0000e-04\n",
      "Epoch 257/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0378 - val_loss: 0.0535 - learning_rate: 5.0000e-04\n",
      "Epoch 258/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0625 - val_loss: 0.0510 - learning_rate: 5.0000e-04\n",
      "Epoch 259/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0373 - val_loss: 0.0456 - learning_rate: 5.0000e-04\n",
      "Epoch 260/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0421 - val_loss: 0.0435 - learning_rate: 5.0000e-04\n",
      "Epoch 261/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0369 - val_loss: 0.0571 - learning_rate: 5.0000e-04\n",
      "Epoch 262/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0454 - val_loss: 0.0386 - learning_rate: 5.0000e-04\n",
      "Epoch 263/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0386 - val_loss: 0.0334 - learning_rate: 5.0000e-04\n",
      "Epoch 264/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0430 - val_loss: 0.0453 - learning_rate: 5.0000e-04\n",
      "Epoch 265/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0603 - val_loss: 0.0688 - learning_rate: 5.0000e-04\n",
      "Epoch 266/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0630 - val_loss: 0.0482 - learning_rate: 5.0000e-04\n",
      "Epoch 267/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0621 - val_loss: 0.1284 - learning_rate: 5.0000e-04\n",
      "Epoch 268/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0584 - val_loss: 0.0655 - learning_rate: 5.0000e-04\n",
      "Epoch 269/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0574 - val_loss: 0.0354 - learning_rate: 5.0000e-04\n",
      "Epoch 270/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0472 - val_loss: 0.0732 - learning_rate: 5.0000e-04\n",
      "Epoch 271/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0416 - val_loss: 0.0497 - learning_rate: 5.0000e-04\n",
      "Epoch 272/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0431 - val_loss: 0.0480 - learning_rate: 5.0000e-04\n",
      "Epoch 273/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0496 - val_loss: 0.0396 - learning_rate: 5.0000e-04\n",
      "Epoch 274/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0335 - val_loss: 0.0403 - learning_rate: 5.0000e-04\n",
      "Epoch 275/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0442 - val_loss: 0.0468 - learning_rate: 5.0000e-04\n",
      "Epoch 276/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0515 - val_loss: 0.0398 - learning_rate: 5.0000e-04\n",
      "Epoch 277/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0772 - val_loss: 0.0420 - learning_rate: 5.0000e-04\n",
      "Epoch 278/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0537 - val_loss: 0.0354 - learning_rate: 5.0000e-04\n",
      "Epoch 279/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0508 - val_loss: 0.0826 - learning_rate: 5.0000e-04\n",
      "Epoch 280/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0387 - val_loss: 0.0354 - learning_rate: 5.0000e-04\n",
      "Epoch 281/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0397 - val_loss: 0.0353 - learning_rate: 5.0000e-04\n",
      "Epoch 282/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0429 - val_loss: 0.0317 - learning_rate: 5.0000e-04\n",
      "Epoch 283/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0353 - val_loss: 0.0287 - learning_rate: 5.0000e-04\n",
      "Epoch 284/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0289 - val_loss: 0.0509 - learning_rate: 5.0000e-04\n",
      "Epoch 285/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0520 - val_loss: 0.0583 - learning_rate: 5.0000e-04\n",
      "Epoch 286/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0400 - val_loss: 0.0364 - learning_rate: 5.0000e-04\n",
      "Epoch 287/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0316 - val_loss: 0.0302 - learning_rate: 5.0000e-04\n",
      "Epoch 288/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0298 - val_loss: 0.0281 - learning_rate: 5.0000e-04\n",
      "Epoch 289/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0385 - val_loss: 0.0266 - learning_rate: 5.0000e-04\n",
      "Epoch 290/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0365 - val_loss: 0.0288 - learning_rate: 5.0000e-04\n",
      "Epoch 291/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0382 - val_loss: 0.0348 - learning_rate: 5.0000e-04\n",
      "Epoch 292/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0323 - val_loss: 0.0496 - learning_rate: 5.0000e-04\n",
      "Epoch 293/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0340 - val_loss: 0.0290 - learning_rate: 5.0000e-04\n",
      "Epoch 294/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0604 - val_loss: 0.0739 - learning_rate: 5.0000e-04\n",
      "Epoch 295/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0485 - val_loss: 0.0385 - learning_rate: 5.0000e-04\n",
      "Epoch 296/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0342 - val_loss: 0.1310 - learning_rate: 5.0000e-04\n",
      "Epoch 297/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0603 - val_loss: 0.1071 - learning_rate: 5.0000e-04\n",
      "Epoch 298/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0566 - val_loss: 0.0401 - learning_rate: 5.0000e-04\n",
      "Epoch 299/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0493 - val_loss: 0.0350 - learning_rate: 5.0000e-04\n",
      "Epoch 300/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0368 - val_loss: 0.1132 - learning_rate: 5.0000e-04\n",
      "Epoch 301/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0587 - val_loss: 0.0410 - learning_rate: 5.0000e-04\n",
      "Epoch 302/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0441 - val_loss: 0.0357 - learning_rate: 5.0000e-04\n",
      "Epoch 303/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0350 - learning_rate: 5.0000e-04\n",
      "Epoch 304/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0371 - val_loss: 0.0376 - learning_rate: 5.0000e-04\n",
      "Epoch 305/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0408 - val_loss: 0.1001 - learning_rate: 5.0000e-04\n",
      "Epoch 306/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0496 - val_loss: 0.0542 - learning_rate: 5.0000e-04\n",
      "Epoch 307/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0559 - val_loss: 0.1315 - learning_rate: 5.0000e-04\n",
      "Epoch 308/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0794 - val_loss: 0.1738 - learning_rate: 5.0000e-04\n",
      "Epoch 309/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0690 - val_loss: 0.0316 - learning_rate: 5.0000e-04\n",
      "Epoch 310/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0331 - val_loss: 0.0292 - learning_rate: 5.0000e-04\n",
      "Epoch 311/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0345 - val_loss: 0.0339 - learning_rate: 5.0000e-04\n",
      "Epoch 312/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0322 - val_loss: 0.0265 - learning_rate: 5.0000e-04\n",
      "Epoch 313/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0360 - val_loss: 0.0414 - learning_rate: 5.0000e-04\n",
      "Epoch 314/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0268 - val_loss: 0.0265 - learning_rate: 5.0000e-04\n",
      "Epoch 315/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0422 - val_loss: 0.0263 - learning_rate: 5.0000e-04\n",
      "Epoch 316/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0318 - val_loss: 0.0275 - learning_rate: 5.0000e-04\n",
      "Epoch 317/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0276 - val_loss: 0.0330 - learning_rate: 5.0000e-04\n",
      "Epoch 318/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0293 - val_loss: 0.0290 - learning_rate: 5.0000e-04\n",
      "Epoch 319/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0307 - val_loss: 0.0255 - learning_rate: 5.0000e-04\n",
      "Epoch 320/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0531 - val_loss: 0.0480 - learning_rate: 5.0000e-04\n",
      "Epoch 321/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0455 - val_loss: 0.1146 - learning_rate: 5.0000e-04\n",
      "Epoch 322/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1108 - val_loss: 0.0451 - learning_rate: 5.0000e-04\n",
      "Epoch 323/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1039 - val_loss: 0.1138 - learning_rate: 5.0000e-04\n",
      "Epoch 324/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0890 - val_loss: 0.0278 - learning_rate: 5.0000e-04\n",
      "Epoch 325/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0494 - val_loss: 0.0901 - learning_rate: 5.0000e-04\n",
      "Epoch 326/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0574 - val_loss: 0.0248 - learning_rate: 5.0000e-04\n",
      "Epoch 327/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0359 - val_loss: 0.0323 - learning_rate: 5.0000e-04\n",
      "Epoch 328/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0332 - val_loss: 0.0365 - learning_rate: 5.0000e-04\n",
      "Epoch 329/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0450 - val_loss: 0.0407 - learning_rate: 5.0000e-04\n",
      "Epoch 330/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0359 - val_loss: 0.0361 - learning_rate: 5.0000e-04\n",
      "Epoch 331/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0299 - val_loss: 0.0240 - learning_rate: 5.0000e-04\n",
      "Epoch 332/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0281 - val_loss: 0.0312 - learning_rate: 5.0000e-04\n",
      "Epoch 333/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0330 - val_loss: 0.0799 - learning_rate: 5.0000e-04\n",
      "Epoch 334/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0361 - val_loss: 0.0504 - learning_rate: 5.0000e-04\n",
      "Epoch 335/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0315 - val_loss: 0.0296 - learning_rate: 5.0000e-04\n",
      "Epoch 336/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0326 - val_loss: 0.0353 - learning_rate: 5.0000e-04\n",
      "Epoch 337/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0311 - val_loss: 0.0539 - learning_rate: 5.0000e-04\n",
      "Epoch 338/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0519 - val_loss: 0.0778 - learning_rate: 5.0000e-04\n",
      "Epoch 339/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0534 - val_loss: 0.0665 - learning_rate: 5.0000e-04\n",
      "Epoch 340/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0415 - val_loss: 0.0266 - learning_rate: 5.0000e-04\n",
      "Epoch 341/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0279 - val_loss: 0.0349 - learning_rate: 5.0000e-04\n",
      "Epoch 342/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0252 - val_loss: 0.0572 - learning_rate: 5.0000e-04\n",
      "Epoch 343/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0384 - val_loss: 0.0234 - learning_rate: 5.0000e-04\n",
      "Epoch 344/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0376 - val_loss: 0.0605 - learning_rate: 5.0000e-04\n",
      "Epoch 345/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0413 - val_loss: 0.0725 - learning_rate: 5.0000e-04\n",
      "Epoch 346/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0386 - val_loss: 0.0347 - learning_rate: 5.0000e-04\n",
      "Epoch 347/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0354 - val_loss: 0.0346 - learning_rate: 5.0000e-04\n",
      "Epoch 348/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0321 - val_loss: 0.0374 - learning_rate: 5.0000e-04\n",
      "Epoch 349/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0393 - val_loss: 0.0224 - learning_rate: 5.0000e-04\n",
      "Epoch 350/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0480 - val_loss: 0.0631 - learning_rate: 5.0000e-04\n",
      "Epoch 351/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0574 - val_loss: 0.0344 - learning_rate: 5.0000e-04\n",
      "Epoch 352/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0585 - val_loss: 0.0324 - learning_rate: 5.0000e-04\n",
      "Epoch 353/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0513 - val_loss: 0.0290 - learning_rate: 5.0000e-04\n",
      "Epoch 354/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0222 - val_loss: 0.0290 - learning_rate: 5.0000e-04\n",
      "Epoch 355/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0201 - val_loss: 0.0271 - learning_rate: 5.0000e-04\n",
      "Epoch 356/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0282 - val_loss: 0.0269 - learning_rate: 5.0000e-04\n",
      "Epoch 357/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0305 - val_loss: 0.0240 - learning_rate: 5.0000e-04\n",
      "Epoch 358/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0323 - val_loss: 0.0285 - learning_rate: 5.0000e-04\n",
      "Epoch 359/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0237 - val_loss: 0.0218 - learning_rate: 5.0000e-04\n",
      "Epoch 360/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0319 - val_loss: 0.0577 - learning_rate: 5.0000e-04\n",
      "Epoch 361/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0726 - val_loss: 0.0431 - learning_rate: 5.0000e-04\n",
      "Epoch 362/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0332 - learning_rate: 5.0000e-04\n",
      "Epoch 363/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0328 - val_loss: 0.0235 - learning_rate: 5.0000e-04\n",
      "Epoch 364/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0538 - val_loss: 0.0295 - learning_rate: 5.0000e-04\n",
      "Epoch 365/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0348 - val_loss: 0.0288 - learning_rate: 5.0000e-04\n",
      "Epoch 366/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0290 - val_loss: 0.0254 - learning_rate: 5.0000e-04\n",
      "Epoch 367/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0292 - val_loss: 0.0390 - learning_rate: 5.0000e-04\n",
      "Epoch 368/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0249 - val_loss: 0.0184 - learning_rate: 5.0000e-04\n",
      "Epoch 369/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0252 - val_loss: 0.0214 - learning_rate: 5.0000e-04\n",
      "Epoch 370/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0303 - val_loss: 0.0345 - learning_rate: 5.0000e-04\n",
      "Epoch 371/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0336 - val_loss: 0.0304 - learning_rate: 5.0000e-04\n",
      "Epoch 372/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0240 - val_loss: 0.0284 - learning_rate: 5.0000e-04\n",
      "Epoch 373/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0344 - val_loss: 0.0267 - learning_rate: 5.0000e-04\n",
      "Epoch 374/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0286 - val_loss: 0.0273 - learning_rate: 5.0000e-04\n",
      "Epoch 375/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0379 - val_loss: 0.0786 - learning_rate: 5.0000e-04\n",
      "Epoch 376/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0536 - val_loss: 0.0315 - learning_rate: 5.0000e-04\n",
      "Epoch 377/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0298 - val_loss: 0.0674 - learning_rate: 5.0000e-04\n",
      "Epoch 378/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0343 - val_loss: 0.0228 - learning_rate: 5.0000e-04\n",
      "Epoch 379/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0290 - val_loss: 0.0222 - learning_rate: 5.0000e-04\n",
      "Epoch 380/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0300 - val_loss: 0.0487 - learning_rate: 5.0000e-04\n",
      "Epoch 381/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0349 - val_loss: 0.0281 - learning_rate: 5.0000e-04\n",
      "Epoch 382/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0260 - val_loss: 0.0208 - learning_rate: 5.0000e-04\n",
      "Epoch 383/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0234 - val_loss: 0.0267 - learning_rate: 5.0000e-04\n",
      "Epoch 384/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0280 - val_loss: 0.0230 - learning_rate: 5.0000e-04\n",
      "Epoch 385/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0202 - val_loss: 0.0249 - learning_rate: 5.0000e-04\n",
      "Epoch 386/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0207 - val_loss: 0.0230 - learning_rate: 5.0000e-04\n",
      "Epoch 387/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0198 - val_loss: 0.0302 - learning_rate: 5.0000e-04\n",
      "Epoch 388/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0276 - val_loss: 0.0348 - learning_rate: 5.0000e-04\n",
      "Epoch 389/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0215 - learning_rate: 5.0000e-04\n",
      "Epoch 390/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0183 - val_loss: 0.0183 - learning_rate: 5.0000e-04\n",
      "Epoch 391/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0332 - val_loss: 0.0266 - learning_rate: 5.0000e-04\n",
      "Epoch 392/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0338 - val_loss: 0.0206 - learning_rate: 5.0000e-04\n",
      "Epoch 393/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0415 - val_loss: 0.0354 - learning_rate: 5.0000e-04\n",
      "Epoch 394/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0342 - val_loss: 0.0260 - learning_rate: 5.0000e-04\n",
      "Epoch 395/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0227 - val_loss: 0.0189 - learning_rate: 5.0000e-04\n",
      "Epoch 396/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0191 - val_loss: 0.0194 - learning_rate: 5.0000e-04\n",
      "Epoch 397/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0214 - val_loss: 0.0225 - learning_rate: 5.0000e-04\n",
      "Epoch 398/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0228 - val_loss: 0.0170 - learning_rate: 5.0000e-04\n",
      "Epoch 399/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0209 - val_loss: 0.0249 - learning_rate: 5.0000e-04\n",
      "Epoch 400/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0241 - val_loss: 0.0232 - learning_rate: 5.0000e-04\n",
      "Epoch 401/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0204 - val_loss: 0.0289 - learning_rate: 5.0000e-04\n",
      "Epoch 402/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0257 - val_loss: 0.0180 - learning_rate: 5.0000e-04\n",
      "Epoch 403/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0299 - val_loss: 0.0265 - learning_rate: 5.0000e-04\n",
      "Epoch 404/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0206 - val_loss: 0.0227 - learning_rate: 5.0000e-04\n",
      "Epoch 405/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0254 - val_loss: 0.0285 - learning_rate: 5.0000e-04\n",
      "Epoch 406/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0510 - val_loss: 0.0229 - learning_rate: 5.0000e-04\n",
      "Epoch 407/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1207 - val_loss: 0.3503 - learning_rate: 5.0000e-04\n",
      "Epoch 408/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2012 - val_loss: 0.2042 - learning_rate: 5.0000e-04\n",
      "Epoch 409/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1415 - val_loss: 0.0976 - learning_rate: 5.0000e-04\n",
      "Epoch 410/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0712 - val_loss: 0.1668 - learning_rate: 5.0000e-04\n",
      "Epoch 411/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0681 - val_loss: 0.0487 - learning_rate: 5.0000e-04\n",
      "Epoch 412/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0469 - val_loss: 0.0651 - learning_rate: 5.0000e-04\n",
      "Epoch 413/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0396 - val_loss: 0.0360 - learning_rate: 5.0000e-04\n",
      "Epoch 414/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0320 - val_loss: 0.0530 - learning_rate: 5.0000e-04\n",
      "Epoch 415/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0551 - val_loss: 0.0265 - learning_rate: 5.0000e-04\n",
      "Epoch 416/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0415 - val_loss: 0.0423 - learning_rate: 5.0000e-04\n",
      "Epoch 417/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0458 - val_loss: 0.0364 - learning_rate: 5.0000e-04\n",
      "Epoch 418/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0338 - val_loss: 0.0256 - learning_rate: 5.0000e-04\n",
      "Epoch 419/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0304 - val_loss: 0.0271 - learning_rate: 5.0000e-04\n",
      "Epoch 420/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0280 - val_loss: 0.0265 - learning_rate: 5.0000e-04\n",
      "Epoch 421/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0212 - val_loss: 0.0486 - learning_rate: 5.0000e-04\n",
      "Epoch 422/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0287 - val_loss: 0.0200 - learning_rate: 5.0000e-04\n",
      "Epoch 423/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0306 - val_loss: 0.0206 - learning_rate: 5.0000e-04\n",
      "Epoch 424/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0335 - val_loss: 0.0330 - learning_rate: 5.0000e-04\n",
      "Epoch 425/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0434 - val_loss: 0.0508 - learning_rate: 5.0000e-04\n",
      "Epoch 426/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0559 - val_loss: 0.0318 - learning_rate: 5.0000e-04\n",
      "Epoch 427/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0262 - val_loss: 0.0214 - learning_rate: 5.0000e-04\n",
      "Epoch 428/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0262 - val_loss: 0.0232 - learning_rate: 5.0000e-04\n",
      "Epoch 429/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0285 - val_loss: 0.0315 - learning_rate: 5.0000e-04\n",
      "Epoch 430/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0268 - learning_rate: 5.0000e-04\n",
      "Epoch 431/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0276 - val_loss: 0.0597 - learning_rate: 5.0000e-04\n",
      "Epoch 432/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0317 - val_loss: 0.0225 - learning_rate: 5.0000e-04\n",
      "Epoch 433/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0410 - val_loss: 0.0496 - learning_rate: 5.0000e-04\n",
      "Epoch 434/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0511 - val_loss: 0.1018 - learning_rate: 5.0000e-04\n",
      "Epoch 435/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0595 - val_loss: 0.0552 - learning_rate: 5.0000e-04\n",
      "Epoch 436/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0339 - val_loss: 0.0286 - learning_rate: 5.0000e-04\n",
      "Epoch 437/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0302 - val_loss: 0.0197 - learning_rate: 5.0000e-04\n",
      "Epoch 438/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0271 - val_loss: 0.0320 - learning_rate: 5.0000e-04\n",
      "Epoch 439/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0228 - val_loss: 0.0310 - learning_rate: 5.0000e-04\n",
      "Epoch 440/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0241 - val_loss: 0.0199 - learning_rate: 5.0000e-04\n",
      "Epoch 441/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0195 - val_loss: 0.0201 - learning_rate: 5.0000e-04\n",
      "Epoch 442/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0408 - val_loss: 0.0271 - learning_rate: 5.0000e-04\n",
      "Epoch 443/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0356 - val_loss: 0.0262 - learning_rate: 5.0000e-04\n",
      "Epoch 444/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0342 - val_loss: 0.0517 - learning_rate: 5.0000e-04\n",
      "Epoch 445/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0341 - val_loss: 0.0221 - learning_rate: 5.0000e-04\n",
      "Epoch 446/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0295 - val_loss: 0.0237 - learning_rate: 5.0000e-04\n",
      "Epoch 447/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0334 - val_loss: 0.0226 - learning_rate: 5.0000e-04\n",
      "Epoch 448/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0298 - val_loss: 0.0265 - learning_rate: 5.0000e-04\n",
      "Epoch 449/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0207 - val_loss: 0.0196 - learning_rate: 2.5000e-04\n",
      "Epoch 450/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0194 - val_loss: 0.0171 - learning_rate: 2.5000e-04\n",
      "Epoch 451/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0178 - val_loss: 0.0186 - learning_rate: 2.5000e-04\n",
      "Epoch 452/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0194 - val_loss: 0.0179 - learning_rate: 2.5000e-04\n",
      "Epoch 453/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0171 - val_loss: 0.0166 - learning_rate: 2.5000e-04\n",
      "Epoch 454/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0164 - val_loss: 0.0203 - learning_rate: 2.5000e-04\n",
      "Epoch 455/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0150 - val_loss: 0.0170 - learning_rate: 2.5000e-04\n",
      "Epoch 456/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0168 - val_loss: 0.0171 - learning_rate: 2.5000e-04\n",
      "Epoch 457/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0171 - val_loss: 0.0236 - learning_rate: 2.5000e-04\n",
      "Epoch 458/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0217 - val_loss: 0.0172 - learning_rate: 2.5000e-04\n",
      "Epoch 459/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0164 - val_loss: 0.0221 - learning_rate: 2.5000e-04\n",
      "Epoch 460/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0174 - val_loss: 0.0167 - learning_rate: 2.5000e-04\n",
      "Epoch 461/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0159 - val_loss: 0.0184 - learning_rate: 2.5000e-04\n",
      "Epoch 462/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0205 - val_loss: 0.0324 - learning_rate: 2.5000e-04\n",
      "Epoch 463/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0205 - val_loss: 0.0215 - learning_rate: 2.5000e-04\n",
      "Epoch 464/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0189 - val_loss: 0.0159 - learning_rate: 2.5000e-04\n",
      "Epoch 465/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0167 - val_loss: 0.0175 - learning_rate: 2.5000e-04\n",
      "Epoch 466/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0180 - val_loss: 0.0264 - learning_rate: 2.5000e-04\n",
      "Epoch 467/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0269 - val_loss: 0.0170 - learning_rate: 2.5000e-04\n",
      "Epoch 468/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-0s\u001b[0m -14142us/step - loss: 0.0288 - val_loss: 0.0232 - learning_rate: 2.5000e-04\n",
      "Epoch 469/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - val_loss: 0.0163 - learning_rate: 2.5000e-04\n",
      "Epoch 470/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0177 - val_loss: 0.0163 - learning_rate: 2.5000e-04\n",
      "Epoch 471/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0185 - val_loss: 0.0180 - learning_rate: 2.5000e-04\n",
      "Epoch 472/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0202 - val_loss: 0.0204 - learning_rate: 2.5000e-04\n",
      "Epoch 473/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0172 - val_loss: 0.0200 - learning_rate: 2.5000e-04\n",
      "Epoch 474/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0153 - val_loss: 0.0192 - learning_rate: 2.5000e-04\n",
      "Epoch 475/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0204 - val_loss: 0.0155 - learning_rate: 2.5000e-04\n",
      "Epoch 476/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0183 - val_loss: 0.0234 - learning_rate: 2.5000e-04\n",
      "Epoch 477/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0200 - val_loss: 0.0195 - learning_rate: 2.5000e-04\n",
      "Epoch 478/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0277 - val_loss: 0.0314 - learning_rate: 2.5000e-04\n",
      "Epoch 479/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0176 - val_loss: 0.0155 - learning_rate: 2.5000e-04\n",
      "Epoch 480/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0184 - val_loss: 0.0165 - learning_rate: 2.5000e-04\n",
      "Epoch 481/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0178 - val_loss: 0.0250 - learning_rate: 2.5000e-04\n",
      "Epoch 482/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0178 - val_loss: 0.0194 - learning_rate: 2.5000e-04\n",
      "Epoch 483/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0182 - val_loss: 0.0188 - learning_rate: 2.5000e-04\n",
      "Epoch 484/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0161 - val_loss: 0.0154 - learning_rate: 2.5000e-04\n",
      "Epoch 485/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0143 - val_loss: 0.0162 - learning_rate: 2.5000e-04\n",
      "Epoch 486/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0173 - val_loss: 0.0156 - learning_rate: 2.5000e-04\n",
      "Epoch 487/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0144 - val_loss: 0.0180 - learning_rate: 2.5000e-04\n",
      "Epoch 488/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0148 - val_loss: 0.0144 - learning_rate: 2.5000e-04\n",
      "Epoch 489/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - val_loss: 0.0242 - learning_rate: 2.5000e-04\n",
      "Epoch 490/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0249 - val_loss: 0.0616 - learning_rate: 2.5000e-04\n",
      "Epoch 491/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0245 - val_loss: 0.0157 - learning_rate: 2.5000e-04\n",
      "Epoch 492/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0148 - val_loss: 0.0163 - learning_rate: 2.5000e-04\n",
      "Epoch 493/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0153 - val_loss: 0.0161 - learning_rate: 2.5000e-04\n",
      "Epoch 494/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0171 - val_loss: 0.0180 - learning_rate: 2.5000e-04\n",
      "Epoch 495/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0195 - val_loss: 0.0201 - learning_rate: 2.5000e-04\n",
      "Epoch 496/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0162 - val_loss: 0.0155 - learning_rate: 2.5000e-04\n",
      "Epoch 497/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0142 - val_loss: 0.0171 - learning_rate: 2.5000e-04\n",
      "Epoch 498/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0137 - val_loss: 0.0156 - learning_rate: 2.5000e-04\n",
      "Epoch 499/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0156 - val_loss: 0.0169 - learning_rate: 2.5000e-04\n",
      "Epoch 500/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0160 - val_loss: 0.0169 - learning_rate: 2.5000e-04\n",
      "Epoch 501/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0177 - val_loss: 0.0171 - learning_rate: 2.5000e-04\n",
      "Epoch 502/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0155 - val_loss: 0.0153 - learning_rate: 2.5000e-04\n",
      "Epoch 503/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0143 - val_loss: 0.0153 - learning_rate: 2.5000e-04\n",
      "Epoch 504/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0170 - val_loss: 0.0220 - learning_rate: 2.5000e-04\n",
      "Epoch 505/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0195 - val_loss: 0.0188 - learning_rate: 2.5000e-04\n",
      "Epoch 506/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0134 - val_loss: 0.0168 - learning_rate: 2.5000e-04\n",
      "Epoch 507/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0130 - val_loss: 0.0170 - learning_rate: 2.5000e-04\n",
      "Epoch 508/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0136 - val_loss: 0.0197 - learning_rate: 2.5000e-04\n",
      "Epoch 509/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0194 - val_loss: 0.0168 - learning_rate: 2.5000e-04\n",
      "Epoch 510/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0172 - val_loss: 0.0439 - learning_rate: 2.5000e-04\n",
      "Epoch 511/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0411 - val_loss: 0.0349 - learning_rate: 2.5000e-04\n",
      "Epoch 512/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0340 - val_loss: 0.0162 - learning_rate: 2.5000e-04\n",
      "Epoch 513/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0229 - val_loss: 0.0254 - learning_rate: 2.5000e-04\n",
      "Epoch 514/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0158 - val_loss: 0.0165 - learning_rate: 2.5000e-04\n",
      "Epoch 515/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0269 - val_loss: 0.0157 - learning_rate: 2.5000e-04\n",
      "Epoch 516/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0180 - val_loss: 0.0181 - learning_rate: 2.5000e-04\n",
      "Epoch 517/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0168 - val_loss: 0.0181 - learning_rate: 2.5000e-04\n",
      "Epoch 518/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0174 - val_loss: 0.0292 - learning_rate: 2.5000e-04\n",
      "Epoch 519/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0203 - val_loss: 0.0203 - learning_rate: 2.5000e-04\n",
      "Epoch 520/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0137 - val_loss: 0.0224 - learning_rate: 2.5000e-04\n",
      "Epoch 521/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0143 - val_loss: 0.0161 - learning_rate: 2.5000e-04\n",
      "Epoch 522/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0145 - val_loss: 0.0217 - learning_rate: 2.5000e-04\n",
      "Epoch 523/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0181 - val_loss: 0.0246 - learning_rate: 2.5000e-04\n",
      "Epoch 524/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0176 - val_loss: 0.0232 - learning_rate: 2.5000e-04\n",
      "Epoch 525/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0208 - val_loss: 0.0170 - learning_rate: 2.5000e-04\n",
      "Epoch 526/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0165 - val_loss: 0.0167 - learning_rate: 2.5000e-04\n",
      "Epoch 527/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0136 - val_loss: 0.0155 - learning_rate: 2.5000e-04\n",
      "Epoch 528/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0154 - val_loss: 0.0160 - learning_rate: 2.5000e-04\n",
      "Epoch 529/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0131 - val_loss: 0.0155 - learning_rate: 2.5000e-04\n",
      "Epoch 530/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0213 - val_loss: 0.0286 - learning_rate: 2.5000e-04\n",
      "Epoch 531/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0283 - val_loss: 0.0161 - learning_rate: 2.5000e-04\n",
      "Epoch 532/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0247 - val_loss: 0.0221 - learning_rate: 2.5000e-04\n",
      "Epoch 533/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0210 - val_loss: 0.0431 - learning_rate: 2.5000e-04\n",
      "Epoch 534/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0231 - val_loss: 0.0176 - learning_rate: 2.5000e-04\n",
      "Epoch 535/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0166 - val_loss: 0.0221 - learning_rate: 2.5000e-04\n",
      "Epoch 536/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0185 - val_loss: 0.0166 - learning_rate: 2.5000e-04\n",
      "Epoch 537/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0178 - val_loss: 0.0220 - learning_rate: 2.5000e-04\n",
      "Epoch 538/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0261 - val_loss: 0.0184 - learning_rate: 2.5000e-04\n",
      "Epoch 539/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0153 - val_loss: 0.0144 - learning_rate: 1.2500e-04\n",
      "Epoch 540/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0120 - val_loss: 0.0155 - learning_rate: 1.2500e-04\n",
      "Epoch 541/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0139 - val_loss: 0.0136 - learning_rate: 1.2500e-04\n",
      "Epoch 542/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0135 - val_loss: 0.0142 - learning_rate: 1.2500e-04\n",
      "Epoch 543/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0137 - val_loss: 0.0150 - learning_rate: 1.2500e-04\n",
      "Epoch 544/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0132 - val_loss: 0.0150 - learning_rate: 1.2500e-04\n",
      "Epoch 545/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0128 - val_loss: 0.0136 - learning_rate: 1.2500e-04\n",
      "Epoch 546/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0153 - val_loss: 0.0176 - learning_rate: 1.2500e-04\n",
      "Epoch 547/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0124 - val_loss: 0.0137 - learning_rate: 1.2500e-04\n",
      "Epoch 548/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0159 - val_loss: 0.0288 - learning_rate: 1.2500e-04\n",
      "Epoch 549/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0139 - val_loss: 0.0141 - learning_rate: 1.2500e-04\n",
      "Epoch 550/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0124 - val_loss: 0.0155 - learning_rate: 1.2500e-04\n",
      "Epoch 551/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0146 - val_loss: 0.0145 - learning_rate: 1.2500e-04\n",
      "Epoch 552/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0128 - val_loss: 0.0181 - learning_rate: 1.2500e-04\n",
      "Epoch 553/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0124 - val_loss: 0.0148 - learning_rate: 1.2500e-04\n",
      "Epoch 554/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0124 - val_loss: 0.0136 - learning_rate: 1.2500e-04\n",
      "Epoch 555/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0120 - val_loss: 0.0143 - learning_rate: 1.2500e-04\n",
      "Epoch 556/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0128 - val_loss: 0.0158 - learning_rate: 1.2500e-04\n",
      "Epoch 557/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0136 - val_loss: 0.0186 - learning_rate: 1.2500e-04\n",
      "Epoch 558/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0126 - val_loss: 0.0191 - learning_rate: 1.2500e-04\n",
      "Epoch 559/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0135 - val_loss: 0.0147 - learning_rate: 1.2500e-04\n",
      "Epoch 560/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0128 - val_loss: 0.0146 - learning_rate: 1.2500e-04\n",
      "Epoch 561/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0122 - val_loss: 0.0143 - learning_rate: 1.2500e-04\n",
      "Epoch 562/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0120 - val_loss: 0.0153 - learning_rate: 1.2500e-04\n",
      "Epoch 563/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0123 - val_loss: 0.0183 - learning_rate: 1.2500e-04\n",
      "Epoch 564/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0157 - val_loss: 0.0183 - learning_rate: 1.2500e-04\n",
      "Epoch 565/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0128 - val_loss: 0.0135 - learning_rate: 1.2500e-04\n",
      "Epoch 566/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0139 - val_loss: 0.0178 - learning_rate: 1.2500e-04\n",
      "Epoch 567/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0174 - val_loss: 0.0253 - learning_rate: 1.2500e-04\n",
      "Epoch 568/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0175 - val_loss: 0.0175 - learning_rate: 1.2500e-04\n",
      "Epoch 569/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0175 - val_loss: 0.0156 - learning_rate: 1.2500e-04\n",
      "Epoch 570/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0144 - val_loss: 0.0205 - learning_rate: 1.2500e-04\n",
      "Epoch 571/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0134 - val_loss: 0.0152 - learning_rate: 1.2500e-04\n",
      "Epoch 572/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0111 - val_loss: 0.0160 - learning_rate: 1.2500e-04\n",
      "Epoch 573/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0169 - val_loss: 0.0131 - learning_rate: 1.2500e-04\n",
      "Epoch 574/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0124 - val_loss: 0.0149 - learning_rate: 1.2500e-04\n",
      "Epoch 575/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0152 - val_loss: 0.0139 - learning_rate: 1.2500e-04\n",
      "Epoch 576/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0147 - val_loss: 0.0223 - learning_rate: 1.2500e-04\n",
      "Epoch 577/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0135 - val_loss: 0.0144 - learning_rate: 1.2500e-04\n",
      "Epoch 578/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0138 - val_loss: 0.0178 - learning_rate: 1.2500e-04\n",
      "Epoch 579/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0152 - val_loss: 0.0149 - learning_rate: 1.2500e-04\n",
      "Epoch 580/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0135 - val_loss: 0.0143 - learning_rate: 1.2500e-04\n",
      "Epoch 581/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0113 - val_loss: 0.0136 - learning_rate: 1.2500e-04\n",
      "Epoch 582/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0115 - val_loss: 0.0160 - learning_rate: 1.2500e-04\n",
      "Epoch 583/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0137 - val_loss: 0.0161 - learning_rate: 1.2500e-04\n",
      "Epoch 584/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0126 - val_loss: 0.0149 - learning_rate: 1.2500e-04\n",
      "Epoch 585/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0124 - val_loss: 0.0180 - learning_rate: 1.2500e-04\n",
      "Epoch 586/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0166 - val_loss: 0.0165 - learning_rate: 1.2500e-04\n",
      "Epoch 587/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0187 - val_loss: 0.0185 - learning_rate: 1.2500e-04\n",
      "Epoch 588/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0141 - val_loss: 0.0183 - learning_rate: 1.2500e-04\n",
      "Epoch 589/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0155 - val_loss: 0.0132 - learning_rate: 1.2500e-04\n",
      "Epoch 590/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0143 - val_loss: 0.0255 - learning_rate: 1.2500e-04\n",
      "Epoch 591/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0156 - val_loss: 0.0148 - learning_rate: 1.2500e-04\n",
      "Epoch 592/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0150 - val_loss: 0.0149 - learning_rate: 1.2500e-04\n",
      "Epoch 593/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0131 - val_loss: 0.0147 - learning_rate: 1.2500e-04\n",
      "Epoch 594/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0140 - val_loss: 0.0210 - learning_rate: 1.2500e-04\n",
      "Epoch 595/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0141 - val_loss: 0.0140 - learning_rate: 1.2500e-04\n",
      "Epoch 596/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0126 - val_loss: 0.0138 - learning_rate: 1.2500e-04\n",
      "Epoch 597/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0128 - val_loss: 0.0156 - learning_rate: 1.2500e-04\n",
      "Epoch 598/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0121 - val_loss: 0.0158 - learning_rate: 1.2500e-04\n",
      "Epoch 599/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0130 - val_loss: 0.0158 - learning_rate: 1.2500e-04\n",
      "Epoch 600/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0150 - val_loss: 0.0144 - learning_rate: 1.2500e-04\n",
      "Epoch 601/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0135 - val_loss: 0.0148 - learning_rate: 1.2500e-04\n",
      "Epoch 602/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0129 - val_loss: 0.0130 - learning_rate: 1.2500e-04\n",
      "Epoch 603/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0157 - val_loss: 0.0182 - learning_rate: 1.2500e-04\n",
      "Epoch 604/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0154 - val_loss: 0.0173 - learning_rate: 1.2500e-04\n",
      "Epoch 605/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0184 - val_loss: 0.0155 - learning_rate: 1.2500e-04\n",
      "Epoch 606/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0160 - val_loss: 0.0205 - learning_rate: 1.2500e-04\n",
      "Epoch 607/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0202 - val_loss: 0.0279 - learning_rate: 1.2500e-04\n",
      "Epoch 608/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0170 - val_loss: 0.0163 - learning_rate: 1.2500e-04\n",
      "Epoch 609/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0136 - val_loss: 0.0147 - learning_rate: 1.2500e-04\n",
      "Epoch 610/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0123 - val_loss: 0.0143 - learning_rate: 1.2500e-04\n",
      "Epoch 611/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0132 - val_loss: 0.0183 - learning_rate: 1.2500e-04\n",
      "Epoch 612/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0116 - val_loss: 0.0152 - learning_rate: 1.2500e-04\n",
      "Epoch 613/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0114 - val_loss: 0.0151 - learning_rate: 1.2500e-04\n",
      "Epoch 614/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0140 - val_loss: 0.0128 - learning_rate: 1.2500e-04\n",
      "Epoch 615/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0134 - val_loss: 0.0162 - learning_rate: 1.2500e-04\n",
      "Epoch 616/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0150 - val_loss: 0.0149 - learning_rate: 1.2500e-04\n",
      "Epoch 617/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0161 - val_loss: 0.0154 - learning_rate: 1.2500e-04\n",
      "Epoch 618/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0148 - val_loss: 0.0155 - learning_rate: 1.2500e-04\n",
      "Epoch 619/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0160 - val_loss: 0.0127 - learning_rate: 1.2500e-04\n",
      "Epoch 620/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0132 - val_loss: 0.0145 - learning_rate: 1.2500e-04\n",
      "Epoch 621/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0128 - val_loss: 0.0201 - learning_rate: 1.2500e-04\n",
      "Epoch 622/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0137 - val_loss: 0.0154 - learning_rate: 1.2500e-04\n",
      "Epoch 623/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0150 - val_loss: 0.0183 - learning_rate: 1.2500e-04\n",
      "Epoch 624/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0134 - val_loss: 0.0157 - learning_rate: 1.2500e-04\n",
      "Epoch 625/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0137 - val_loss: 0.0139 - learning_rate: 1.2500e-04\n",
      "Epoch 626/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0134 - val_loss: 0.0123 - learning_rate: 1.2500e-04\n",
      "Epoch 627/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0138 - val_loss: 0.0366 - learning_rate: 1.2500e-04\n",
      "Epoch 628/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0182 - val_loss: 0.0225 - learning_rate: 1.2500e-04\n",
      "Epoch 629/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0136 - val_loss: 0.0205 - learning_rate: 1.2500e-04\n",
      "Epoch 630/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0162 - val_loss: 0.0125 - learning_rate: 1.2500e-04\n",
      "Epoch 631/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0110 - val_loss: 0.0131 - learning_rate: 1.2500e-04\n",
      "Epoch 632/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0117 - val_loss: 0.0157 - learning_rate: 1.2500e-04\n",
      "Epoch 633/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0147 - val_loss: 0.0178 - learning_rate: 1.2500e-04\n",
      "Epoch 634/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0139 - val_loss: 0.0131 - learning_rate: 1.2500e-04\n",
      "Epoch 635/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0123 - val_loss: 0.0162 - learning_rate: 1.2500e-04\n",
      "Epoch 636/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0130 - val_loss: 0.0162 - learning_rate: 1.2500e-04\n",
      "Epoch 637/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0149 - val_loss: 0.0165 - learning_rate: 1.2500e-04\n",
      "Epoch 638/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0154 - val_loss: 0.0145 - learning_rate: 1.2500e-04\n",
      "Epoch 639/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0121 - val_loss: 0.0147 - learning_rate: 1.2500e-04\n",
      "Epoch 640/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0117 - val_loss: 0.0126 - learning_rate: 1.2500e-04\n",
      "Epoch 641/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0122 - val_loss: 0.0125 - learning_rate: 1.2500e-04\n",
      "Epoch 642/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0151 - val_loss: 0.0200 - learning_rate: 1.2500e-04\n",
      "Epoch 643/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0149 - val_loss: 0.0130 - learning_rate: 1.2500e-04\n",
      "Epoch 644/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0116 - val_loss: 0.0124 - learning_rate: 1.2500e-04\n",
      "Epoch 645/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0119 - val_loss: 0.0123 - learning_rate: 1.2500e-04\n",
      "Epoch 646/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0137 - val_loss: 0.0143 - learning_rate: 1.2500e-04\n",
      "Epoch 647/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0127 - val_loss: 0.0132 - learning_rate: 1.2500e-04\n",
      "Epoch 648/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0139 - val_loss: 0.0214 - learning_rate: 1.2500e-04\n",
      "Epoch 649/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0189 - val_loss: 0.0149 - learning_rate: 1.2500e-04\n",
      "Epoch 650/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0131 - val_loss: 0.0160 - learning_rate: 1.2500e-04\n",
      "Epoch 651/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0113 - val_loss: 0.0131 - learning_rate: 1.2500e-04\n",
      "Epoch 652/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0136 - val_loss: 0.0131 - learning_rate: 1.2500e-04\n",
      "Epoch 653/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0126 - val_loss: 0.0132 - learning_rate: 1.2500e-04\n",
      "Epoch 654/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0110 - val_loss: 0.0142 - learning_rate: 1.2500e-04\n",
      "Epoch 655/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0107 - val_loss: 0.0125 - learning_rate: 1.2500e-04\n",
      "Epoch 656/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0114 - val_loss: 0.0157 - learning_rate: 1.2500e-04\n",
      "Epoch 657/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0159 - val_loss: 0.0129 - learning_rate: 1.2500e-04\n",
      "Epoch 658/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0131 - val_loss: 0.0161 - learning_rate: 1.2500e-04\n",
      "Epoch 659/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0140 - val_loss: 0.0138 - learning_rate: 1.2500e-04\n",
      "Epoch 660/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0117 - val_loss: 0.0126 - learning_rate: 1.2500e-04\n",
      "Epoch 661/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0130 - val_loss: 0.0196 - learning_rate: 1.2500e-04\n",
      "Epoch 662/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0156 - val_loss: 0.0208 - learning_rate: 1.2500e-04\n",
      "Epoch 663/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0175 - val_loss: 0.0146 - learning_rate: 1.2500e-04\n",
      "Epoch 664/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0122 - val_loss: 0.0157 - learning_rate: 1.2500e-04\n",
      "Epoch 665/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0144 - val_loss: 0.0140 - learning_rate: 1.2500e-04\n",
      "Epoch 666/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0190 - val_loss: 0.0194 - learning_rate: 1.2500e-04\n",
      "Epoch 667/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0125 - val_loss: 0.0146 - learning_rate: 1.2500e-04\n",
      "Epoch 668/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0160 - val_loss: 0.0189 - learning_rate: 1.2500e-04\n",
      "Epoch 669/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0154 - val_loss: 0.0139 - learning_rate: 1.2500e-04\n",
      "Epoch 670/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0144 - val_loss: 0.0189 - learning_rate: 1.2500e-04\n",
      "Epoch 671/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0158 - val_loss: 0.0165 - learning_rate: 1.2500e-04\n",
      "Epoch 672/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0130 - val_loss: 0.0139 - learning_rate: 1.2500e-04\n",
      "Epoch 673/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0110 - val_loss: 0.0117 - learning_rate: 1.2500e-04\n",
      "Epoch 674/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0111 - val_loss: 0.0125 - learning_rate: 1.2500e-04\n",
      "Epoch 675/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0108 - val_loss: 0.0134 - learning_rate: 1.2500e-04\n",
      "Epoch 676/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0112 - val_loss: 0.0128 - learning_rate: 1.2500e-04\n",
      "Epoch 677/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0200 - val_loss: 0.0198 - learning_rate: 1.2500e-04\n",
      "Epoch 678/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0135 - val_loss: 0.0174 - learning_rate: 1.2500e-04\n",
      "Epoch 679/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - val_loss: 0.0125 - learning_rate: 1.2500e-04\n",
      "Epoch 680/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0106 - val_loss: 0.0119 - learning_rate: 1.2500e-04\n",
      "Epoch 681/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0105 - val_loss: 0.0163 - learning_rate: 1.2500e-04\n",
      "Epoch 682/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - val_loss: 0.0139 - learning_rate: 1.2500e-04\n",
      "Epoch 683/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0130 - val_loss: 0.0131 - learning_rate: 1.2500e-04\n",
      "Epoch 684/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0103 - val_loss: 0.0121 - learning_rate: 1.2500e-04\n",
      "Epoch 685/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0106 - val_loss: 0.0135 - learning_rate: 1.2500e-04\n",
      "Epoch 686/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0122 - val_loss: 0.0130 - learning_rate: 1.2500e-04\n",
      "Epoch 687/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0125 - val_loss: 0.0119 - learning_rate: 1.2500e-04\n",
      "Epoch 688/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0108 - val_loss: 0.0123 - learning_rate: 1.2500e-04\n",
      "Epoch 689/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0104 - val_loss: 0.0142 - learning_rate: 1.2500e-04\n",
      "Epoch 690/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0117 - val_loss: 0.0144 - learning_rate: 1.2500e-04\n",
      "Epoch 691/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0143 - val_loss: 0.0143 - learning_rate: 1.2500e-04\n",
      "Epoch 692/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0106 - val_loss: 0.0131 - learning_rate: 1.2500e-04\n",
      "Epoch 693/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - val_loss: 0.0127 - learning_rate: 1.2500e-04\n",
      "Epoch 694/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0132 - val_loss: 0.0189 - learning_rate: 1.2500e-04\n",
      "Epoch 695/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0158 - val_loss: 0.0228 - learning_rate: 1.2500e-04\n",
      "Epoch 696/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0127 - val_loss: 0.0138 - learning_rate: 1.2500e-04\n",
      "Epoch 697/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0141 - val_loss: 0.0181 - learning_rate: 1.2500e-04\n",
      "Epoch 698/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0152 - val_loss: 0.0141 - learning_rate: 1.2500e-04\n",
      "Epoch 699/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0171 - val_loss: 0.0179 - learning_rate: 1.2500e-04\n",
      "Epoch 700/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-0s\u001b[0m -14711us/step - loss: 0.0175 - val_loss: 0.0159 - learning_rate: 1.2500e-04\n",
      "Epoch 701/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0162 - val_loss: 0.0231 - learning_rate: 1.2500e-04\n",
      "Epoch 702/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0150 - val_loss: 0.0151 - learning_rate: 1.2500e-04\n",
      "Epoch 703/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0118 - val_loss: 0.0126 - learning_rate: 1.2500e-04\n",
      "Epoch 704/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - val_loss: 0.0157 - learning_rate: 1.2500e-04\n",
      "Epoch 705/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0137 - val_loss: 0.0151 - learning_rate: 1.2500e-04\n",
      "Epoch 706/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0106 - val_loss: 0.0126 - learning_rate: 1.2500e-04\n",
      "Epoch 707/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0110 - val_loss: 0.0128 - learning_rate: 1.2500e-04\n",
      "Epoch 708/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0114 - val_loss: 0.0153 - learning_rate: 1.2500e-04\n",
      "Epoch 709/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0156 - val_loss: 0.0120 - learning_rate: 1.2500e-04\n",
      "Epoch 710/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0115 - val_loss: 0.0120 - learning_rate: 1.2500e-04\n",
      "Epoch 711/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0112 - val_loss: 0.0121 - learning_rate: 1.2500e-04\n",
      "Epoch 712/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0108 - val_loss: 0.0123 - learning_rate: 1.2500e-04\n",
      "Epoch 713/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0126 - val_loss: 0.0132 - learning_rate: 1.2500e-04\n",
      "Epoch 714/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0100 - val_loss: 0.0170 - learning_rate: 1.2500e-04\n",
      "Epoch 715/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0128 - val_loss: 0.0285 - learning_rate: 1.2500e-04\n",
      "Epoch 716/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182 - val_loss: 0.0154 - learning_rate: 1.2500e-04\n",
      "Epoch 717/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0147 - val_loss: 0.0169 - learning_rate: 1.2500e-04\n",
      "Epoch 718/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0142 - val_loss: 0.0152 - learning_rate: 1.2500e-04\n",
      "Epoch 719/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0120 - val_loss: 0.0161 - learning_rate: 1.2500e-04\n",
      "Epoch 720/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0122 - val_loss: 0.0152 - learning_rate: 1.2500e-04\n",
      "Epoch 721/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0105 - val_loss: 0.0116 - learning_rate: 1.2500e-04\n",
      "Epoch 722/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0101 - val_loss: 0.0115 - learning_rate: 1.2500e-04\n",
      "Epoch 723/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0110 - val_loss: 0.0124 - learning_rate: 1.2500e-04\n",
      "Epoch 724/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0131 - val_loss: 0.0109 - learning_rate: 1.2500e-04\n",
      "Epoch 725/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0127 - val_loss: 0.0117 - learning_rate: 1.2500e-04\n",
      "Epoch 726/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0125 - val_loss: 0.0128 - learning_rate: 1.2500e-04\n",
      "Epoch 727/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0115 - val_loss: 0.0130 - learning_rate: 1.2500e-04\n",
      "Epoch 728/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0160 - val_loss: 0.0165 - learning_rate: 1.2500e-04\n",
      "Epoch 729/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0146 - val_loss: 0.0126 - learning_rate: 1.2500e-04\n",
      "Epoch 730/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0113 - val_loss: 0.0114 - learning_rate: 1.2500e-04\n",
      "Epoch 731/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0111 - val_loss: 0.0114 - learning_rate: 1.2500e-04\n",
      "Epoch 732/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0117 - val_loss: 0.0167 - learning_rate: 1.2500e-04\n",
      "Epoch 733/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0134 - val_loss: 0.0291 - learning_rate: 1.2500e-04\n",
      "Epoch 734/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0200 - val_loss: 0.0142 - learning_rate: 1.2500e-04\n",
      "Epoch 735/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0112 - val_loss: 0.0108 - learning_rate: 1.2500e-04\n",
      "Epoch 736/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0128 - val_loss: 0.0141 - learning_rate: 1.2500e-04\n",
      "Epoch 737/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0117 - val_loss: 0.0141 - learning_rate: 1.2500e-04\n",
      "Epoch 738/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0137 - val_loss: 0.0155 - learning_rate: 1.2500e-04\n",
      "Epoch 739/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0113 - val_loss: 0.0125 - learning_rate: 1.2500e-04\n",
      "Epoch 740/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0118 - val_loss: 0.0117 - learning_rate: 1.2500e-04\n",
      "Epoch 741/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0103 - val_loss: 0.0124 - learning_rate: 1.2500e-04\n",
      "Epoch 742/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0156 - val_loss: 0.0109 - learning_rate: 1.2500e-04\n",
      "Epoch 743/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0128 - val_loss: 0.0132 - learning_rate: 1.2500e-04\n",
      "Epoch 744/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0124 - val_loss: 0.0151 - learning_rate: 1.2500e-04\n",
      "Epoch 745/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0131 - val_loss: 0.0125 - learning_rate: 1.2500e-04\n",
      "Epoch 746/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0153 - val_loss: 0.0114 - learning_rate: 1.2500e-04\n",
      "Epoch 747/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0121 - val_loss: 0.0124 - learning_rate: 1.2500e-04\n",
      "Epoch 748/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0109 - val_loss: 0.0136 - learning_rate: 1.2500e-04\n",
      "Epoch 749/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0096 - val_loss: 0.0122 - learning_rate: 1.2500e-04\n",
      "Epoch 750/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0117 - val_loss: 0.0127 - learning_rate: 1.2500e-04\n",
      "Epoch 751/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - val_loss: 0.0128 - learning_rate: 1.2500e-04\n",
      "Epoch 752/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0102 - val_loss: 0.0128 - learning_rate: 1.2500e-04\n",
      "Epoch 753/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0110 - val_loss: 0.0127 - learning_rate: 1.2500e-04\n",
      "Epoch 754/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0107 - val_loss: 0.0125 - learning_rate: 1.2500e-04\n",
      "Epoch 755/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0102 - val_loss: 0.0180 - learning_rate: 1.2500e-04\n",
      "Epoch 756/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0105 - val_loss: 0.0196 - learning_rate: 1.2500e-04\n",
      "Epoch 757/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0139 - val_loss: 0.0110 - learning_rate: 1.2500e-04\n",
      "Epoch 758/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0115 - val_loss: 0.0131 - learning_rate: 1.2500e-04\n",
      "Epoch 759/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0107 - val_loss: 0.0122 - learning_rate: 1.2500e-04\n",
      "Epoch 760/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0097 - val_loss: 0.0118 - learning_rate: 1.2500e-04\n",
      "Epoch 761/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0135 - val_loss: 0.0129 - learning_rate: 1.2500e-04\n",
      "Epoch 762/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0132 - val_loss: 0.0125 - learning_rate: 1.2500e-04\n",
      "Epoch 763/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0105 - val_loss: 0.0112 - learning_rate: 1.2500e-04\n",
      "Epoch 764/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0114 - val_loss: 0.0155 - learning_rate: 1.2500e-04\n",
      "Epoch 765/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0107 - val_loss: 0.0111 - learning_rate: 1.2500e-04\n",
      "Epoch 766/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0132 - val_loss: 0.0127 - learning_rate: 1.2500e-04\n",
      "Epoch 767/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0109 - val_loss: 0.0147 - learning_rate: 1.2500e-04\n",
      "Epoch 768/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0100 - val_loss: 0.0153 - learning_rate: 1.2500e-04\n",
      "Epoch 769/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0110 - val_loss: 0.0112 - learning_rate: 1.2500e-04\n",
      "Epoch 770/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0106 - val_loss: 0.0130 - learning_rate: 1.2500e-04\n",
      "Epoch 771/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0151 - val_loss: 0.0536 - learning_rate: 1.2500e-04\n",
      "Epoch 772/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0265 - val_loss: 0.0145 - learning_rate: 1.2500e-04\n",
      "Epoch 773/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - val_loss: 0.0118 - learning_rate: 1.2500e-04\n",
      "Epoch 774/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - val_loss: 0.0121 - learning_rate: 1.2500e-04\n",
      "Epoch 775/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0108 - val_loss: 0.0112 - learning_rate: 1.2500e-04\n",
      "Epoch 776/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102 - val_loss: 0.0129 - learning_rate: 1.2500e-04\n",
      "Epoch 777/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0115 - val_loss: 0.0113 - learning_rate: 1.2500e-04\n",
      "Epoch 778/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - val_loss: 0.0122 - learning_rate: 1.2500e-04\n",
      "Epoch 779/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0108 - val_loss: 0.0121 - learning_rate: 1.2500e-04\n",
      "Epoch 780/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0103 - val_loss: 0.0114 - learning_rate: 1.2500e-04\n",
      "Epoch 781/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0098 - val_loss: 0.0127 - learning_rate: 1.2500e-04\n",
      "Epoch 782/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0143 - val_loss: 0.0199 - learning_rate: 1.2500e-04\n",
      "Epoch 783/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0123 - val_loss: 0.0158 - learning_rate: 1.2500e-04\n",
      "Epoch 784/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0115 - val_loss: 0.0127 - learning_rate: 1.2500e-04\n",
      "Epoch 785/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0096 - val_loss: 0.0114 - learning_rate: 1.2500e-04\n",
      "Epoch 786/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0124 - learning_rate: 6.2500e-05\n",
      "Epoch 787/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0101 - val_loss: 0.0121 - learning_rate: 6.2500e-05\n",
      "Epoch 788/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - val_loss: 0.0109 - learning_rate: 6.2500e-05\n",
      "Epoch 789/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0090 - val_loss: 0.0110 - learning_rate: 6.2500e-05\n",
      "Epoch 790/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102 - val_loss: 0.0111 - learning_rate: 6.2500e-05\n",
      "Epoch 791/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0117 - learning_rate: 6.2500e-05\n",
      "Epoch 792/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0113 - learning_rate: 6.2500e-05\n",
      "Epoch 793/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0174 - learning_rate: 6.2500e-05\n",
      "Epoch 794/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0100 - val_loss: 0.0106 - learning_rate: 6.2500e-05\n",
      "Epoch 795/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0093 - val_loss: 0.0106 - learning_rate: 6.2500e-05\n",
      "Epoch 796/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0106 - learning_rate: 6.2500e-05\n",
      "Epoch 797/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0121 - learning_rate: 6.2500e-05\n",
      "Epoch 798/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0109 - val_loss: 0.0116 - learning_rate: 6.2500e-05\n",
      "Epoch 799/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0099 - val_loss: 0.0119 - learning_rate: 6.2500e-05\n",
      "Epoch 800/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - val_loss: 0.0108 - learning_rate: 6.2500e-05\n",
      "Epoch 801/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0109 - learning_rate: 6.2500e-05\n",
      "Epoch 802/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0114 - learning_rate: 6.2500e-05\n",
      "Epoch 803/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0091 - val_loss: 0.0112 - learning_rate: 6.2500e-05\n",
      "Epoch 804/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0116 - learning_rate: 6.2500e-05\n",
      "Epoch 805/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0106 - learning_rate: 6.2500e-05\n",
      "Epoch 806/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0085 - val_loss: 0.0112 - learning_rate: 6.2500e-05\n",
      "Epoch 807/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0092 - val_loss: 0.0122 - learning_rate: 6.2500e-05\n",
      "Epoch 808/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0090 - val_loss: 0.0114 - learning_rate: 6.2500e-05\n",
      "Epoch 809/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0096 - val_loss: 0.0120 - learning_rate: 6.2500e-05\n",
      "Epoch 810/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0110 - learning_rate: 6.2500e-05\n",
      "Epoch 811/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0105 - learning_rate: 6.2500e-05\n",
      "Epoch 812/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0108 - learning_rate: 6.2500e-05\n",
      "Epoch 813/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0123 - learning_rate: 6.2500e-05\n",
      "Epoch 814/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0115 - learning_rate: 6.2500e-05\n",
      "Epoch 815/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - val_loss: 0.0116 - learning_rate: 6.2500e-05\n",
      "Epoch 816/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0092 - val_loss: 0.0107 - learning_rate: 6.2500e-05\n",
      "Epoch 817/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0108 - val_loss: 0.0153 - learning_rate: 6.2500e-05\n",
      "Epoch 818/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0117 - learning_rate: 6.2500e-05\n",
      "Epoch 819/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0092 - val_loss: 0.0139 - learning_rate: 6.2500e-05\n",
      "Epoch 820/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0099 - val_loss: 0.0117 - learning_rate: 6.2500e-05\n",
      "Epoch 821/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0092 - val_loss: 0.0118 - learning_rate: 6.2500e-05\n",
      "Epoch 822/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0093 - val_loss: 0.0119 - learning_rate: 6.2500e-05\n",
      "Epoch 823/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0096 - val_loss: 0.0112 - learning_rate: 6.2500e-05\n",
      "Epoch 824/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0087 - val_loss: 0.0119 - learning_rate: 6.2500e-05\n",
      "Epoch 825/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0097 - val_loss: 0.0104 - learning_rate: 6.2500e-05\n",
      "Epoch 826/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0117 - learning_rate: 6.2500e-05\n",
      "Epoch 827/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0096 - val_loss: 0.0118 - learning_rate: 6.2500e-05\n",
      "Epoch 828/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0092 - val_loss: 0.0129 - learning_rate: 6.2500e-05\n",
      "Epoch 829/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0099 - val_loss: 0.0106 - learning_rate: 6.2500e-05\n",
      "Epoch 830/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102 - val_loss: 0.0120 - learning_rate: 6.2500e-05\n",
      "Epoch 831/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0119 - val_loss: 0.0106 - learning_rate: 6.2500e-05\n",
      "Epoch 832/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0090 - val_loss: 0.0102 - learning_rate: 6.2500e-05\n",
      "Epoch 833/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0098 - val_loss: 0.0124 - learning_rate: 6.2500e-05\n",
      "Epoch 834/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0096 - val_loss: 0.0109 - learning_rate: 6.2500e-05\n",
      "Epoch 835/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0114 - learning_rate: 6.2500e-05\n",
      "Epoch 836/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0110 - learning_rate: 6.2500e-05\n",
      "Epoch 837/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0112 - learning_rate: 6.2500e-05\n",
      "Epoch 838/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0111 - learning_rate: 6.2500e-05\n",
      "Epoch 839/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0131 - learning_rate: 6.2500e-05\n",
      "Epoch 840/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0102 - val_loss: 0.0108 - learning_rate: 6.2500e-05\n",
      "Epoch 841/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0114 - val_loss: 0.0107 - learning_rate: 6.2500e-05\n",
      "Epoch 842/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0102 - val_loss: 0.0135 - learning_rate: 6.2500e-05\n",
      "Epoch 843/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0130 - val_loss: 0.0145 - learning_rate: 6.2500e-05\n",
      "Epoch 844/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0096 - val_loss: 0.0115 - learning_rate: 6.2500e-05\n",
      "Epoch 845/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0105 - learning_rate: 6.2500e-05\n",
      "Epoch 846/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0092 - val_loss: 0.0108 - learning_rate: 6.2500e-05\n",
      "Epoch 847/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0113 - learning_rate: 6.2500e-05\n",
      "Epoch 848/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - val_loss: 0.0112 - learning_rate: 6.2500e-05\n",
      "Epoch 849/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0091 - val_loss: 0.0113 - learning_rate: 6.2500e-05\n",
      "Epoch 850/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0090 - val_loss: 0.0113 - learning_rate: 6.2500e-05\n",
      "Epoch 851/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0109 - val_loss: 0.0100 - learning_rate: 6.2500e-05\n",
      "Epoch 852/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0100 - val_loss: 0.0134 - learning_rate: 6.2500e-05\n",
      "Epoch 853/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0095 - val_loss: 0.0102 - learning_rate: 6.2500e-05\n",
      "Epoch 854/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0096 - val_loss: 0.0099 - learning_rate: 6.2500e-05\n",
      "Epoch 855/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0095 - val_loss: 0.0112 - learning_rate: 6.2500e-05\n",
      "Epoch 856/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0106 - learning_rate: 6.2500e-05\n",
      "Epoch 857/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - val_loss: 0.0109 - learning_rate: 6.2500e-05\n",
      "Epoch 858/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0096 - val_loss: 0.0118 - learning_rate: 6.2500e-05\n",
      "Epoch 859/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0094 - val_loss: 0.0111 - learning_rate: 6.2500e-05\n",
      "Epoch 860/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0117 - learning_rate: 6.2500e-05\n",
      "Epoch 861/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0107 - learning_rate: 6.2500e-05\n",
      "Epoch 862/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0090 - val_loss: 0.0114 - learning_rate: 6.2500e-05\n",
      "Epoch 863/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0100 - val_loss: 0.0118 - learning_rate: 6.2500e-05\n",
      "Epoch 864/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0100 - val_loss: 0.0113 - learning_rate: 6.2500e-05\n",
      "Epoch 865/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0118 - learning_rate: 6.2500e-05\n",
      "Epoch 866/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0092 - val_loss: 0.0135 - learning_rate: 6.2500e-05\n",
      "Epoch 867/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0120 - val_loss: 0.0124 - learning_rate: 6.2500e-05\n",
      "Epoch 868/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0100 - val_loss: 0.0129 - learning_rate: 6.2500e-05\n",
      "Epoch 869/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0101 - val_loss: 0.0107 - learning_rate: 6.2500e-05\n",
      "Epoch 870/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0108 - learning_rate: 6.2500e-05\n",
      "Epoch 871/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0094 - val_loss: 0.0117 - learning_rate: 6.2500e-05\n",
      "Epoch 872/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0107 - learning_rate: 6.2500e-05\n",
      "Epoch 873/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0104 - learning_rate: 6.2500e-05\n",
      "Epoch 874/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0133 - learning_rate: 6.2500e-05\n",
      "Epoch 875/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0097 - val_loss: 0.0103 - learning_rate: 6.2500e-05\n",
      "Epoch 876/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0097 - val_loss: 0.0101 - learning_rate: 6.2500e-05\n",
      "Epoch 877/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0093 - val_loss: 0.0104 - learning_rate: 6.2500e-05\n",
      "Epoch 878/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0109 - val_loss: 0.0121 - learning_rate: 6.2500e-05\n",
      "Epoch 879/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0092 - val_loss: 0.0101 - learning_rate: 6.2500e-05\n",
      "Epoch 880/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0116 - learning_rate: 6.2500e-05\n",
      "Epoch 881/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0093 - val_loss: 0.0112 - learning_rate: 6.2500e-05\n",
      "Epoch 882/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0103 - learning_rate: 6.2500e-05\n",
      "Epoch 883/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0105 - learning_rate: 6.2500e-05\n",
      "Epoch 884/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0102 - learning_rate: 6.2500e-05\n",
      "Epoch 885/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0114 - learning_rate: 6.2500e-05\n",
      "Epoch 886/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0117 - learning_rate: 6.2500e-05\n",
      "Epoch 887/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0116 - learning_rate: 6.2500e-05\n",
      "Epoch 888/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0126 - learning_rate: 6.2500e-05\n",
      "Epoch 889/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0115 - learning_rate: 6.2500e-05\n",
      "Epoch 890/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - val_loss: 0.0127 - learning_rate: 6.2500e-05\n",
      "Epoch 891/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0128 - learning_rate: 6.2500e-05\n",
      "Epoch 892/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0100 - learning_rate: 6.2500e-05\n",
      "Epoch 893/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0110 - learning_rate: 6.2500e-05\n",
      "Epoch 894/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0118 - learning_rate: 6.2500e-05\n",
      "Epoch 895/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0107 - learning_rate: 6.2500e-05\n",
      "Epoch 896/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0118 - learning_rate: 6.2500e-05\n",
      "Epoch 897/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0101 - learning_rate: 6.2500e-05\n",
      "Epoch 898/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0101 - learning_rate: 6.2500e-05\n",
      "Epoch 899/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0109 - learning_rate: 6.2500e-05\n",
      "Epoch 900/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - val_loss: 0.0146 - learning_rate: 6.2500e-05\n",
      "Epoch 901/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0108 - val_loss: 0.0105 - learning_rate: 6.2500e-05\n",
      "Epoch 902/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0106 - val_loss: 0.0106 - learning_rate: 3.1250e-05\n",
      "Epoch 903/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0085 - val_loss: 0.0125 - learning_rate: 3.1250e-05\n",
      "Epoch 904/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0091 - val_loss: 0.0104 - learning_rate: 3.1250e-05\n",
      "Epoch 905/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0112 - learning_rate: 3.1250e-05\n",
      "Epoch 906/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0083 - val_loss: 0.0116 - learning_rate: 3.1250e-05\n",
      "Epoch 907/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0134 - learning_rate: 3.1250e-05\n",
      "Epoch 908/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0091 - val_loss: 0.0099 - learning_rate: 3.1250e-05\n",
      "Epoch 909/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0087 - val_loss: 0.0105 - learning_rate: 3.1250e-05\n",
      "Epoch 910/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0099 - learning_rate: 3.1250e-05\n",
      "Epoch 911/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0136 - learning_rate: 3.1250e-05\n",
      "Epoch 912/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0106 - learning_rate: 3.1250e-05\n",
      "Epoch 913/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0120 - learning_rate: 3.1250e-05\n",
      "Epoch 914/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0098 - val_loss: 0.0107 - learning_rate: 3.1250e-05\n",
      "Epoch 915/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0085 - val_loss: 0.0101 - learning_rate: 3.1250e-05\n",
      "Epoch 916/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0112 - learning_rate: 3.1250e-05\n",
      "Epoch 917/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0098 - learning_rate: 3.1250e-05\n",
      "Epoch 918/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0102 - learning_rate: 3.1250e-05\n",
      "Epoch 919/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0106 - learning_rate: 3.1250e-05\n",
      "Epoch 920/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0112 - learning_rate: 3.1250e-05\n",
      "Epoch 921/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0106 - learning_rate: 3.1250e-05\n",
      "Epoch 922/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0100 - learning_rate: 3.1250e-05\n",
      "Epoch 923/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0099 - learning_rate: 3.1250e-05\n",
      "Epoch 924/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0102 - learning_rate: 3.1250e-05\n",
      "Epoch 925/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0123 - learning_rate: 3.1250e-05\n",
      "Epoch 926/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0102 - learning_rate: 3.1250e-05\n",
      "Epoch 927/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0100 - learning_rate: 3.1250e-05\n",
      "Epoch 928/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0097 - learning_rate: 3.1250e-05\n",
      "Epoch 929/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0103 - learning_rate: 3.1250e-05\n",
      "Epoch 930/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0099 - learning_rate: 3.1250e-05\n",
      "Epoch 931/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0101 - learning_rate: 3.1250e-05\n",
      "Epoch 932/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0100 - learning_rate: 3.1250e-05\n",
      "Epoch 933/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0101 - learning_rate: 3.1250e-05\n",
      "Epoch 934/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0101 - learning_rate: 3.1250e-05\n",
      "Epoch 935/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0099 - learning_rate: 3.1250e-05\n",
      "Epoch 936/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0106 - learning_rate: 3.1250e-05\n",
      "Epoch 937/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0103 - learning_rate: 3.1250e-05\n",
      "Epoch 938/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0103 - learning_rate: 3.1250e-05\n",
      "Epoch 939/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0105 - learning_rate: 3.1250e-05\n",
      "Epoch 940/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0102 - learning_rate: 3.1250e-05\n",
      "Epoch 941/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0105 - learning_rate: 3.1250e-05\n",
      "Epoch 942/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0113 - learning_rate: 3.1250e-05\n",
      "Epoch 943/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0104 - learning_rate: 3.1250e-05\n",
      "Epoch 944/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0101 - learning_rate: 3.1250e-05\n",
      "Epoch 945/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0110 - learning_rate: 3.1250e-05\n",
      "Epoch 946/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0105 - learning_rate: 3.1250e-05\n",
      "Epoch 947/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0103 - learning_rate: 3.1250e-05\n",
      "Epoch 948/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0102 - learning_rate: 3.1250e-05\n",
      "Epoch 949/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0106 - learning_rate: 3.1250e-05\n",
      "Epoch 950/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0102 - learning_rate: 3.1250e-05\n",
      "Epoch 951/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0101 - learning_rate: 3.1250e-05\n",
      "Epoch 952/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0097 - learning_rate: 3.1250e-05\n",
      "Epoch 953/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0103 - learning_rate: 3.1250e-05\n",
      "Epoch 954/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0110 - learning_rate: 3.1250e-05\n",
      "Epoch 955/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0098 - learning_rate: 3.1250e-05\n",
      "Epoch 956/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0099 - learning_rate: 3.1250e-05\n",
      "Epoch 957/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0106 - learning_rate: 3.1250e-05\n",
      "Epoch 958/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0106 - learning_rate: 3.1250e-05\n",
      "Epoch 959/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0096 - learning_rate: 3.1250e-05\n",
      "Epoch 960/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0115 - learning_rate: 3.1250e-05\n",
      "Epoch 961/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0100 - learning_rate: 3.1250e-05\n",
      "Epoch 962/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0098 - learning_rate: 3.1250e-05\n",
      "Epoch 963/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0106 - learning_rate: 3.1250e-05\n",
      "Epoch 964/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0107 - learning_rate: 3.1250e-05\n",
      "Epoch 965/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0104 - learning_rate: 3.1250e-05\n",
      "Epoch 966/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0107 - learning_rate: 3.1250e-05\n",
      "Epoch 967/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0102 - learning_rate: 3.1250e-05\n",
      "Epoch 968/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0107 - learning_rate: 3.1250e-05\n",
      "Epoch 969/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0101 - learning_rate: 3.1250e-05\n",
      "Epoch 970/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0098 - learning_rate: 3.1250e-05\n",
      "Epoch 971/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0103 - learning_rate: 3.1250e-05\n",
      "Epoch 972/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0098 - learning_rate: 3.1250e-05\n",
      "Epoch 973/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0107 - learning_rate: 3.1250e-05\n",
      "Epoch 974/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0102 - learning_rate: 3.1250e-05\n",
      "Epoch 975/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0120 - learning_rate: 3.1250e-05\n",
      "Epoch 976/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0096 - learning_rate: 3.1250e-05\n",
      "Epoch 977/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0097 - learning_rate: 3.1250e-05\n",
      "Epoch 978/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0100 - learning_rate: 3.1250e-05\n",
      "Epoch 979/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0103 - learning_rate: 1.5625e-05\n",
      "Epoch 980/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 981/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0100 - learning_rate: 1.5625e-05\n",
      "Epoch 982/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 983/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0099 - learning_rate: 1.5625e-05\n",
      "Epoch 984/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 985/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0099 - learning_rate: 1.5625e-05\n",
      "Epoch 986/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 987/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 988/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0098 - learning_rate: 1.5625e-05\n",
      "Epoch 989/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0099 - learning_rate: 1.5625e-05\n",
      "Epoch 990/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0099 - learning_rate: 1.5625e-05\n",
      "Epoch 991/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0104 - learning_rate: 1.5625e-05\n",
      "Epoch 992/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0104 - learning_rate: 1.5625e-05\n",
      "Epoch 993/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 994/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 995/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0095 - learning_rate: 1.5625e-05\n",
      "Epoch 996/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0099 - learning_rate: 1.5625e-05\n",
      "Epoch 997/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0098 - learning_rate: 1.5625e-05\n",
      "Epoch 998/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 999/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1000/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0098 - learning_rate: 1.5625e-05\n",
      "Epoch 1001/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1002/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0109 - learning_rate: 1.5625e-05\n",
      "Epoch 1003/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0095 - learning_rate: 1.5625e-05\n",
      "Epoch 1004/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0098 - learning_rate: 1.5625e-05\n",
      "Epoch 1005/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0098 - learning_rate: 1.5625e-05\n",
      "Epoch 1006/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0095 - learning_rate: 1.5625e-05\n",
      "Epoch 1007/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0107 - learning_rate: 1.5625e-05\n",
      "Epoch 1008/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0101 - learning_rate: 1.5625e-05\n",
      "Epoch 1009/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0109 - learning_rate: 1.5625e-05\n",
      "Epoch 1010/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 1011/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0094 - learning_rate: 1.5625e-05\n",
      "Epoch 1012/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0104 - learning_rate: 1.5625e-05\n",
      "Epoch 1013/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0100 - learning_rate: 1.5625e-05\n",
      "Epoch 1014/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1015/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 1016/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1017/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0098 - learning_rate: 1.5625e-05\n",
      "Epoch 1018/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0099 - learning_rate: 1.5625e-05\n",
      "Epoch 1019/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 1020/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0103 - learning_rate: 1.5625e-05\n",
      "Epoch 1021/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1022/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1023/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0094 - learning_rate: 1.5625e-05\n",
      "Epoch 1024/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0104 - learning_rate: 1.5625e-05\n",
      "Epoch 1025/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0102 - learning_rate: 1.5625e-05\n",
      "Epoch 1026/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 1027/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 1028/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0100 - learning_rate: 1.5625e-05\n",
      "Epoch 1029/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0103 - learning_rate: 1.5625e-05\n",
      "Epoch 1030/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0102 - learning_rate: 1.5625e-05\n",
      "Epoch 1031/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 1032/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1033/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0105 - learning_rate: 1.5625e-05\n",
      "Epoch 1034/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1035/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 1036/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1037/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0098 - learning_rate: 1.5625e-05\n",
      "Epoch 1038/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0094 - learning_rate: 1.5625e-05\n",
      "Epoch 1039/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0095 - learning_rate: 1.5625e-05\n",
      "Epoch 1040/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0101 - learning_rate: 1.5625e-05\n",
      "Epoch 1041/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0095 - learning_rate: 1.5625e-05\n",
      "Epoch 1042/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1043/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 1044/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0099 - learning_rate: 1.5625e-05\n",
      "Epoch 1045/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1046/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0113 - learning_rate: 1.5625e-05\n",
      "Epoch 1047/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 1048/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0094 - learning_rate: 1.5625e-05\n",
      "Epoch 1049/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0099 - learning_rate: 1.5625e-05\n",
      "Epoch 1050/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0095 - learning_rate: 1.5625e-05\n",
      "Epoch 1051/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0099 - learning_rate: 1.5625e-05\n",
      "Epoch 1052/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0094 - learning_rate: 1.5625e-05\n",
      "Epoch 1053/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0102 - learning_rate: 1.5625e-05\n",
      "Epoch 1054/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0101 - learning_rate: 1.5625e-05\n",
      "Epoch 1055/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0100 - learning_rate: 1.5625e-05\n",
      "Epoch 1056/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0099 - learning_rate: 1.5625e-05\n",
      "Epoch 1057/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0098 - learning_rate: 1.5625e-05\n",
      "Epoch 1058/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1059/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0095 - learning_rate: 1.5625e-05\n",
      "Epoch 1060/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0098 - learning_rate: 1.5625e-05\n",
      "Epoch 1061/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0093 - learning_rate: 1.5625e-05\n",
      "Epoch 1062/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0094 - learning_rate: 1.5625e-05\n",
      "Epoch 1063/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1064/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0095 - learning_rate: 1.5625e-05\n",
      "Epoch 1065/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 1066/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1067/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0116 - learning_rate: 1.5625e-05\n",
      "Epoch 1068/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0098 - learning_rate: 1.5625e-05\n",
      "Epoch 1069/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0094 - learning_rate: 1.5625e-05\n",
      "Epoch 1070/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0094 - learning_rate: 1.5625e-05\n",
      "Epoch 1071/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0099 - learning_rate: 1.5625e-05\n",
      "Epoch 1072/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0093 - learning_rate: 1.5625e-05\n",
      "Epoch 1073/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0101 - learning_rate: 1.5625e-05\n",
      "Epoch 1074/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0104 - learning_rate: 1.5625e-05\n",
      "Epoch 1075/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0112 - learning_rate: 1.5625e-05\n",
      "Epoch 1076/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0094 - learning_rate: 1.5625e-05\n",
      "Epoch 1077/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0093 - learning_rate: 1.5625e-05\n",
      "Epoch 1078/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0098 - learning_rate: 1.5625e-05\n",
      "Epoch 1079/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0099 - learning_rate: 1.5625e-05\n",
      "Epoch 1080/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 1081/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1082/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0094 - learning_rate: 1.5625e-05\n",
      "Epoch 1083/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0095 - learning_rate: 1.5625e-05\n",
      "Epoch 1084/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0095 - learning_rate: 1.5625e-05\n",
      "Epoch 1085/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0101 - learning_rate: 1.5625e-05\n",
      "Epoch 1086/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0095 - learning_rate: 1.5625e-05\n",
      "Epoch 1087/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0099 - learning_rate: 1.5625e-05\n",
      "Epoch 1088/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0111 - learning_rate: 1.5625e-05\n",
      "Epoch 1089/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0093 - learning_rate: 1.5625e-05\n",
      "Epoch 1090/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0099 - learning_rate: 1.5625e-05\n",
      "Epoch 1091/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0094 - learning_rate: 1.5625e-05\n",
      "Epoch 1092/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0094 - learning_rate: 1.5625e-05\n",
      "Epoch 1093/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0095 - learning_rate: 1.5625e-05\n",
      "Epoch 1094/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0094 - learning_rate: 1.5625e-05\n",
      "Epoch 1095/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 1096/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0100 - learning_rate: 1.5625e-05\n",
      "Epoch 1097/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0095 - learning_rate: 1.5625e-05\n",
      "Epoch 1098/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1099/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0095 - learning_rate: 1.5625e-05\n",
      "Epoch 1100/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 1101/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0107 - learning_rate: 1.5625e-05\n",
      "Epoch 1102/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0095 - learning_rate: 1.5625e-05\n",
      "Epoch 1103/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0101 - learning_rate: 1.5625e-05\n",
      "Epoch 1104/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0098 - learning_rate: 1.5625e-05\n",
      "Epoch 1105/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0093 - learning_rate: 1.5625e-05\n",
      "Epoch 1106/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0097 - learning_rate: 1.5625e-05\n",
      "Epoch 1107/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0095 - learning_rate: 1.5625e-05\n",
      "Epoch 1108/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0096 - learning_rate: 1.5625e-05\n",
      "Epoch 1109/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0093 - learning_rate: 1.5625e-05\n",
      "Epoch 1110/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0093 - learning_rate: 1.5625e-05\n",
      "Epoch 1111/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0105 - learning_rate: 1.5625e-05\n",
      "Epoch 1112/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0096 - learning_rate: 7.8125e-06\n",
      "Epoch 1113/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1114/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1115/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1116/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1117/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1118/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1119/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0095 - learning_rate: 7.8125e-06\n",
      "Epoch 1120/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0092 - learning_rate: 7.8125e-06\n",
      "Epoch 1121/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0098 - learning_rate: 7.8125e-06\n",
      "Epoch 1122/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0099 - learning_rate: 7.8125e-06\n",
      "Epoch 1123/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0096 - learning_rate: 7.8125e-06\n",
      "Epoch 1124/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1125/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1126/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1127/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0095 - learning_rate: 7.8125e-06\n",
      "Epoch 1128/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0099 - learning_rate: 7.8125e-06\n",
      "Epoch 1129/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1130/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1131/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0095 - learning_rate: 7.8125e-06\n",
      "Epoch 1132/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1133/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0102 - learning_rate: 7.8125e-06\n",
      "Epoch 1134/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1135/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0068 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1136/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1137/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0092 - learning_rate: 7.8125e-06\n",
      "Epoch 1138/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0092 - learning_rate: 7.8125e-06\n",
      "Epoch 1139/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1140/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1141/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1142/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0101 - learning_rate: 7.8125e-06\n",
      "Epoch 1143/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0097 - learning_rate: 7.8125e-06\n",
      "Epoch 1144/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0103 - learning_rate: 7.8125e-06\n",
      "Epoch 1145/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1146/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1147/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0105 - learning_rate: 7.8125e-06\n",
      "Epoch 1148/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0092 - learning_rate: 7.8125e-06\n",
      "Epoch 1149/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0068 - val_loss: 0.0092 - learning_rate: 7.8125e-06\n",
      "Epoch 1150/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0067 - val_loss: 0.0095 - learning_rate: 7.8125e-06\n",
      "Epoch 1151/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0067 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1152/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0068 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1153/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0067 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1154/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1155/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1156/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1157/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1158/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1159/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0096 - learning_rate: 7.8125e-06\n",
      "Epoch 1160/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0092 - learning_rate: 7.8125e-06\n",
      "Epoch 1161/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0096 - learning_rate: 7.8125e-06\n",
      "Epoch 1162/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0092 - learning_rate: 7.8125e-06\n",
      "Epoch 1163/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1164/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1165/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0092 - learning_rate: 7.8125e-06\n",
      "Epoch 1166/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1167/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1168/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1169/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1170/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0095 - learning_rate: 7.8125e-06\n",
      "Epoch 1171/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1172/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1173/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1174/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0095 - learning_rate: 7.8125e-06\n",
      "Epoch 1175/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0092 - learning_rate: 7.8125e-06\n",
      "Epoch 1176/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1177/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1178/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0095 - learning_rate: 7.8125e-06\n",
      "Epoch 1179/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0092 - learning_rate: 7.8125e-06\n",
      "Epoch 1180/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1181/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0067 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1182/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0095 - learning_rate: 7.8125e-06\n",
      "Epoch 1183/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0099 - learning_rate: 7.8125e-06\n",
      "Epoch 1184/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0099 - learning_rate: 7.8125e-06\n",
      "Epoch 1185/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1186/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0094 - learning_rate: 7.8125e-06\n",
      "Epoch 1187/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0093 - learning_rate: 7.8125e-06\n",
      "Epoch 1188/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0092 - learning_rate: 7.8125e-06\n",
      "Epoch 1189/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1190/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1191/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1192/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1193/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0095 - learning_rate: 3.9063e-06\n",
      "Epoch 1194/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1195/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0095 - learning_rate: 3.9063e-06\n",
      "Epoch 1196/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0094 - learning_rate: 3.9063e-06\n",
      "Epoch 1197/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1198/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 3.9063e-06\n",
      "Epoch 1199/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0094 - learning_rate: 3.9063e-06\n",
      "Epoch 1200/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1201/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 3.9063e-06\n",
      "Epoch 1202/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1203/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 3.9063e-06\n",
      "Epoch 1204/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0095 - learning_rate: 3.9063e-06\n",
      "Epoch 1205/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0096 - learning_rate: 3.9063e-06\n",
      "Epoch 1206/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0092 - learning_rate: 3.9063e-06\n",
      "Epoch 1207/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0092 - learning_rate: 3.9063e-06\n",
      "Epoch 1208/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1209/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1210/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 3.9063e-06\n",
      "Epoch 1211/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 3.9063e-06\n",
      "Epoch 1212/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 3.9063e-06\n",
      "Epoch 1213/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 3.9063e-06\n",
      "Epoch 1214/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0095 - learning_rate: 3.9063e-06\n",
      "Epoch 1215/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0094 - learning_rate: 3.9063e-06\n",
      "Epoch 1216/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 3.9063e-06\n",
      "Epoch 1217/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0092 - learning_rate: 3.9063e-06\n",
      "Epoch 1218/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0094 - learning_rate: 3.9063e-06\n",
      "Epoch 1219/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0094 - learning_rate: 3.9063e-06\n",
      "Epoch 1220/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1221/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0094 - learning_rate: 3.9063e-06\n",
      "Epoch 1222/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1223/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0097 - learning_rate: 3.9063e-06\n",
      "Epoch 1224/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1225/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 3.9063e-06\n",
      "Epoch 1226/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 3.9063e-06\n",
      "Epoch 1227/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1228/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0092 - learning_rate: 3.9063e-06\n",
      "Epoch 1229/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1230/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1231/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1232/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1233/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1234/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 3.9063e-06\n",
      "Epoch 1235/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0095 - learning_rate: 3.9063e-06\n",
      "Epoch 1236/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0094 - learning_rate: 3.9063e-06\n",
      "Epoch 1237/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0093 - learning_rate: 3.9063e-06\n",
      "Epoch 1238/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 3.9063e-06\n",
      "Epoch 1239/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1240/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1241/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1242/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1243/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1244/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1245/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-0s\u001b[0m -19246us/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1246/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1247/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1248/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1249/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1250/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1251/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1252/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1253/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1254/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1255/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1256/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1257/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1258/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1259/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1260/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1261/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1262/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0065 - val_loss: 0.0094 - learning_rate: 1.9531e-06\n",
      "Epoch 1263/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1264/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1265/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1266/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1267/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1268/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1269/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1270/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1271/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1272/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1273/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0094 - learning_rate: 1.9531e-06\n",
      "Epoch 1274/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1275/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1276/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1277/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1278/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1279/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1280/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1281/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0094 - learning_rate: 1.9531e-06\n",
      "Epoch 1282/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1283/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1284/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1285/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1286/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0093 - learning_rate: 1.9531e-06\n",
      "Epoch 1287/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1288/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.9531e-06\n",
      "Epoch 1289/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1290/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0093 - learning_rate: 1.0000e-06\n",
      "Epoch 1291/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1292/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1293/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1294/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1295/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1296/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1297/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1298/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1299/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1300/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0093 - learning_rate: 1.0000e-06\n",
      "Epoch 1301/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1302/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1303/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1304/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1305/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1306/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1307/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1308/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1309/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1310/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1311/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1312/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1313/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1314/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1315/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1316/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0093 - learning_rate: 1.0000e-06\n",
      "Epoch 1317/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1318/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1319/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1320/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1321/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1322/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1323/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1324/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1325/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1326/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1327/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1328/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1329/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1330/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1331/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1332/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1333/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1334/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0093 - learning_rate: 1.0000e-06\n",
      "Epoch 1335/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1336/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1337/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1338/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1339/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1340/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1341/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1342/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1343/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1344/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1345/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 1346/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "gnn_model, history = train_GNN(x_train=x_train,y_train=y_train_s, c_train=c_train,\n",
    "                           x_val=x_val,y_val=y_val_s,c_val=c_val,\n",
    "                           epochs=5000, verbose=1, threshold=1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00ba510a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHHCAYAAABeLEexAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAcXZJREFUeJzt3Xd4U9XjBvD3ZjRddEBpC6VQLMgWkA0y1LJFBARkyHJ8EVAQByKyRETkB+JAcLFUpiKIIFAqU/beS0ZZbVmlu804vz9Ck6ZN2yRNmzR5P8/DQ3PuuTcnp0Bfzjn3XEkIIUBERETkxmSObgARERGRozEQERERkdtjICIiIiK3x0BEREREbo+BiIiIiNweAxERERG5PQYiIiIicnsMREREROT2GIiIiIjI7TEQETmBIUOGICIiwqZzp0yZAkmS7NsgF2WuryIiIjBkyJBCz128eDEkScLVq1ft1p6rV69CkiQsXrzYbtckItswEBEVQJIki35t377d0U11KQkJCVAoFBg4cGC+dZKTk+Hl5YWePXuWYMtss2zZMsydO9fRzTAxZMgQ+Pr6OroZRE5D4egGEDmzn3/+2eT10qVLER0dnae8Vq1aRXqfH374ATqdzqZzP/roI3zwwQdFen9nExwcjPbt22PdunVIS0uDt7d3njpr1qxBRkZGgaHJEufPn4dMVrz/N1y2bBlOnTqFMWPGmJRXqVIF6enpUCqVxfr+RFQ4BiKiAuT+Ybtv3z5ER0cX+kM4vx/i+SnKD0SFQgGFwvX+Kg8YMACbNm3Cn3/+iZdeeinP8WXLlsHf3x9du3Yt0vuoVKoinV8UkiTB09PTYe9PREacMiMqonbt2qFu3bo4fPgw2rRpA29vb3z44YcAgHXr1qFr166oWLEiVCoVIiMjMW3aNGi1WpNr5F5DlL225P/+7//w/fffIzIyEiqVCk2aNMHBgwdNzjW3LkaSJIwaNQpr165F3bp1oVKpUKdOHWzatClP+7dv347GjRvD09MTkZGR+O677yxalzRq1Cj4+voiLS0tz7F+/fohNDTU8DkPHTqEjh07IigoCF5eXqhatSqGDRtW4PV79OgBHx8fLFu2LM+xhIQExMTE4MUXX4RKpcKuXbvQu3dvVK5cGSqVCuHh4Xj77beRnp5e4HsA5tcQnT59Gs888wy8vLxQqVIlfPLJJ2ZH8Cz5/rZr1w4bNmzAtWvXDFOs2d/r/NYQ/fPPP2jdujV8fHwQEBCA7t274+zZsyZ1sr9Hly5dwpAhQxAQEAB/f38MHTrU7PfEVqtXr0ajRo3g5eWFoKAgDBw4EDdv3jSpExcXh6FDh6JSpUpQqVSoUKECunfvbrLeypY/A0QlyfX+W0nkAPfu3UPnzp3x0ksvYeDAgQgJCQGgX4jr6+uLsWPHwtfXF//88w8mTZqEpKQkzJo1q9DrLlu2DMnJyfjf//4HSZLw+eefo2fPnrh8+XKho0q7d+/GmjVrMGLECJQpUwZfffUVevXqhdjYWJQrVw4AcPToUXTq1AkVKlTA1KlTodVq8fHHH6N8+fKFtq1v376YN28eNmzYgN69exvK09LSsH79egwZMgRyuRwJCQno0KEDypcvjw8++AABAQG4evUq1qxZU+D1fXx80L17d/z222+4f/8+ypYtazi2cuVKaLVaDBgwAID+h3ZaWhreeOMNlCtXDgcOHMDXX3+NGzduYPXq1YV+lpzi4uLw9NNPQ6PR4IMPPoCPjw++//57eHl55alryfd3woQJePjwIW7cuIEvvvgCAApcu7N161Z07twZjz32GKZMmYL09HR8/fXXaNWqFY4cOZJn8X2fPn1QtWpVzJgxA0eOHMGPP/6I4OBgzJw506rPbc7ixYsxdOhQNGnSBDNmzEB8fDy+/PJL/Pvvvzh69CgCAgIAAL169cLp06fx5ptvIiIiAgkJCYiOjkZsbKzhtS1/BohKlCAii40cOVLk/mvTtm1bAUAsWLAgT/20tLQ8Zf/73/+Et7e3yMjIMJQNHjxYVKlSxfD6ypUrAoAoV66cuH//vqF83bp1AoBYv369oWzy5Ml52gRAeHh4iEuXLhnKjh8/LgCIr7/+2lDWrVs34e3tLW7evGkou3jxolAoFHmumZtOpxNhYWGiV69eJuWrVq0SAMTOnTuFEEL88ccfAoA4ePBggdczZ8OGDQKA+O6770zKmzdvLsLCwoRWqxVCmO/nGTNmCEmSxLVr1wxl5vqqSpUqYvDgwYbXY8aMEQDE/v37DWUJCQnC399fABBXrlwxlFv6/e3atavJ9zdb9vd50aJFhrIGDRqI4OBgce/ePUPZ8ePHhUwmE4MGDcrzWYYNG2ZyzR49eohy5crlea/cBg8eLHx8fPI9npWVJYKDg0XdunVFenq6ofyvv/4SAMSkSZOEEEI8ePBAABCzZs3K91pF+TNAVFI4ZUZkByqVCkOHDs1TnnNUITk5GXfv3kXr1q2RlpaGc+fOFXrdvn37IjAw0PC6devWAIDLly8Xem5UVBQiIyMNr5944gn4+fkZztVqtdi6dSteeOEFVKxY0VCvWrVq6Ny5c6HXlyQJvXv3xsaNG5GSkmIoX7lyJcLCwvDUU08BgGEU4a+//oJarS70ujlljyrknDa7cuUK9u3bh379+hkWQ+fs59TUVNy9exctW7aEEAJHjx616j03btyI5s2bo2nTpoay8uXLG0ajcirq9ze327dv49ixYxgyZIjJiNgTTzyB9u3bY+PGjXnOGT58uMnr1q1b4969e0hKSrL6/XM6dOgQEhISMGLECJN1Tl27dkXNmjWxYcMGAPo+8PDwwPbt2/HgwQOz1yrKnwGiksJARGQHYWFh8PDwyFN++vRp9OjRA/7+/vDz80P58uUNC7IfPnxY6HUrV65s8jo7HOX3g6egc7PPzz43ISEB6enpqFatWp565srM6du3L9LT0/Hnn38CAFJSUrBx40b07t3bsAapbdu26NWrF6ZOnYqgoCB0794dixYtQmZmZqHXVygU6Nu3L3bt2mVYt5IdjnIGlNjYWEOI8PX1Rfny5dG2bVsAlvVzTteuXUP16tXzlNeoUSNPWVG/v+beO7/3qlWrFu7evYvU1FST8qL8GbG1LTVr1jQcV6lUmDlzJv7++2+EhISgTZs2+PzzzxEXF2eoX5Q/A0QlhYGIyA7MrS9JTExE27Ztcfz4cXz88cdYv349oqOjDWs7LLnNXi6Xmy0XQhTruZZq3rw5IiIisGrVKgDA+vXrkZ6ejr59+xrqSJKE3377DXv37sWoUaNw8+ZNDBs2DI0aNTIZWcrPwIEDodPpsHz5cgDA8uXLUbt2bTRo0ACAfqSrffv22LBhA8aNG4e1a9ciOjrasFDZ1u0MCmOP7689lMT3uTBjxozBhQsXMGPGDHh6emLixImoVauWYXSuqH8GiEoCAxFRMdm+fTvu3buHxYsXY/To0XjuuecQFRVlMgXmSMHBwfD09MSlS5fyHDNXlp8+ffpg06ZNSEpKwsqVKxEREYHmzZvnqde8eXNMnz4dhw4dwq+//orTp09jxYoVhV6/WbNmiIyMxLJly3D8+HGcPn3aZHTo5MmTuHDhAmbPno1x48ahe/fuiIqKMpkGtEaVKlVw8eLFPOXnz583eW3N99fSncSrVKli9r0A4Ny5cwgKCoKPj49F1yqqgtpy/vx5w/FskZGReOedd7BlyxacOnUKWVlZmD17tkkdW/8MEJUEBiKiYpL9P/ec/1PPysrCt99+66gmmZDL5YiKisLatWtx69YtQ/mlS5fw999/W3ydvn37IjMzE0uWLMGmTZvQp08fk+MPHjzIM1qRPbpj6ZTJgAEDcPToUUyePBmSJKF///4mnwMw7WchBL788kuLP0NOXbp0wb59+3DgwAFD2Z07d/Drr7+a1LPm++vj42PRFFqFChXQoEEDLFmyBImJiYbyU6dOYcuWLejSpYu1H8dmjRs3RnBwMBYsWGDyffr7779x9uxZw/5PaWlpyMjIMDk3MjISZcqUMZxnjz8DRMWNt90TFZOWLVsiMDAQgwcPxltvvQVJkvDzzz+X6FRGYaZMmYItW7agVatWeOONN6DVavHNN9+gbt26OHbsmEXXePLJJ1GtWjVMmDABmZmZJtNlALBkyRJ8++236NGjByIjI5GcnIwffvgBfn5+Fv+AHzhwID7++GOsW7cOrVq1Mrn1vGbNmoiMjMS7776Lmzdvws/PD7///rvNa2jef/99/Pzzz+jUqRNGjx5tuO2+SpUqOHHihKGeNd/fRo0aYeXKlRg7diyaNGkCX19fdOvWzez7z5o1C507d0aLFi3wyiuvGG679/f3x5QpU2z6TPlRq9X45JNP8pSXLVsWI0aMwMyZMzF06FC0bdsW/fr1M9x2HxERgbfffhsAcOHCBTz77LPo06cPateuDYVCgT/++APx8fGGDTXt8WeAqNg55uY2otIpv9vu69SpY7b+v//+K5o3by68vLxExYoVxfvvvy82b94sAIht27YZ6uV32725W5kBiMmTJxte53fb/ciRI/Ocm/sWcyGEiImJEQ0bNhQeHh4iMjJS/Pjjj+Kdd94Rnp6e+fRCXhMmTBAARLVq1fIcO3LkiOjXr5+oXLmyUKlUIjg4WDz33HPi0KFDFl9fCCGaNGkiAIhvv/02z7EzZ86IqKgo4evrK4KCgsRrr71m2GYg5y3tltx2L4QQJ06cEG3bthWenp4iLCxMTJs2Tfz00095bru39PubkpIi+vfvLwICAgQAw/fa3G33QgixdetW0apVK+Hl5SX8/PxEt27dxJkzZ0zqZH+WO3fumJQvWrQoTzvNGTx4sABg9ldkZKSh3sqVK0XDhg2FSqUSZcuWFQMGDBA3btwwHL97964YOXKkqFmzpvDx8RH+/v6iWbNmYtWqVYY69vozQFScJCGc6L+rROQUXnjhBZw+fdrsWhoiIlfENUREbi734y0uXryIjRs3ol27do5pEBGRA3CEiMjNVahQAUOGDMFjjz2Ga9euYf78+cjMzMTRo0fN7sdDROSKuKiayM116tQJy5cvR1xcHFQqFVq0aIFPP/2UYYiI3ApHiIiIiMjtcQ0RERERuT0GIiIiInJ7breGSKfT4datWyhTpozF2+kTERGRYwkhkJycjIoVK0Ims/94jtsFolu3biE8PNzRzSAiIiIbXL9+HZUqVbL7dd0uEJUpUwaAvkP9/Pzsem21Wo0tW7agQ4cOUCqVdr12acO+MGJfGLEvjNgXRuwLI/aFUe6+SEpKQnh4uOHnuL25XSDKnibz8/MrlkDk7e0NPz8//kFmXxiwL4zYF0bsCyP2hRH7wii/viiu5S5cVE1ERERuj4GIiIiI3B4DEREREbk9t1tDRERErkWr1UKtVju6GXahVquhUCiQkZEBrVbr6OaUOA8Pj2K5pd4SDERERFQqCSEQFxeHxMRERzfFboQQCA0NxfXr191yrzyZTIaqVavCw8OjxN+bgYiIiEql7DAUHBwMb29vlwgQOp0OKSkp8PX1ddhIiaNkb5x8+/ZtVK5cucTfn4GIiIhKHa1WawhD5cqVc3Rz7Ean0yErKwuenp5uF4gAoHz58rh16xY0Gk2Jv7f79TYREZV62WuGvL29HdwSsqfsqTJHrJ9iICIiolLLFabJyMiR308GIiIiInJ7DERERESlXEREBObOnevoZpRqDEREREQlRJKkAn9NnTrVpusePHgQr7/+epHa1q5dO4wZM6ZI1yjNHBqIdu7ciW7duqFixYqQJAlr164t9Jzt27fjySefhEqlQrVq1bB48eJib6elHqRl4WGW8bVGq3NcY4iIyOncvn3b8Gvu3Lnw8/MzKXvnnXcMdYUQFt9tVb58eS4wLyKHBqLU1FTUr18f8+bNs6j+lStX0LVrVzz99NM4duwYxowZg1dffRWbN28u5pYW7t9Ld9H5qz1Y/p8Mp28lYfG/V1Btwt9Yd+ymo5tGREROIjQ01PDL398fkiQZXp87dw7+/v6Ijo5GkyZNoFKpsHv3bvz333/o3r07QkJC4OvriyZNmmDr1q0m1809ZSZJEn788Uf06NED3t7eqF69Ov78888itf33339HnTp1oFKpEBERgdmzZ5sc//bbb1G9enV4enoiJCQEL774ouHYb7/9hnr16sHLywvlypVDVFQUUlNTi9Qee3PoPkSdO3dG586dLa6/YMECVK1a1fBNqFWrFnbv3o0vvvgCHTt2LK5mWiTET4WkDDXupcrwwvx9hvLRK45h5t/n8L+2kagW7AtvDznSs7RYf+I2PJUyPFMzGOV8VLiXmonbiRmoGOCFquV9kJ6lQZZGYPPpONSqUAYtIoMQ9zAD8UkZqBjgiTeXH8Pwto+he4MwB35qIiLnIYRAutoxj7vwUsrtdofU1KlTMXv2bFSrVg2BgYG4fv06unTpgunTp0OlUmHp0qXo1q0bzp8/X+AGhlOnTsXnn3+OWbNm4euvv8aAAQNw7do1lC1b1uo2HT58GH369MGUKVPQt29f7NmzByNGjEC5cuUwZMgQHDp0CG+99RZ+/vlntGzZEvfv38euXbsA6EfF+vXrh88//xw9evRAcnIydu3aBSGEzX1UHErVxox79+5FVFSUSVnHjh0LnPPMzMxEZmam4XVSUhIA/R4W9nz2TZVAT7zRJgJfbbuS59ithxmY/Odps+ct+veqze85esUxnLv9EK+2ioCfl9Lm6xSH7L51lecLFQX7woh9YcS+MLKlL9RqNYQQ0Ol00On0yxPSsjSoOyW6WNpYmFNT2sPbw7ofqdntzv37hx9+iKioKEPACggIQL169QznTZ06FX/88QfWrVuHkSNHGsqz+yPb4MGD0bdvXwDAJ598gq+++gr79u1Dp06d8m1T7mtkmz17Np555hlMmDABAFCtWjWcPn0as2bNwqBBg3D16lX4+PigS5cuKFOmDMLDw1G/fn3odDrcvHkTGo0GL7zwgiHA1alTx+Qz5+wTIQTUarXhWEn9XSlVgSguLg4hISEmZSEhIUhKSkJ6ejq8vLzynDNjxgyzi9S2bNli9/nWCB3QOlSGXXHGmchqfjpcSpKhgpeARgBaASgkICFD/wc92FMgWQ34ewC+SoHbaRJSNRIUkoBGFP6/jfk7ruDvw5cxpq4WzrgdR3S0Y/5xckbsCyP2hRH7wsiavlAoFAgNDUVKSgqysvSLN9OzHPcw1OSkZGg85Fadk5GRASGE4T/qaWlpAIAGDRogOTnZUC8lJQUzZ87Eli1bEBcXB61Wi/T0dFy8eNFwrk6nQ0ZGhuE1oA8tOV+XKVMGsbGxJmU5aTQaZGVlmT1++vRpdOnSxeRYw4YN8eWXX+LBgwdo1qwZKlWqhMjISDz77LN49tln8dxzz8Hb2xtVq1ZF27ZtUb9+fTzzzDN4+umn0b17dwQEBOR5n6ysLKSnp2Pnzp2G9VPZfy6y+6e4lKpAZIvx48dj7NixhtdJSUkIDw9Hhw4d4OfnZ9f3UqvVkEdH47vXn4VSafuIjVYnIJdJ0OkEZDIJmWot1DqB5AwNZBJw+W4qtp+/i9sPM/D36XhcTZEQ61sTvRuFIchXZcdPZDu1Wo3o6Gi0b9++SH3hCtgXRuwLI/aFkS19kZGRgevXr8PX1xeenp4AgDJC4NSU9sXZ1HzZMmXm6ekJSZIMP4uy/5Pu4+ODMmXKGK43btw4bN26FZ9//jmqVasGLy8v9OnTx+RcmUwGT09Pk59rfn5+Jq9lMhk8PDzy/dmnUCjyPS6Xy6FSqUyOZQ9C+Pn5ITAwEEePHsX27dsRHR2NmTNnYtasWdi/fz8CAwMRExODPXv2IDo6Gj/99BOmT5+OvXv3omrVqibvk5GRAS8vL7Rp0wZyudzkz0V+Qc5eSlUgCg0NRXx8vElZfHw8/Pz8zI4OAYBKpYJKlTckKJXKYvtHqKjXzn1m9rUCffWvK5UrgzY1QgEA3ef9i+PXEzFn6yVsOBmPzW+3sfl9i0Nx9nNpw74wYl8YsS+MrOkLrVYLSZIgk8lMnvnlK7dulMaRstud+3cAhs8GAHv27MGQIUPQq1cvAPoRo6tXr6Jdu3b5npN9vdzPQzNXllPua2SrVasW9uzZY3Js7969ePzxxw3fMw8PD3To0AEdOnTAlClTEBAQgO3bt6Nnz54AgNatW6N169aYPHkyqlSpgnXr1pkMWGS3T5IkKJVKyB99L7P/XBT335NSFYhatGiBjRs3mpRFR0ejRYsWDmqR43nIjf8jOR+fXEBNIiIqjapXr441a9agW7dukCQJEydONLvOxx7u3LmDY8eOmZRVqFAB77zzDpo0aYJp06ahb9++2Lt3L7755ht8++23AIC//voLly9fRps2bRAYGIiNGzdCp9OhRo0a2L9/P2JiYtChQwcEBwdj//79uHPnDmrVqlUsn8FWDg1EKSkpuHTpkuH1lStXcOzYMZQtWxaVK1fG+PHjcfPmTSxduhQAMHz4cHzzzTd4//33MWzYMPzzzz9YtWoVNmzY4KiP4HASnHDhEBER2c2cOXMwbNgwtGzZEkFBQRg3blyxTR8tW7YMy5YtMymbNm0aPvroI6xatQqTJk3CtGnTUKFCBXz88ccYMmQIAP3C7zVr1mDKlCnIyMhA9erVsXz5ctSpUwdnz57Fzp07MXfuXCQlJaFKlSqYPXu2VXeZlwSHBqJDhw7h6aefNrzOHjobPHgwFi9ejNu3byM2NtZwvGrVqtiwYQPefvttfPnll6hUqRJ+/PFHh99y7yxUCm48TkRUWgwZMsQQKAD9TtFarTZP2ImIiMA///xjUpbz7jIAuHr1qslrc7e0JyYmFtie7du3F3i8V69ehmm73J566ql8z69VqxY2bdpU4LWdgUMDUbt27Qrch8DcLtTt2rXD0aNHi7FVpYuAsf8qBZpfR0VEREQF45BCKZczT2ao+agQIiIiWzAQlXLVQ8oYvs7UMBARERHZgoGolPugU000f0y/DXumg7asJyIiKu0YiEo5f28lvujbAACQoWEgIiIisgUDkQtQKfSbV6m1Alqdcz0sj4iIqDRgIHIBnkrjtzGTo0RERERWYyByAZ4K41b1vNOMiIjIegxELkAmk+Ah138rM7iwmoiIyGoMRC4ie5dq3npPROT62rVrhzFjxji6GS6FgchFqJT6aTOOEBEROa9u3bqhU6dOZo/t2rULcrkcp06dKvL7LF68GAEBAUW+jjthIHIR2QurGYiIiJzXK6+8gujoaNy4cSPPsUWLFqFx48aoW7euA1pGDEQuInvKjIuqiYic13PPPYfy5cvneVZnSkoKVq9ejaFDh+L+/fvo378/wsLC4O3tjXr16mH58uV2bUdsbCy6d+8OX19f+Pn5oU+fPoiPjzccP378OJ5++mmUKVMGfn5+aNSoEQ4dOgQAuHbtGrp164bAwED4+PigTp062Lhxo13b5wgOfbgr2Y/noykz3nZPRG5LCECd5pj3VnoDklRoNYVCgUGDBmHx4sWYMGECpEfnrF69GlqtFv369cPt27fRqFEjfPDBB/Dz88OGDRvw8ssvIzIyEk2bNi1yU3U6nSEM7dixAxqNBiNHjkTfvn0NT6wfMGAAGjZsiPnz50Mul+PYsWNQKpUAgJEjRyIrKws7d+6Ej48Pzpw5A19f3yK3y9EYiFyEp2ENEUeIiMhNqdOATys65r0/vAV4+FhUddiwYZg1axZ27NiBdu3aAdBPl/Xq1Qv+/v6QJAnvvPMOZDL9yP+bb76JzZs3Y9WqVXYJRDExMTh58iSuXLmC8PBwAMDSpUtRp04dHDx4EE2aNEFsbCzee+891KxZEwBQvXp1w/mxsbHo1asX6tWrBwB47LHHitwmZ8ApMxeRvYaII0RERM6tZs2aaNmyJRYuXAgAuHTpEnbt2oVXXnkFAKDVavHJJ5+gXr16KFu2LHx9fbF582bExsba5f3Pnj2L8PBwQxgCgNq1ayMgIABnz54FAIwdOxavvvoqoqKi8Nlnn+G///4z1H3rrbfwySefoFWrVpg8eTJOnDhhl3Y5GkeIXET2PkS87Z6I3JbSWz9S46j3tsIrr7yCN998E/PmzcOiRYsQGRmJtm3bQgiBr776CvPmzcPcuXNRr149+Pj4YMyYMcjKyiqmxuc1ZcoU9O/fHxs2bMDff/+NyZMnY8WKFejRowdeffVVdOzYERs2bMCWLVswY8YMzJ49G2+++WaJta84cITIRchl+nloIfgsMyJyU5Kkn7ZyxC8L1g/l1KdPH8hkMixbtgxLly7FsGHDDOuJ9u/fj+effx4DBw5E/fr18dhjj+HChQt266ZatWrh+vXruH79uqHszJkzSExMRO3atQ1ljz/+ON5++21s2bIFPXv2xKJFiwzHwsPDMXz4cKxZswbvvPMOfvjhB7u1z1E4QuQisv8i8dmuRETOz9fXF3379sX48eORlJSEIUOGGI5FRkZi/fr12LNnDwIDAzFnzhzEx8ebhBVLaLVaHDt2zKRMpVIhKioK9erVw4ABAzB37lxoNBqMGDECbdu2RePGjZGeno733nsPL774IqpWrYobN27g4MGD6NWrFwBgzJgx6Ny5Mx5//HE8ePAA27ZtQ61atYraJQ7HQOQiHg0QQccRIiKiUuGVV17BTz/9hC5duqBiReNi8HfffRc3btxAx44d4e3tjddffx0vvPACHj58aNX1U1JS0LBhQ5OyyMhIXLp0CevWrcObb76JNm3aQCaToVOnTvj6668BAHK5HPfu3cOgQYMQHx+PoKAg9OzZE1OnTgWgD1ojR47EjRs34Ofnh06dOuGLL74oYm84HgORi5BxhIiIqFRp0aKF2WUOgYGB+OOPPwx3mZmTfXt8foYMGWIy6pRb5cqVsW7dOrPHPDw8Ctz3KDs4uRquIXIR2YGIa4iIiIisx0DkIrLX8+k4RERERGQ1BiIXwSkzIiIi2zEQuQguqiYiIrIdA5GLMK4hcnBDiIhKENdNuhZHfj8ZiFyEcR8i/uNARK4v+0GjaWkOepgrFYvs3bjlcnmJvzdvu3cRxikzx7aDiKgkyOVyBAQEICEhAQDg7e1t+I9haabT6ZCVlYWMjIwCb7t3RTqdDnfu3IG3tzcUCgU0Gk2Jvj8DkYuQcYSIiNxMaGgoABhCkSsQQiA9PR1eXl4uEfCsJZPJULlyZYd8dgYiF5H9HwnOpxORu5AkCRUqVEBwcDDUarWjm2MXarUaO3fuRJs2bQzTgu7Ew8PDYSNjDEQugs8yIyJ3JZfLHbLmpDjI5XJoNBp4enq6ZSByJPeaoHRhvO2eiIjIdgxELoIbMxIREdmOgchF8FlmREREtmMgchESp8yIiIhsxkDkIjhlRkREZDsGIhfBRdVERES2YyByEXyWGRERke0YiFyEYR8izpkRERFZjYHIRfBZZkRERLZjIHIRfJYZERGR7RiIXET2CBH3ISIiIrIeA5GL4LPMiIiIbMdA5CKyp8y0HCEiIiKyGgORi+CUGRERke0YiFyETJZ9272DG0JERFQKMRC5CD7LjIiIyHYMRC5CzkXVRERENmMgchHGR3cwEREREVmLgchFcMqMiIjIdgxELkLGKTMiIiKbMRC5CBlHiIiIiGzGQOQism+7Zx4iIiKyHgORi5D4cFciIiKbMRC5CE6ZERER2Y6ByEVwUTUREZHtGIhcBJ9lRkREZDuHB6J58+YhIiICnp6eaNasGQ4cOFBg/blz56JGjRrw8vJCeHg43n77bWRkZJRQa52XxBEiIiIimzk0EK1cuRJjx47F5MmTceTIEdSvXx8dO3ZEQkKC2frLli3DBx98gMmTJ+Ps2bP46aefsHLlSnz44Ycl3HLnI+OiaiIiIps5NBDNmTMHr732GoYOHYratWtjwYIF8Pb2xsKFC83W37NnD1q1aoX+/fsjIiICHTp0QL9+/QodVXIHxkXVjm0HERFRaaRw1BtnZWXh8OHDGD9+vKFMJpMhKioKe/fuNXtOy5Yt8csvv+DAgQNo2rQpLl++jI0bN+Lll1/O930yMzORmZlpeJ2UlAQAUKvVUKvVdvo0MFwz5+8lSafTAQC0Wp1D3j83R/aFs2FfGLEvjNgXRuwLI/aFUe6+KO4+kYSDVuHeunULYWFh2LNnD1q0aGEof//997Fjxw7s37/f7HlfffUV3n33XQghoNFoMHz4cMyfPz/f95kyZQqmTp2ap3zZsmXw9vYu+gdxEofvSlh6UY7H/XUYWVvn6OYQERHZVVpaGvr374+HDx/Cz8/P7td32AiRLbZv345PP/0U3377LZo1a4ZLly5h9OjRmDZtGiZOnGj2nPHjx2Ps2LGG10lJSQgPD0eHDh3s3qFqtRrR0dFo3749lEqlXa9dGHEyDksvnkDZsuXQpUuTEn1vcxzZF86GfWHEvjBiXxixL4zYF0a5+yJ7hqe4OCwQBQUFQS6XIz4+3qQ8Pj4eoaGhZs+ZOHEiXn75Zbz66qsAgHr16iE1NRWvv/46JkyYAJks75IolUoFlUqVp1ypVBbbH7bivHa+76nQfysFJKf6S+SIvnBW7Asj9oUR+8KIfWHEvjDK7ovi7g+HLar28PBAo0aNEBMTYyjT6XSIiYkxmULLKS0tLU/okcvlALj/jnEfIse2g4iIqDRy6JTZ2LFjMXjwYDRu3BhNmzbF3LlzkZqaiqFDhwIABg0ahLCwMMyYMQMA0K1bN8yZMwcNGzY0TJlNnDgR3bp1MwQjd8VnmREREdnOoYGob9++uHPnDiZNmoS4uDg0aNAAmzZtQkhICAAgNjbWZEToo48+giRJ+Oijj3Dz5k2UL18e3bp1w/Tp0x31EZwGn2VGRERkO4cvqh41ahRGjRpl9tj27dtNXisUCkyePBmTJ08ugZaVLnyWGRERke0c/ugOso/sgTR3X0tFRERkCwYiF8FnmREREdmOgchFZE+Znbz5EPdSMgupTURERDkxELmI7EXVAPDJhrOOawgREVEpxEDkIrJHiADg+v00B7aEiIio9GEgKg46LZCZXKJvmSMP8dZ7IiIiKzn8tntXIh1ZggbX1kK+cjFweRtQJhSo0QV4bk6xv3fOESIiIiKyDgORHSn+fgdVAOD+o4Lk28Chn4Br/wJNXwdkcqBcdaBSEyAzCfAKBLRZQMIZYO884FIM0PlzICAc0KqBqm2A038ANw4CLd8EFJ7Aqd8BnQbYOgVoNQao9RwQWs8kEHF8iIiIyDoMRCXhzjlgw1jL6v7xuvnyfd/mLdvxmf7X4PWQSXUNxZwxIyIisg7XENmLTue4917SDRLHhYiIiGzGQGQvWSmGL7VtPjBfp+VbQNQUQOEFKH2M5WUqAP7h+q+jpgD9VgLPTAT8wvRlCk8gpG7uq5nwTIk1fM1oREREZB1OmdnLo0Ckgxy6p96BvHJT4M+3gDbvAhFPAb4hgKefvu5Tbz86J1UfdmRy/TxXzoXRNTrpz02OA3yC9c/m0GqApJuAQqW/k215XyDuJADA595pAIH6czlnRkREZBUGInvJ1AcijdxT/xiNas8CY08XfI5HjlGi/O4SKxNq/FquAAKrGF8P3w183w64dRTe904BaA2AI0RERETW4pSZvWTp9x3SyDxL9n2fHAQA8HpwvmTfl4iIyIVwhMheJDl0FRogKRUoV5Lv+2idkSItwVDEGTMiIiLrcITIXio2gHbYVuyPtPD2envxDQYAKNLvGIoEJ82IiIiswkBU2vmGAAAU6XchQX/rP0eIiIiIrMNAVNr5BAMevpCEFu1kxwEwEBEREVmLgai0kyuA8GYAgJfk2wDwLjMiIiJrMRC5gjovAADKS4kObQYREVFpxUDkCgKrAgD8kQoAEJwzIyIisgoDkSvw0u9Q7SelOrghREREpRMDkSvwCgCQPUIkuKiaiIjISgxErsDTHwDgIWnhiSwHN4aIiKj0YSByBQrj40I8oObGjERERFZiIHIFMgUE9A+H9UYmp8yIiIisxEDkCiQJkHsAAPZ5von+mSsc3CAiIqLShYHIVciVhi+HZi5zYEOIiIhKHwYiFyEejRARERGR9RiIXAUDERERkc0YiFwFAxEREZHNGIhchJApC69EREREZjEQuQqOEBEREdmMgchFyJUqRzeBiIio1GIgchUcISIiIrIZA5GrYCAiIiKyGQORq5BzUTUREZGtGIhcBUeIiIiIbMZA5Cpkcke3gIiIqNRiIHIVEr+VREREtuJPUVfBESIiIiKbMRC5ComBiIiIyFYMRK6CI0REREQ2YyByFRwhIiIishkDkavgCBEREZHNGIhcBe8yIyIishl/irqKXCNEOp1wUEOIiIhKHwYiV5FrDZGGgYiIiMhiDESuIvcIkWAgIiIishQDkavgCBEREZHNGIhcBUeIiIiIbMZA5Cpy3WUmdA5qBxERUSnEQOQqOEJERERkMwYiVyExEBEREdmKgchV5Bohkt06AjAUERERWYSByFXkGiEKXNYJOLzYMW0hIiIqZRweiObNm4eIiAh4enqiWbNmOHDgQIH1ExMTMXLkSFSoUAEqlQqPP/44Nm7cWEKtdWIyM9/Koz+XfDuIiIhKIYW1JyQmJuKPP/7Arl27cO3aNaSlpaF8+fJo2LAhOnbsiJYtW1p8rZUrV2Ls2LFYsGABmjVrhrlz56Jjx444f/48goOD89TPyspC+/btERwcjN9++w1hYWG4du0aAgICrP0YrodPuyciIrKZxSNEt27dwquvvooKFSrgk08+QXp6Oho0aIBnn30WlSpVwrZt29C+fXvUrl0bK1eutOiac+bMwWuvvYahQ4eidu3aWLBgAby9vbFw4UKz9RcuXIj79+9j7dq1aNWqFSIiItC2bVvUr1/f0o/huvi0eyIiIptZPELUsGFDDB48GIcPH0bt2rXN1klPT8fatWsxd+5cXL9+He+++26+18vKysLhw4cxfvx4Q5lMJkNUVBT27t1r9pw///wTLVq0wMiRI7Fu3TqUL18e/fv3x7hx4yCXmw8EmZmZyMzMNLxOSkoCAKjVaqjV6kI/tzWyr2fv61pCJoDcPaDT6aB1QFsAx/aFs2FfGLEvjNgXRuwLI/aFUe6+KO4+kYSw7Fake/fuoVy5chZfuLD6t27dQlhYGPbs2YMWLVoYyt9//33s2LED+/fvz3NOzZo1cfXqVQwYMAAjRozApUuXMGLECLz11luYPHmy2feZMmUKpk6dmqd82bJl8Pb2tvjzOLvHEjaj3s1fTcoeeD+GnTWmOKZBREREdpSWlob+/fvj4cOH8PPzs/v1LR4hsiYM2VLfEjqdDsHBwfj+++8hl8vRqFEj3Lx5E7Nmzco3EI0fPx5jx441vE5KSkJ4eDg6dOhg9w5Vq9WIjo5G+/btoVQq7XrtwsgO3gJumpb5+/ujS5cuJdqObI7sC2fDvjBiXxixL4zYF0bsC6PcfZE9w1NcrFpUPWLECHz++efw9fUFACxfvhzPP/88fHx8AOgXXPfv39+iu76CgoIgl8sRHx9vUh4fH4/Q0FCz51SoUAFKpdJkeqxWrVqIi4tDVlYWPDw88pyjUqmgUqnylCuVymL7w1ac1y7gTfMUySQJMgf/hXJIXzgp9oUR+8KIfWHEvjBiXxhl90Vx94dVt91/9913SEtLM7z+3//+ZxJoMjMzsXnzZouu5eHhgUaNGiEmJsZQptPpEBMTYzKFllOrVq1w6dIl6HTGB3VduHABFSpUMBuG3Iqld5mdXQ8c4e34REREOVkViHIvN7Jw+VG+xo4dix9++AFLlizB2bNn8cYbbyA1NRVDhw4FAAwaNMhk0fUbb7yB+/fvY/To0bhw4QI2bNiATz/9FCNHjixSO1yCpXeZrRwI/DkKeHCteNtDRERUili9D5E99e3bF3fu3MGkSZMQFxeHBg0aYNOmTQgJCQEAxMbGQpZjw8Hw8HBs3rwZb7/9Np544gmEhYVh9OjRGDdunKM+gvMwO0JUQGBNvw8EVim25hAREZUmDg1EADBq1CiMGjXK7LHt27fnKWvRogX27dtXzK0qhazdh2jLRMAnCHhxESBJxdMmIiKiUsLqQDRp0iTD7epZWVmYPn06/P39AcBkfRGVMMnKp7Bc3aX/veVbQNiT9m8PERFRKWJVIGrTpg3Onz9veN2yZUtcvnw5Tx1yALOBKNfIj7k1XzpNsTSHiIioNLEqEJmbwiInYcm0VxEXwRMREbkquzztXqPRICUlxR6XIltZMmUmdIXXISIickNWBaL169dj8eLFJmXTp0+Hr68vAgIC0KFDBzx48MCe7SNLmQ1EuUeEOEJERERkjlWBaM6cOUhNTTW83rNnDyZNmoSJEydi1apVuH79OqZNm2b3RpIFLBohMheIeIcZERGRVYHo9OnTaNmypeH1b7/9hvbt22PChAno2bMnZs+ejfXr19u9kWQBi+4y4wgRERGROVYFouTkZJOHtu7evRvPPvus4XWdOnVw69Yt+7WOLGdmY8Y88aeARdUxZ+PRfs4OnLr50L7tIiIiKgWsCkRhYWE4e/YsACAlJQXHjx83GTG6d++eYY8iKmFmRogepGblKsk/EL2y5BAuJqTg9aWH7NwwIiIi52dVIOrduzfGjBmDn3/+Ga+99hpCQ0PRvHlzw/FDhw6hRo0adm8kWcBMILqXOxBZcNt9Sib3JSIiIvdj1T5EkyZNws2bN/HWW28hNDQUv/zyC+Ry41TN8uXL0a1bN7s3kixgbh+iXAFox4UEtC2h5hAREZUmVgUiLy8vLF26NN/j27ZtK3KDyEYWLKp+45fDOONZAm0hIiIqZeyyMSM5AQsCkcS7zIiIiMyyaoTomWeesajeP//8Y1NjqAjMBKKc8UcIwUBERESUD6ufZValShV07doVSqWyuNpEtpDlve0+Q61FpkYLlUIOnQBkDERERERmWRWIZs6ciUWLFmH16tUYMGAAhg0bhrp16xZX28ga+UyZffPPJbzToQaEEODGjEREROZZtYbovffew5kzZ7B27VokJyejVatWaNq0KRYsWICkpKTiaiNZIp9AtP38HQCATvAhHURERPmxaVF1ixYt8MMPP+D27dsYOXIkFi5ciIoVKzIUOVI+gSj7bnwd1xARERHlq0h3mR05cgQ7duzA2bNnUbduXa4rciRz+xDBdFSIgYiIiMg8qwPRrVu38Omnn+Lxxx/Hiy++iLJly2L//v3Yt28fvLy8iqONZIn8brt/FJR0QuAJ2ZUSbBAREVHpYdWi6i5dumDbtm3o0KEDZs2aha5du0KhsOoSVFzymzJ79LtOAEs8ZpZce4iIiEoRq9LMpk2bUKFCBcTGxmLq1KmYOnWq2XpHjhyxS+PICvkEItmjRCQseI4ZwPvQiIjIPVkViCZPnlxc7aCikvLuQyRBQMqeMtMx6hAREeWHgchVFDJlJoTOssvYqTlERESlCZ9l5ioKue1eWDhCxHEkIiJyRxYHok6dOmHfvn2F1ktOTsbMmTMxb968IjWMrJRvIMqeMtOWZGuIiIhKFYunzHr37o1evXrB398f3bp1Q+PGjVGxYkV4enriwYMHOHPmDHbv3o2NGzeia9eumDVrVnG2m3IrZB8iYeHYD6fMiIjIHVkciF555RUMHDgQq1evxsqVK/H999/j4cOHAPSjELVr10bHjh1x8OBB1KpVq9gaTPkwM0KkgNa4U7XOsjVERERE7siqRdUqlQoDBw7EwIEDAQAPHz5Eeno6ypUrx12qHc1MIKoluw4F9EFI5BuIuGqIiIioSLsq+vv7w9/f315toaLIZw1RkE7/cNd89yGycH8iIiIiV8a7zFxFYbfdc4SIiIgoX3zuhqvIZ1G18Vlm+QSiHCNEAUhGCNT2bhkREZHTYyByGQXfH2bJCNExz//pv0juAJQJsVO7iIiInB+nzFxFviNE+m+xVWuI4k7aqVFERESlg02B6Pr167hx44bh9YEDBzBmzBh8//33dmsYWSu/ESJ9OdcQERER5c+mQNS/f39s27YNABAXF4f27dvjwIEDmDBhAj7++GO7NpAslM8IkUzSB558n2XGu8yIiIhsC0SnTp1C06ZNAQCrVq1C3bp1sWfPHvz6669YvHixPdtHlsrnLrPsUl2+wcdcOUMSERG5F5sCkVqthkqlAgBs3boVzz//PACgZs2auH37tv1aR1bIZ4To0caMyO9ZZhwhIiIisi0Q1alTBwsWLMCuXbsQHR2NTp06AQBu3bqFcuXK2bWBZCGZ+W+l3DBlZs0IERERkXuxKRDNnDkT3333Hdq1a4d+/fqhfv36AIA///zTMJVGJcwrEGgwEDqlt0mx9Cjw5DtlZq6co0ZERORmbNqHqF27drh79y6SkpIQGBhoKH/99dfh7e1dwJlUrF6Yh8zH2sNrzWBDke7RVJnIb8qMI0RERES2jRClp6cjMzPTEIauXbuGuXPn4vz58wgODrZrA8k6Xh65HrIrCpky42gQERGRbYGoe/fuWLp0KQAgMTERzZo1w+zZs/HCCy9g/vz5dm0gWUmSm7ws560fBLRuHyKGJCIici82BaIjR46gdevWAIDffvsNISEhuHbtGpYuXYqvvvrKrg0kK+W+/d4wApTfCFGxtoaIiKhUsCkQpaWloUyZMgCALVu2oGfPnpDJZGjevDmuXbtm1waSlXLdbbb/8h2sP34LukJHiJiMiIjIfdkUiKpVq4a1a9fi+vXr2Lx5Mzp06AAASEhIgJ+fn10bSFbKNUKUlqnGm8uP4n5Khvn6j0aQZDkDEdcVERGRm7EpEE2aNAnvvvsuIiIi0LRpU7Ro0QKAfrSoYcOGdm0gWSnXGqLsoJOcoc7nBP1xiSNERETkxmy67f7FF1/EU089hdu3bxv2IAKAZ599Fj169LBb48gGstyBSD9VJhXyLDMGIiIicmc2BSIACA0NRWhoqOGp95UqVeKmjM4g15RZ9giRTmc+8ExdfwqV7tQwnTJjOCIiIjdj05SZTqfDxx9/DH9/f1SpUgVVqlRBQEAApk2bVsDiXSoRuabMskd+1PlszHj9fhqm/XUGXWT7i71pREREzsqmEaIJEybgp59+wmeffYZWrVoBAHbv3o0pU6YgIyMD06dPt2sjyQp5Roj0AVWjMR+IsgPTXI9vi7ddRERETsymQLRkyRL8+OOPhqfcA8ATTzyBsLAwjBgxgoHIkWTmp8yyCglEJniXGRERuRmbpszu37+PmjVr5imvWbMm7t+/X+RGURHkHiF69LT7/EeIiIiIyKZAVL9+fXzzzTd5yr/55huTu87IAfJZQ6TR8tEdRERE+bFpyuzzzz9H165dsXXrVsMeRHv37sX169exceNGuzaQrJTPGqIsjcZ89WJvEBERkfOzaYSobdu2uHDhAnr06IHExEQkJiaiZ8+eOH/+vOEZZ+QgefYhKmzKjKNBRERENgUiAKhYsSKmT5+O33//Hb///js++eQT6HQ6vP7661Zfa968eYiIiICnpyeaNWuGAwcOWHTeihUrIEkSXnjhBavf02XlmjIriyQAAn+fum2+OhdVExER2R6IzLl37x5++uknq85ZuXIlxo4di8mTJ+PIkSOoX78+OnbsiISEhALPu3r1Kt59912OSOWWa8rsS49v8Y3y63z3h+KUGRERkZ0DkS3mzJmD1157DUOHDkXt2rWxYMECeHt7Y+HChfmeo9VqMWDAAEydOhWPPfZYCba2FJDl/ZY+J9+HdrLjZqtzyoyIiMjBgSgrKwuHDx9GVFSUoUwmkyEqKgp79+7N97yPP/4YwcHBeOWVV0qimaWLZP5b+p5ylfnqvMuMiIjI9meZ2cPdu3eh1WoREhJiUh4SEoJz586ZPWf37t346aefcOzYMYveIzMzE5mZmYbXSUlJAAC1Wg21Or8nwNsm+3r2vq5VtAJKK6qbmzLTaDQQRfwMTtEXToJ9YcS+MGJfGLEvjNgXRrn7orj7xKpA1LNnzwKPJyYmFqUthUpOTsbLL7+MH374AUFBQRadM2PGDEydOjVP+ZYtW+Dt7W3vJgIAoqOji+W6lvDMuo+OVp2RdzToyOFDuH3ZPoOHjuwLZ8O+MGJfGLEvjNgXRuwLo+y+SEtLK9b3sSoQ+fv7F3p80KBBFl8vKCgIcrkc8fHxJuXx8fEIDQ3NU/+///7D1atX0a1bN0NZ9mJhhUKB8+fPIzIy0uSc8ePHY+zYsYbXSUlJCA8PR4cOHeDn52dxWy2hVqsRHR2N9u3bQ6m0ZpzGjpLjgNOWVzc3Zfbkkw0hanUpUjOcoi+cBPvCiH1hxL4wYl8YsS+McvdF9gxPcbEqEC1atMiub+7h4YFGjRohJibGcOu8TqdDTEwMRo0alad+zZo1cfLkSZOyjz76CMnJyfjyyy8RHh6e5xyVSgWVSpWnXKlUFtsftuK8dqE88n7WgpibMlPIJMBO7XdoXzgZ9oUR+8KIfWHEvjBiXxhl90Vx94dD1xABwNixYzF48GA0btwYTZs2xdy5c5GamoqhQ4cCAAYNGoSwsDDMmDEDnp6eqFu3rsn5AQEBAJCn3G3ls6g63+rch4iIiMjxgahv3764c+cOJk2ahLi4ODRo0ACbNm0yLLSOjY2FzMyt5JQf63YWMh+I8nvuGRERkWtyeCACgFGjRpmdIgOA7du3F3ju4sWL7d+g0kyyNhCZwREiIiJyMxx6cTXWBiKJI0REREROMUJEdmTlGqL/U36HTJFroRoDERERuRmOELkauYfVp3zt8U2uEk6ZERGRe2EgcjVKL6Djp0W7BkeIiIjIzTAQuaIWI4t2PgMRERG5GQYiV/XSMtvP5V1mRETkZhiIXFWVVrafK3TQ6RiKiIjIfTAQuSrPgp87V5CUjCw0/TQGH68/Y8cGEREROS8GIlclScA752069bsd/+FuSiYW/nvFzo0iIiJyTgxErqxMqE2nJaVn2bkhBACy7TOAAz84uhlERGQGA5Gre3kt8Hhnq06RgXeZ2VuZ9BuQ/zsb2Piuo5tCRERmMBC5usingf4rgIAqFp9i3cM/yBIKXYajm0BERAVgIHIXViyy9kYGnpKdhBKaYmyQu2HMJCJyZnyWmbuwIhC9q1wNAPhR0xlA92JqkHsROQOREFY/hJeIiIoXR4jchW+I1acMkm8phoa4qZz5hxtfEhE5HQYid9HhEyCoBtBppsWncAzDfkxHiLhonYjI2TAQuQu/CsCoA0Dz4RafwrvN7ImBiIjImTEQUb44QmQ/HCEiInJuDESUL5nEtS72w0BEROTMGIjc0asxFlcVXABsHyaLqhmIiIicDQORO6rUGJjy0KKqfOi9fXDKjIjIuTEQuTMLdq/WMhHZCQMREZEzYyByZ8M2FVqFgcheGIiIiJwZA5E786sIbVCNAqtodGZ+eAsB3PuPGwxaQXBjRiIip8ZA5Obkr0YDkjzf41qdANQZpj/EY6YCXz8JbPu0BFroKjhCRETkzBiI3J2nPxA1Jd/Duoe3gOkhwOrBxsLdX+h/3/l58bbNpeQIlAxEREROh4GIgJZvAqH1zB7yOPGL/osz60qwQS6OgYiIyOkwEJH+yetVWpk9JLSaAk8VQkCj5Q/4wpjscclARETkdBiIqEBCqy7w+OgVx9BwWjQS07JKqEWlFafMiIicGQMRPWL+yWV+h78p8Kw/j99CcoYGa4/eLI5GuSYGIiIip8NARHpS0R7lyhvJrcBARETkdBiISK/FqCKdzq11CsMpMyIiZ8ZARHr+YUDvJY5uhcuSTAIR0yMRkbNhICIjhaejW+C6eJcZEZFTYyAiI6WXzadyzKMwnDIjInJmDERkFFLH0S1wDwxEREROh4GIjHyCgMhnbDpVcF1MgSSOEBEROTUGIjI1cA3w7kVHt8K1MRARETkdhaMbQE5GkgDfYPPHhABO/V6y7XEZHCEiInJmHCEiiyWmZgC/v+LoZpR+DERERE6HgYgs9v2OC2bLa0qx6HhsFHDrWMk2qBThPkRERM6NgYgsptNozZYv8/gE4ff+BX5qX8ItKkW4DxERkVNjICKLCaExW15WStF/oeUT7/PHNURERM6MgYgsptHkDURtZMcd0JLSx+TRuQxEREROh4GILKZRq/OULfWY6YCWlHIMREREToeBiCxmboSILMUpMyIiZ8ZARObV6panyOJAJARk0RNQ+d5OOzeqNGMgIiJyZgxEZF6P7/MUabQWBqLL2yA/8B0axv5o50aVYrzLjIjIqTEQkXke3nmK/pfwiWXnpj+wc2NcDAMREZHTYSCifKU2GmHy+vGsMw5qSenHjRmJiJwbAxHlyyegvG0n8ge+GVxDRETkzBiIKH868ztTUxExEBEROR0GIsqfJBVex57nuQsGIiIip8NARPlr8gpQrhoe1BmMZOHl6NaUahKnzIiInJrC0Q0gJ+YVCLx5GFlJGQg8vcTRrSndeNs9EZFT4wgRFcrfS2ndCVxUbQZHiIiInBkDERXKUykvtmunZWlwMT652K7vLDhlRkTk3JwiEM2bNw8RERHw9PREs2bNcODAgXzr/vDDD2jdujUCAwMRGBiIqKioAuuTc3vuq91o/8VO/HvprqObUnIYiIiInI7DA9HKlSsxduxYTJ48GUeOHEH9+vXRsWNHJCQkmK2/fft29OvXD9u2bcPevXsRHh6ODh064ObNmyXccrKHy3dTAQDrj99ycEtKEKcUiYicjsMD0Zw5c/Daa69h6NChqF27NhYsWABvb28sXLjQbP1ff/0VI0aMQIMGDVCzZk38+OOP0Ol0iImJKeGWkz1JLn+rvjEEWfxMOCIiKjEOvcssKysLhw8fxvjx4w1lMpkMUVFR2Lt3r0XXSEtLg1qtRtmyZc0ez8zMRGZmpuF1UlISAECtVkOtVheh9XllX8/e13UGli6rVqvVkLRawx8si/tC6Fyy34BHfZJjVGj3hTi0quuan7Uwrvx3xFrsCyP2hRH7wih3XxR3nzg0EN29exdarRYhISEm5SEhITh37pxF1xg3bhwqVqyIqKgos8dnzJiBqVOn5infsmULvL3zPsDUHqKjo4vluo7U3cJ6GzduRNiDY2j86HX0li2FbNSo/yN4PTYWGzdeLUILnVvOh6CcuXITDzdudFhbnIEr/h2xFfvCiH1hxL4wyu6LtLS0Yn2fUr0P0WeffYYVK1Zg+/bt8PT0NFtn/PjxGDt2rOF1UlKSYd2Rn5+fXdujVqsRHR2N9u3bQ6m08lZ1Z3fUsmpdunSBdDoDuKp/3b59FJQeqnzrj967BQBQtWoEunSpWcRGOie1Wo1jv58yvC4b4I8uXbo4sEWO49J/R6zEvjBiXxixL4xy90X2DE9xcWggCgoKglwuR3x8vEl5fHw8QkNDCzz3//7v//DZZ59h69ateOKJJ/Ktp1KpoFLl/YGsVCqL7Q9bcV7b2SmVSkBuvE3f49QKKJq9Wuh5CrnMxfvMOGUmk+Din7Vw7vx3JDf2hRH7woh9YZTdF8XdHw5dVO3h4YFGjRqZLIjOXiDdokWLfM/7/PPPMW3aNGzatAmNGzfOtx7Z0ct/2HSa4u93LKonc6NF1SZ7EhERkVNw+F1mY8eOxQ8//IAlS5bg7NmzeOONN5CamoqhQ4cCAAYNGmSy6HrmzJmYOHEiFi5ciIiICMTFxSEuLg4pKSmO+gjuIfIZ3C/ftNguL3P1PJSDxH2IiIicjsPXEPXt2xd37tzBpEmTEBcXhwYNGmDTpk2GhdaxsbGQyYy5bf78+cjKysKLL75ocp3JkydjypQpJdl0tyOTF99wpczFE1HOTydxHyIiIqfj8EAEAKNGjcKoUaPMHtu+fbvJ66tXrxZ/g8gsT0XxhRaXnzITOafMOEJERORsHD5lRqWHqhjjc7EOEAkBXP0XSHWOx4NwDRERkfNhICKLSbriG9ko1hGi838Di7sAXzcqvvcoBB/uSkTk3BiIyHJ2/kEuRM5b0YszEG3Q/56RWHzvYQVJaB3dBCIiyoWBiCxnQSASViwY1uhKKBDpnCGAGD/rC3cWOLAdRERkDgMRWU5pfjfwnHKGnMJodaabFRYbLZ8JREREBWMgIst1+T/ALwwx2ob5VtFoLQ9Eaq1xxKlYb7vXOf7p8lxITUTk3BiIyHLlawBvn4bmubn5VtFYsfBaW2JTZo4PRHlwLyIiIqfCQETWkSR0rFc538MarbD4h73aitGkInGGNUS5+4SBiIjIqTAQkfXkHvke0q8hsuyHfc4RIl1xBgSnHCHirfdERM6EgYisp1Dle0ij0+Hmg1SLLpNzes3k7rTUe/YdQdE5waLqPCNEDERERM6EgYisJ8t/y2qNViAxNdOiy+RcbpQ9WJR5ch0w6zEk//F2UVqY640cP2Umco+acS8iIiKnwkBE1itgAbTi2k6Ln3mmnybT/8qeMkv6ayIAoMyJRUVtZY43cvyUWZ4BL44QERE5FQYisqsK6/pCJuWzgFirBr5vB6z5n/6lVo2NHh/iB+Uc6B4NEaWri2HkxAkCUZ74w0BERORUGIjI7nRaXe4C/e9XdgK3jgInVgAAPOKOobbsGtrLDxumzIplvx4nCERcQ0RE5NwYiMjuktJzrSESWtxMTIdQp5sU63Ks7THeZVYM+xFpHR+I8mzgzUBERORUGIjI7i4e3Wnyetm+y2j12T/44/BVk3JtjlETnaWP/NBqCg84D28AX9QFds15dHHHB6I8uA8REZFTYSAiu+sj+8fk9cyNZwAAO8/cNBYKYbJdkRD60FLghtU6LfBVA+Crhqa3qOW2Yybw8DoQM/XRxR1/R1eeh946wZ1vRERkxEBExU48+uGvlDQ5C01GhZreWl74hdLu6YPOw1gg/UEBFXOlKicYjckTiDhlRkTkVBiIyDb9V1lcVfboHisljKMi2lsnoMuxYeKzN+cBKGxRdc6gU0A9hafpaycIH3la6wRtIiIiIwYiss3jHYFeP+m/zv49H/JHgcgDxgAk/7Edwg7OsO49c86nFTTqk2cnbWcYIcpdwEBERORMGIjIdvVeBD66o/+9AMYRItPFzT53T+SpW+A9ZjlDREGBIucIkRDm694+Dhxbpt8bqQTk3amagYiIyJkwEFHRKPJ/0Gs2eT6ByGo57xYr6M6xnCNEPzxtfgHzd22AtW8An0cWrU0W4hoiIiLnxkBExa61/CQAYzAqSKF3mRm+tjAQ3TqqX4idn8yHhbbJHvJOmfEuMyIiZ8JARPYR0TrfQ7OU36OadANyqYijIsLCQCTPvYbI8fJOmTl+XRMRERkxEJF9NBte4OGtqvdRTbpZYB2gkLvMTEaIChhhKXCYyTEsXlStTgfUGcXeHiIiMsVARPZRo3OhVZ6T7y+0jsWLqgsaISpsfY4DRmcsCkRaNTAzAphVreCNJ4mIyO4YiMg+ZHLg2cl2uJAxEhW4u7OugLvDCtsF2iG7RFuwqDolHtBkAFnJQFZKyTSLiIgAMBCRPfkG2/VyGp0ALu8Aru3RF1h6l1lhC5ZzHc8TvIqBzqK7zKRCjhMRUXFROLoB5ELkhd+CX5icy380KQ+gXPq8/sXEu7kWVRcQegoLE7nCVEaWFl6q4v6rkGsy0Gz7c4QmZ3wgLRGRC+MIEdnP450AyfY/UrlHajSpd40vtGrLb7svdMrM9Fz1v19b2kSbWbQPUc52abOKt0FERGSCgYjsx9MPmBBn8+kanTC5y0ytzbWI2uJF1datIfL918pHiNjAskXVOQNRyeygTUREegxEZF95niNmuUyNzmTpcc48BJ3G/AjR3nnArtmmFyrsDi0HTEdZtA9RzoXiDERERCWKgYjsr+KTNp2WqdaaLKPRaHMFIJNF1Vr9fj2bPwRiPgZSEozHClpDJIT5QPTvV8Dvr+qvac0i65QE4PrBwutZMmWWMwQVdBcdERHZHQMR2V+fJTadlqU1HSFSq3Oso9Fp8uxU/feJHI/kUKcbvy5oykyIPFNmAhIQPRE4uRqYHgKsHWF5o2fXAH6KAmIL3mMpT/zhGiIiIqfCQET2F1AZmiFboJF5Fl43h0y1aUjQqXNNIeUMMmfW4YPVR8xfaOf/5f8mQlf4lNnxZUByPBB3yqRYrdXhwJX7yNLkaGd2sLm8veBr5mmHmdBmEoh4lxkRUUliIKJiIcKexJ5q46w6J1NjGog0mkzji9wjRMeXI1BKzvGGj84VAnk2QcxBq9NZtjHj7MeBBa2Ae/8ZiqZvOIs+3+3F5D9PFXCieRbdZZZzyowjREREJYqBiIqNTpJbVX/6xrMma220mlxTZjtNF08HIsX0OFDoYuT7KRnWLaq+fczw5eI9VwEAyw9cz1vv0tYCL5M7EMUlpuWtpOMaIiIiR2EgomKjk6zb7HDnhTsmr7WaXDtTx+4xOe4t5XgIanYQKiRIpGVm5Q1EBS3CluSWPVfsxoHC6+SQcmZL3kIt1xARETkKAxEVmzSPIAjfEKvOyXl7ui7HCNGMv07kqeuHHKMs2UGokCCRpdHmCUSygkLU6sHAkm4FXtMSulwzZtUu/GCmUs4psyKuIdKqgehJ+kefEBFRoRiIqNho5Z7QvHEAePeixefIcoSVsJi3DF8fvnQrT10/KUcgOr8JOLu+0CkztVqTZw2RVMCaIwDAtd2IT8pAWSShtnS14Lr5KuQ9dDpg+UuGl3cfJhdQ2QIHfwL+/RLIfvQJEREViIGIipeHj8UPff1c8R2ChfFxHYHigeHr31Qf56nvn3MN0fZPgZUDoU4qeKfsTI228J2szfhp9xXsVI3BRtWHNoUicw+QTUjWT/ntungH05dtNjm28biZdUrWuP9f4XWIiMiAgYhKRnPj3j73ag8xW6WPwrrpHZMRokeyku+aqWmk1miRkZlZYB1ztp6Jh++jNUtPy45h82kzwauAu9fMjQ8NWfAPAODln/Zj8+nbJscUuiwgMwW4cci6jSINb2jBuieyPyGAX3vrN/kkolKFgYhKRtQUoN9KYPwNlGs1yFCsjuxo8yX9kZqnLP2/fQWeo9ZosP3s7QLrmKPNsbC6jJSO//18OG8ASso7rVeQTg9XArdPYL3HBPyq/NTkWBmlFljaHfjxWeD4cqvba1OIoqK79x9wcYt+k0/uJUVUqjAQUclQqIAanQBVGSC4DuAdBCi8oOy/DAiMsOmSLyvy3uoedGBmgeeoNRpoNNbf0q5VG0eVfJCeXWhaaW7dfM/X5V5VDeAtxVrgu9aoJ7uKcJnpHXa+MjVw85D+xdFfrG5voWuWqHjknI7lnYJEpQoDEZU8pSfw9ingw5uAXAGMPg70/LFE3jo9Sw1PyYY9ftTGW/x9pUeByIq9grRW5hNJk5HzlXUnAwWPEN29CPz1NpCYzzqle/8Vuq8SWUBr/dQsETkOAxE5htILkOXYuLFmlxJ528c39MHpQ9bfii7TGtcr+SIdMujM39H2aJrkx12X0X3ev3iQqh8lyJ5xuy4Ls+j91Bk5pgMlGwJRASNE4tfewKGFSFzYy3yFr58Efull2UNryVTOtVuF3PFIRM6FgYicg4cPMO4adB/cwBchM4rtbSJltzFascbq85QaY0BpLz+Ck6pX9OtEclPr632y4SyOX0/Eon+vAAA0j/KJTKGy6P2uxN0zvrAlEBWwqFp6oG9TQNL5gq9x66j172sPD66V3vU3OUOQhiNERKUJAxE5D68AyDzL4KXnbF9oXVxyL+D2kTKBv9/PU0999wp0myfiA8Uy/KKcjtRk/dYBukdTWF5yy+bOvGD8YZqmtuUuM8vOyVAXsAWBTSNTRfTfNuDLJ4AV/Uv+ve0h57ohriEiKlUYiMjpVAiPBJ7+CGj3IbR9l2NdrdnYr6tpUida2whDs96z6HqZUBa5TXVkVy2qp/mlN2R7v8JwxV94Sn4aLW7rF0RrHwWUJL/qFl0n54LxQ9cScfDqfePBC1uAJc/rR1Ky6XTAsWXGh9HmDES5wpFa4Wv4+saDXFsX5LxzTnLAPw/7v9P/fnFzwfWcFQMRUanFQETOqe17QLtxkNfqgu59X0Wz0cuA8rWAF+YDo48js+di3A97GnEvmXkm2CPnOi1H+subkDE4usjNmaZcbFE9r4wEk9c+6bcQt/EzDMhcBQCQ5Ar8J1W2+v2n/Hna+GJZb+DKDqSueQszN51DcoZaf2v+2jf0638AmKwhyvWoEq3MGBClQ4uAdaMMQSjzXI6+yhmIrv4L7Jpj2XPdLHH/P+D+lbzlFk4p2t2to8CRn/OOrJ3bCGx4B9BYGG4YiIhKLeuevknkKOUigZHGPYaeCwSea6gPFhq5JxTaDNP6XmVRs7l+obYXANTpAZz+o4Qaa9Qg9V94HY0x3ChW5dZGaMtWA+4XfF5ObeQnsSNrL4DWJuU+17fj5n8/41evYeh9bTPKZR9IvWf6g12bBciNIUgH42L2yAMT9V+EPQk88RJUq/oajm08cRNZ8pt4oWEYsPjRovfACKBuT+O11RnA+Y1A5NOAV2Dext+9BFz7F2g40LCIXq7NgHJ+M/3xiXdN2uawQPR9O/3vZSoA1aOM5Sv66X8PrgU0sWCzxRxriB4kpSCwgv2aSETFiyNEVOrJRh7AqYZTkFqrj76g4cvAiFwbNPY08zBVMzLbfGjXtnkhI0+Z/JkJVl9nYsp0IOk2tN80Myn/yuMb3L11BeUurzMWLuqExDTj6MTD1EfbBGgygesHoDP31/6vt4GFHUyKKl5dg3dWHjatdzfXc+m2fwr8NhT4/TX99U//AaTlSHvfNAbWvwUcXmwo8snMMYqWlmPxOGAaiMyNRmWl2r7pZOo9YMfn+t2//3wLuH85b534U+bPtXTTzRyjQr8f5ONTiEoTBiIq9WRlq6Bu97fh0/s74O0zQPdvgDIhppXkSmD8TaQN/Ati4BrgmYn6ujWfA6q0AuQeQL8VUD39PuIrdTI5Nff6pZzGYqxVbc2o1Eo/wjLqMP7y7GbVuZhTE/K75/IUf3Q+1+3zdy8g+aExaFxfNBQZD25D7JoD/NQevlkJMCvupMnLBrL/8K5iFTSaXAuvs1KBy9v1o0P/fqkvuxQNLOsDrB4CrB6sr5aVBcPU3YaxwEH9XlNeOQNR6qNHrajTgU3jgVvHjMeyw4k6A9gyETiyFGJmBFL+GG2sc/QX4KsncffPiUjb+xOQGIvYKxew47uxuJOQ6/EqS7oB26brd/8+sgRYNch4/Ww5t4LIsZ7qfno+i8/Prgeu7DK+znFnWXp6hv7aMdOAhLzfNyJyLpwyI9chkwH+Bezzo/KFd7VH007VntX//tKv+t+1asPUTciw5cDdC4DKFzi8BH/dbIqBp9OwvuISVG/QCvLAKsDvrwAAPh/zGpD2PLCkO5D5EBlCWeDGj6p+S/VfBFXDYy99DvXiv6HEozU+zYYDCk/g37m29oBBeMI2w9d1k3YCX+Yf6gryhmI97l/ag7LZBds/1f8y5/J2/e9XdgIb3oXHwVyjchvegQQFml/9yli2oBXU7Sbi3vk9CL0dY1r/u9YQlZpAyFWQXdsNQD/z6HtiCR52mInUiztRcd1IAEDQ/UfX3AyoZVXQVncN+PYnYPQJILCK/ljCadPrx51ERmYWshJvwy+7bMtHQJNXodEJ3N48F+HZxceuoGf7TKRqJAR4KyFJEnBxK7ByICBTAh8l6EeHsox3I6okNbD7C2DX/+l/TXkIXIzWj5Y99wWgMjPFSEQOw0BEBJiuY5HJgOBHAeKZCZis1aH9f/cQUfU5yJVy/ShA5ZZAaD0oAioCARWB8bHQpdzFurNpSNk0DT20m+Hh7QffNP1u0FkyT2S8sgN+PkGGt6kdURFiyJ/6xctVWhjfv0or3LuwF4fSQtDm+WFIWdIH5W8bA05JK7viOetPyh2GHlFsGJ2nTLl9GkLzuYx046DZfbr9/y8U/vmcE6nLcffdl08gs9H/kHjlMELM1PWcUR6ZwsdkM/DMpb1xICkQrR/+aSh7SbMO12fsR4ZOjnsQeFizLxql7tQf1KlxYfFwPB670uTaldPPQx17w3iPY+o94NcX9V97BQJdvtB/LcSjXzrgwA/ApnFA/X76GwhSEgBNOuAXBsgUwI1DSN+/EBqtFmVe/FY/7Zd2F6jS0nits+v1u6jXfA64FANUiwIUHo/aqtUvZpcr9UHx4I/6kNZ1NnB9v37/p3KRQKXG+fQukeuShHCvp0AmJSXB398fDx8+hJ+fX+EnWEGtVmPjxo3o0qULlMqi3+pdmrEvHrmyC2plGfx96D907vq8bX2Reg93dy/E2YNbcSg9DGWlJFT2FajtEY+ynhLOedSBuHkET4jzyChTBZ7JxkCQIjzhK5muY1qjfQq+SEcH+WHs0dXBX9rmaCBdgoekxgvyPQCAM4+PQO0L3xbpo1PBdJICGQo/eKutWGGf83y5CrJHjwcRCi9ImvQC6wult/6RMAVs2mmoK8kghTfXB6fYvUCNLkCtbkBWCpCRpF/7dWUnEFoPKPsYoMnQPwrm5iEgOQ6o3R1Qeut3pN89R3/RJq8BFerrg5jCC7hzTr8ha7lIaOLP4fqu5agcWQPy+5eActX1o7hatT4Qpt3XPwdRptCHxIDKgE95IDMJOPcXkJUG1H5e3y7vIMDTD1D5ASdWAQln9NPUd84Dnv5A9fb64Hh6jX6bitbv6gNxZop+lLNcpL6dD67pp9JD6wKZyUDqHcA3RP/5FSr9urKwJ/XTvRe36EcHQ+sBYY30fSx0xqCb/QvQ96lWrb9mxkPAr4L+c0lyQJJBrdVhS3Q0OrRrBaVfsD7EZp8rdED6A8C73KPpXUnfB3IP/S9bWL3fmIX1JZn+MU1FkPvnSHH+/AacJBDNmzcPs2bNQlxcHOrXr4+vv/4aTZs2zbf+6tWrMXHiRFy9ehXVq1fHzJkz0aWLZY9+YCAqGewLI3v1hfbRA2LlsoL/QbrxIA1nL13BkxW9IPzDkJiWhe3n76Dd4+Wx9uhNXL6XimGtqqJxRFkIIbDi4HWU9fGAt4ccry89jM961UP3BmHYcvAUbq2bCk9kobHsAvbpauGSCIMH1Phb1xTVpZuoIN1HSJWaWHezDGaLWbglgrBJ2xRlpSSs0bbG5PI7EFpGjnVx5SBlJiMU99HE4yoqDluKt77biNbiMKLkhxHk54v/Mv1xNKsS3pF+gU5I0EHCPG13tJcdQW2ZMeQd0j2OxrILhte/ap7FWVEZQZ7ACM1SeEjm1/tc15VHGlSIi+iOxHsJ6J5q3Gk8XgRgSNY4TFL8jBbyMxZ9P+JEIEKlBxbVJXI3WRUaw+N/MYVXLIDbBaKVK1di0KBBWLBgAZo1a4a5c+di9erVOH/+PIKDg/PU37NnD9q0aYMZM2bgueeew7JlyzBz5kwcOXIEdevm/7TxbAxEJYN9YVSa+yJTo4VKYVxoLIRApkYHT6UcaVkaKOUyKOUyJCRn4FJ8ClpWC8KD1CycvpWEJlUDTc7V6gTUajU2b/rb0Bfn45Lh66lAWICXyfsevnYfaVlatK5eHvdSMpGu1iItS4vI8r44dj0Rx64nIsBLiVbVglDWxwMeCv39Ieeu3sLBSzcgLxOKKzdvY29sOmqUBbQyT3j7+ODtqMdRvowKWRod/jmXgCt3UuCte4hZO+LxXqfaqOitRey/q9D8sbJIi4iC7sYRlEEqHipDsPvMNTxdCfAIrYFBf6UiMUtCl3A1wtPOYMfDYPT0Po6T4jGU9fFAvZo1sG/XFtwUQbjjEQb/zHg8KbsIDeRoJLsANRRIEV4QkKDNcW+LBnLcEuVwWheBYYpN0EHCY9JtlJWSsVX7JBTQIhG+UEKDROGL/ooYhEiJuCfK4Looj6O66ojRPYnHpFsYLN+CSNltw7V3aeviuIjENRGCgfKtqC+7jAQRgEyhRAo8ISAzCZ7XdMFIhwo1ZdcRJwKRLLyRAi9kQgkFtKgtXcMNEYQ4URa1ZLEoLz2ETkiQSQLbtfWhhgJVpduoJtPfoZchlEiHChnwgACgFgp4SVnQQTIbLFOFCpdFBZSXHsIHGUiHCneFP2rLrkErJAhIUEimo133RBnEihD4Ih1lpDSz170j/OGNDP1u848kCS8ooYWXpL9LMF14GL7WCBm0kCEZ3vB7tGN9fqE7P9kBP2d7U4QndJDghSzIoINccvjYhF2dU9RCzY/2FV6xAG4XiJo1a4YmTZrgm2++AQDodDqEh4fjzTffxAcffJCnft++fZGamoq//vrLUNa8eXM0aNAACxYsKPT9GIhKBvvCiH1h5K59kanRIkujg0ySIJMk3E3JRKCXHOs3bsLjT7ZChUAf3EnORHhZb5TxVEAuSbidlIHbieloEB6ADI0Oh689gEImoV4lf3jIZbh+Pw3lfFUI9Fbi9sMMlPP1QHKGBqmZGoT6e+LynVSkq7VoGB6Ay3dTceDKfdxJzoSXUo5gPxXO3E7CE2EBeKKSP9YevYlAHw/EJ2XAy0MOpUwGSQJSMjXwUMiQlqnFoWv6qb3wQG/4qBQ4H5eMasG+UGt1uP0wA15KOVKzNKjg74kMtQ77r9xD7Qp+qFzWG3dTsgAJSM/SQq3VIetRqPZSyuGplMFDLuHi1etQlCmHAG8PeCrlSM3UIEujgyQBkiRBJgHX76chS6uDSiFHWW8PlPXxQKCPEglJmUjO0ECllEGr04d2fy8lktLVCPJV4X5KJjwUMijlEjQCSM3UQCZJyNToICCgkMmgkElQa3WAJOm/VmchSydDlkaHTI0OHgp9HblM0kdYSUJ6RgYEBNRCAUnoIBMa/a4QEqCQKyDJZPrryfXtylJrIBdaCJkMXh4e8FYpkJimRlKGGkInIEEHGXTQZGVA4aGCClpoIYNGAJIkgwR9aPZAlmEaLQtKCAHIoNXf0ymM27IKIXJ8rZ8dkz0qkXJMlWXHgOy6EoRhdwsBASnHNJkkGSfNTMaqH10vu6xuWAAWvt7W1r8yAEo+EDl0UXVWVhYOHz6M8ePHG8pkMhmioqKwd+9es+fs3bsXY8ea3urcsWNHrF271mz9zMxMZGbm+J9AUhIAfUer1fZ9GnX29ex93dKIfWHEvjBy176QAfCUA/ofOQKhZZRQq9XwVgC1QryhVCpQ3ufRP8c6LbQAgn0UCPYpA6HTQiUDWlYNyHFFHSLK6tdnaDQa/blCB3+VDP4qD0DoUC3Iy3C8coAKlRua7hLZpY5xBH54mwgLPsVjNn12S6jVakRHX0P79g3cKiibo++LaLRv/3Sp74ui/j3P/e9Fcf+74dBAdPfuXWi1WoSEmN7/ERISgnPnzO/bERcXZ7Z+XFyc2fozZszA1KlT85Rv2bIF3t7eNra8YNHRRX9UhKtgXxixL4zYF0bsCyP2hRH7wii7L9LS0gqpWTQuf9v9+PHjTUaUkpKSEB4ejg4dOhTLlJk+2bcv9cm+qNgXRuwLI/aFEfvCiH1hxL4wyt0X2TM8xcWhgSgoKAhyuRzx8fEm5fHx8QgNNb8zSWhoqFX1VSoVVKq8z0dSKpXF9oetOK9d2rAvjNgXRuwLI/aFEfvCiH1hlN0Xxd0fDn10h4eHBxo1aoSYGOOteTqdDjExMWjRooXZc1q0aGFSH9APp+VXn4iIiKgwDp8yGzt2LAYPHozGjRujadOmmDt3LlJTUzF06FAAwKBBgxAWFoYZM2YAAEaPHo22bdti9uzZ6Nq1K1asWIFDhw7h+++/d+THICIiolLM4YGob9++uHPnDiZNmoS4uDg0aNAAmzZtMiycjo2NhUxmHMhq2bIlli1bho8++ggffvghqlevjrVr11q0BxERERGROQ4PRAAwatQojBo1yuyx7du35ynr3bs3evfuXcytIiIiInfh0DVERERERM6AgYiIiIjcHgMRERERuT0GIiIiInJ7DERERETk9hiIiIiIyO0xEBEREZHbc4p9iEqSEAIAiuUhcWq1GmlpaUhKSnL7Z9CwL4zYF0bsCyP2hRH7woh9YZS7L7J/bmf/HLc3twtEycnJAIDw8HAHt4SIiIislZycDH9/f7tfVxLFFbWclE6nw61bt1CmTBlIkmTXayclJSE8PBzXr1+Hn5+fXa9d2rAvjNgXRuwLI/aFEfvCiH1hlLsvhBBITk5GxYoVTR7pZS9uN0Ikk8lQqVKlYn0PPz8/t/+DnI19YcS+MGJfGLEvjNgXRuwLo5x9URwjQ9m4qJqIiIjcHgMRERERuT0GIjtSqVSYPHkyVCqVo5vicOwLI/aFEfvCiH1hxL4wYl8YlXRfuN2iaiIiIqLcOEJEREREbo+BiIiIiNweAxERERG5PQYiIiIicnsMRHYyb948REREwNPTE82aNcOBAwcc3SS7mzFjBpo0aYIyZcogODgYL7zwAs6fP29SJyMjAyNHjkS5cuXg6+uLXr16IT4+3qRObGwsunbtCm9vbwQHB+O9996DRqMpyY9iV5999hkkScKYMWMMZe7WDzdv3sTAgQNRrlw5eHl5oV69ejh06JDhuBACkyZNQoUKFeDl5YWoqChcvHjR5Br379/HgAED4Ofnh4CAALzyyitISUkp6Y9SJFqtFhMnTkTVqlXh5eWFyMhITJs2zeTZS67aFzt37kS3bt1QsWJFSJKEtWvXmhy31+c+ceIEWrduDU9PT4SHh+Pzzz8v7o9mtYL6Qq1WY9y4cahXrx58fHxQsWJFDBo0CLdu3TK5hjv0RW7Dhw+HJEmYO3euSXmJ9YWgIluxYoXw8PAQCxcuFKdPnxavvfaaCAgIEPHx8Y5uml117NhRLFq0SJw6dUocO3ZMdOnSRVSuXFmkpKQY6gwfPlyEh4eLmJgYcejQIdG8eXPRsmVLw3GNRiPq1q0roqKixNGjR8XGjRtFUFCQGD9+vCM+UpEdOHBAREREiCeeeEKMHj3aUO5O/XD//n1RpUoVMWTIELF//35x+fJlsXnzZnHp0iVDnc8++0z4+/uLtWvXiuPHj4vnn39eVK1aVaSnpxvqdOrUSdSvX1/s27dP7Nq1S1SrVk3069fPER/JZtOnTxflypUTf/31l7hy5YpYvXq18PX1FV9++aWhjqv2xcaNG8WECRPEmjVrBADxxx9/mBy3x+d++PChCAkJEQMGDBCnTp0Sy5cvF15eXuK7774rqY9pkYL6IjExUURFRYmVK1eKc+fOib1794qmTZuKRo0amVzDHfoipzVr1oj69euLihUrii+++MLkWEn1BQORHTRt2lSMHDnS8Fqr1YqKFSuKGTNmOLBVxS8hIUEAEDt27BBC6P+iK5VKsXr1akOds2fPCgBi7969Qgj9Xw6ZTCbi4uIMdebPny/8/PxEZmZmyX6AIkpOThbVq1cX0dHRom3btoZA5G79MG7cOPHUU0/le1yn04nQ0FAxa9YsQ1liYqJQqVRi+fLlQgghzpw5IwCIgwcPGur8/fffQpIkcfPmzeJrvJ117dpVDBs2zKSsZ8+eYsCAAUII9+mL3D/47PW5v/32WxEYGGjyd2TcuHGiRo0axfyJbFdQCMh24MABAUBcu3ZNCOF+fXHjxg0RFhYmTp06JapUqWISiEqyLzhlVkRZWVk4fPgwoqKiDGUymQxRUVHYu3evA1tW/B4+fAgAKFu2LADg8OHDUKvVJn1Rs2ZNVK5c2dAXe/fuRb169RASEmKo07FjRyQlJeH06dMl2PqiGzlyJLp27WryeQH364c///wTjRs3Ru/evREcHIyGDRvihx9+MBy/cuUK4uLiTPrD398fzZo1M+mPgIAANG7c2FAnKioKMpkM+/fvL7kPU0QtW7ZETEwMLly4AAA4fvw4du/ejc6dOwNwr77IyV6fe+/evWjTpg08PDwMdTp27Ijz58/jwYMHJfRp7O/hw4eQJAkBAQEA3KsvdDodXn75Zbz33nuoU6dOnuMl2RcMREV09+5daLVakx9sABASEoK4uDgHtar46XQ6jBkzBq1atULdunUBAHFxcfDw8DD8pc6Wsy/i4uLM9lX2sdJixYoVOHLkCGbMmJHnmDv1AwBcvnwZ8+fPR/Xq1bF582a88cYbeOutt7BkyRIAxs9T0N+RuLg4BAcHmxxXKBQoW7ZsqeqPDz74AC+99BJq1qwJpVKJhg0bYsyYMRgwYAAA9+qLnOz1uV3p7022jIwMjBs3Dv369TM8wNSd+mLmzJlQKBR46623zB4vyb5wu6fdk32MHDkSp06dwu7dux3dlBJ3/fp1jB49GtHR0fD09HR0cxxOp9OhcePG+PTTTwEADRs2xKlTp7BgwQIMHjzYwa0rWatWrcKvv/6KZcuWoU6dOjh27BjGjBmDihUrul1fUOHUajX69OkDIQTmz5/v6OaUuMOHD+PLL7/EkSNHIEmSo5vDEaKiCgoKglwuz3MHUXx8PEJDQx3UquI1atQo/PXXX9i2bRsqVapkKA8NDUVWVhYSExNN6ufsi9DQULN9lX2sNDh8+DASEhLw5JNPQqFQQKFQYMeOHfjqq6+gUCgQEhLiFv2QrUKFCqhdu7ZJWa1atRAbGwvA+HkK+jsSGhqKhIQEk+MajQb3798vVf3x3nvvGUaJ6tWrh5dffhlvv/22YSTRnfoiJ3t9blf6e5Mdhq5du4bo6GjD6BDgPn2xa9cuJCQkoHLlyoZ/S69du4Z33nkHERERAEq2LxiIisjDwwONGjVCTEyMoUyn0yEmJgYtWrRwYMvsTwiBUaNG4Y8//sA///yDqlWrmhxv1KgRlEqlSV+cP38esbGxhr5o0aIFTp48afIHPPsfg9w/VJ3Vs88+i5MnT+LYsWOGX40bN8aAAQMMX7tDP2Rr1apVnu0XLly4gCpVqgAAqlatitDQUJP+SEpKwv79+036IzExEYcPHzbU+eeff6DT6dCsWbMS+BT2kZaWBpnM9J9VuVwOnU4HwL36Iid7fe4WLVpg586dUKvVhjrR0dGoUaMGAgMDS+jTFF12GLp48SK2bt2KcuXKmRx3l754+eWXceLECZN/SytWrIj33nsPmzdvBlDCfWHVEmwya8WKFUKlUonFixeLM2fOiNdff10EBASY3EHkCt544w3h7+8vtm/fLm7fvm34lZaWZqgzfPhwUblyZfHPP/+IQ4cOiRYtWogWLVoYjmffbt6hQwdx7NgxsWnTJlG+fPlSebt5TjnvMhPCvfrhwIEDQqFQiOnTp4uLFy+KX3/9VXh7e4tffvnFUOezzz4TAQEBYt26deLEiROie/fuZm+5btiwodi/f7/YvXu3qF69utPfap7b4MGDRVhYmOG2+zVr1oigoCDx/vvvG+q4al8kJyeLo0ePiqNHjwoAYs6cOeLo0aOGO6fs8bkTExNFSEiIePnll8WpU6fEihUrhLe3t9Pdal5QX2RlZYnnn39eVKpUSRw7dszk39Kcd0m5Q1+Yk/suMyFKri8YiOzk66+/FpUrVxYeHh6iadOmYt++fY5ukt0BMPtr0aJFhjrp6elixIgRIjAwUHh7e4sePXqI27dvm1zn6tWronPnzsLLy0sEBQWJd955R6jV6hL+NPaVOxC5Wz+sX79e1K1bV6hUKlGzZk3x/fffmxzX6XRi4sSJIiQkRKhUKvHss8+K8+fPm9S5d++e6Nevn/D19RV+fn5i6NChIjk5uSQ/RpElJSWJ0aNHi8qVKwtPT0/x2GOPiQkTJpj8oHPVvti2bZvZfx8GDx4shLDf5z5+/Lh46qmnhEqlEmFhYeKzzz4rqY9osYL64sqVK/n+W7pt2zbDNdyhL8wxF4hKqi8kIXJsoUpERETkhriGiIiIiNweAxERERG5PQYiIiIicnsMREREROT2GIiIiIjI7TEQERERkdtjICIiIiK3x0BERG5PkiSsXbvW0c0gIgdiICIihxoyZAgkScrzq1OnTo5uGhG5EYWjG0BE1KlTJyxatMikTKVSOag1ROSOOEJERA6nUqkQGhpq8iv7KdWSJGH+/Pno3LkzvLy88Nhjj+G3334zOf/kyZN45pln4OXlhXLlyuH1119HSkqKSZ2FCxeiTp06UKlUqFChAkaNGmVy/O7du+jRowe8vb1RvXp1/Pnnn8X7oYnIqTAQEZHTmzhxInr16oXjx49jwIABeOmll3D27FkAQGpqKjp27IjAwEAcPHgQq1evxtatW00Cz/z58zFy5Ei8/vrrOHnyJP78809Uq1bN5D2mTp2KPn364MSJE+jSpQsGDBiA+/fvl+jnJCIHsvpxsEREdjR48GAhl8uFj4+Pya/p06cLIYQAIIYPH25yTrNmzcQbb7whhBDi+++/F4GBgSIlJcVwfMOGDUImk4m4uDghhBAVK1YUEyZMyLcNAMRHH31keJ2SkiIAiL///ttun5OInBvXEBGRwz399NOYP3++SVnZsmUNX7do0cLkWIsWLXDs2DEAwNmzZ1G/fn34+PgYjrdq1Qo6nQ7nz5+HJEm4desWnn322QLb8MQTTxi+9vHxgZ+fHxISEmz9SERUyjAQEZHD+fj45JnCshcvLy+L6imVSpPXkiRBp9MVR5OIyAlxDREROb19+/bleV2rVi0AQK1atXD8+HGkpqYajv/777+QyWSoUaMGypQpg4iICMTExJRom4modOEIERE5XGZmJuLi4kzKFAoFgoKCAACrV69G48aN8dRTT+HXX3/FgQMH8NNPPwEABgwYgMmTJ2Pw4MGYMmUK7ty5gzfffBMvv/wyQkJCAABTpkzB8OHDERwcjM6dOyM5ORn//vsv3nzzzZL9oETktBiIiMjhNm3ahAoVKpiU1ahRA+fOnQOgvwNsxYoVGDFiBCpUqIDly5ejdu3aAABvb29s3rwZo0ePRpMmTeDt7Y1evXphzpw5hmsNHjwYGRkZ+OKLL/Duu+8iKCgIL774Ysl9QCJyepIQQji6EURE+ZEkCX/88QdeeOEFRzeFiFwY1xARERGR22MgIiIiIrfHNURE5NQ4q09EJYEjREREROT2GIiIiIjI7TEQERERkdtjICIiIiK3x0BEREREbo+BiIiIiNweAxERERG5PQYiIiIicnsMREREROT2/h+cFoEy+OBWDQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64a64017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 3, 70) (99,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape, y_test_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "beee94a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0109 \n",
      "Test MSE loss: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Create test dataset and loader\n",
    "test_dataset = SCFAtomGraphDataset(x_test, y_test_s, c_test, threshold=1.8)\n",
    "test_loader = DisjointLoader(test_dataset, epochs=1, batch_size=32, shuffle=False)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss = gnn_model.evaluate(test_loader.load(), steps=test_loader.steps_per_epoch)\n",
    "print(f\"Test MSE loss: {test_loss:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01e2d8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "y_pred shape: (99,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CRITICAL: **Re‐instantiate** the loader for prediction\n",
    "pred_loader = DisjointLoader(test_dataset, batch_size=32, epochs=1, shuffle=False)\n",
    "y_pred = gnn_model.predict(pred_loader.load(), steps=pred_loader.steps_per_epoch).flatten()\n",
    "y_pred   = (y_pred * y_sd) + y_mu\n",
    "\n",
    "# 3) Now y_pred.shape == y_true.shape == 99\n",
    "print(\"y_pred shape:\", y_pred.shape)\n",
    "\n",
    "# 4) Plot\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "mn, mx = y_test.min(), y_test.max()\n",
    "plt.plot([mn, mx], [mn, mx], 'r--')\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Predicted vs True on Test Set\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e0f5e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4.370783e-02\n",
      "R²:  0.9854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# y_true and y_pred should be 1D NumPy arrays (e.g., from your test set)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print(f\"MSE: {mse:.6e}\")\n",
    "print(f\"MAE: {mae:.6e}\")\n",
    "print(f\"R²:  {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b35b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path('./gnn_model/')\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gnn_model.save(model_dir / 'h2o_gnn_model_scf_features_normalise.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3bfc2c",
   "metadata": {},
   "source": [
    "## Test on translational invariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f4bada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on: CNN, GNN. We have x_test, y_test\n",
    "from numpy.random import default_rng\n",
    "\n",
    "def translation(X, offset=10.0):\n",
    "    '''\n",
    "    Offset: a (3,) vector (tuple) or a scaler. \n",
    "    '''\n",
    "    off = np.asarray(offset)\n",
    "    if off.ndim == 0:\n",
    "        off = np.array([off, off, off])\n",
    "    return X + off  # broadcasting: (N,n_atoms,3) + (3,) → (N,n_atoms,3)\n",
    "\n",
    "def rotate_180_y_axis(X):\n",
    "    R = np.array([[-1, 0, 0],\n",
    "              [ 0, 1, 0],\n",
    "              [ 0, 0,-1]])\n",
    "    return X @ R.T\n",
    "\n",
    "def permutation(X, seed=None):\n",
    "    N, n_atoms, xyz = X.shape\n",
    "    rng = default_rng(seed)          # create a Generator with seed 42\n",
    "    perm = rng.permutation(n_atoms)\n",
    "    return X[:, perm, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80251d22",
   "metadata": {},
   "source": [
    "Step 1: save test dataset's energies and xyz coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "520ec029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99, 3, 70), (99,), (99, 3, 3))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape, c_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "373c5410",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'./test_xyz_{molecule}.npy', c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e26c7199",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('./test_scf_h2o_permutated.npy')\n",
    "y_test = y_test\n",
    "c_test =np.load('./test_xyz_h2o_permutated.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4511eb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 3, 70) (99,) (99, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape, y_test.shape, c_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6f7f30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "MAE: 7.125822e+00\n",
      "R²:  0.9398\n"
     ]
    }
   ],
   "source": [
    "# Create test dataset and loader\n",
    "test_dataset = SCFAtomGraphDataset(x_test, y_test, c_test, threshold=1.5)\n",
    "\n",
    "# CRITICAL: **Re‐instantiate** the loader for prediction\n",
    "pred_loader = DisjointLoader(test_dataset, batch_size=32, epochs=1, shuffle=False)\n",
    "y_pred = gnn_model.predict(pred_loader.load(), steps=pred_loader.steps_per_epoch).flatten()\n",
    "\n",
    "from sklearn.metrics import  mean_absolute_error\n",
    "\n",
    "# y_true and y_pred should be 1D NumPy arrays (e.g., from your test set)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# print(f\"MSE: {mse:.6e}\")\n",
    "print(f\"MAE: {mae:.6e}\")\n",
    "print(f\"R²:  {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
