{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "284fbbd9",
   "metadata": {},
   "source": [
    "# Attempt to copy what the paper does exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad5eaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 10:02:26.519793: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-13 10:02:26.843661: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755093746.961377    1568 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755093746.996149    1568 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755093747.253100    1568 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755093747.253165    1568 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755093747.253167    1568 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755093747.253168    1568 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-13 10:02:27.286566: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_enable_xla_devices=false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from spektral.data import Dataset, Graph\n",
    "from spektral.data.loaders import DisjointLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f837a79a",
   "metadata": {},
   "source": [
    "## Raw data input\n",
    "First change: edges are now the five SCF matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1732b948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 24) (24, 24) (24, 24) (24, 24) (24, 24)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(r'/mnt/d/UROP/pyscf-tutorial/h2o_energies_noise_scf_matrices/h2o_noise_matrices_dft_b3lyp_def2-SVP_0.npz')\n",
    "F, J, K, P, D, H, S = data['features']\n",
    "print(H.shape, F.shape, P.shape, J.shape, K.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "444084cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define this! The rest can remain untouched\n",
    "molecule = 'methanol'\n",
    "n_atoms = 6\n",
    "\n",
    "\n",
    "\n",
    "data_dir = Path(f'./{molecule}_energies_noise_scf_matrices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ade6d1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 7, 48, 48)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "C = [] # xyz coordinates\n",
    "X = [] # calculated SCF matrix features\n",
    "Y = [] # calculated energies\n",
    "\n",
    "for file_path in data_dir.glob('*.npz'):\n",
    "    data_file = np.load(file_path)\n",
    "    try:\n",
    "        C.append(data_file['coords'])\n",
    "        X.append(data_file['features'])\n",
    "        Y.append(data_file['energy'])\n",
    "\n",
    "    except KeyError:\n",
    "        raise KeyError('wrong key for npz file!')\n",
    "# you must perform stacking, cannot just convert to array    \n",
    "N, n_atoms, n_features, channels = np.stack(X).shape\n",
    "X = np.stack(X)\n",
    "C = np.stack(C)\n",
    "Y = np.stack(Y)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7542001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hartree_to_kcal_per_mol(Y):\n",
    "    return Y * 627.50961\n",
    "\n",
    "Y = hartree_to_kcal_per_mol(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bfbc371b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_mu: -45264298.38906596 y_sd: 703.9146138469423\n",
      "(700, 7, 48, 48) (700,) (700, 6, 3)\n",
      "(201, 7, 48, 48) (201,) (201, 6, 3)\n",
      "(99, 7, 48, 48) (99,) (99, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valtest, y_train, y_valtest, c_train, c_valtest = train_test_split(X, Y, C, test_size=0.3, random_state=42)\n",
    "x_val, x_test, y_val, y_test, c_val, c_test = train_test_split(x_valtest, y_valtest, c_valtest, test_size=0.33, random_state=42)\n",
    "\n",
    "# 1) compute from TRAIN ONLY\n",
    "y_mu = y_train.mean()\n",
    "y_sd = y_train.std() + 1e-8\n",
    "print(\"y_mu:\", y_mu, \"y_sd:\", y_sd )\n",
    "\n",
    "# 2) scale every split with the SAME mu/sd\n",
    "y_train_s = (y_train - y_mu) / y_sd\n",
    "y_val_s   = (y_val   - y_mu) / y_sd\n",
    "y_test_s  = (y_test  - y_mu) / y_sd  # if you have test\n",
    "\n",
    "\n",
    "print(x_train.shape, y_train.shape, c_train.shape)\n",
    "print(x_val.shape, y_val.shape, c_val.shape)\n",
    "print(x_test.shape, y_test.shape, c_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7ba132",
   "metadata": {},
   "source": [
    "Of course, we can define the edge features as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4363e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "def edge_index_and_attr(F, J, K, P, H, D=None, S=None, tau=1e-4):\n",
    "    N = F.shape[0]\n",
    "    # fallbacks\n",
    "    if D is None: D = np.zeros_like(F)\n",
    "    if S is None: S = np.zeros_like(F)\n",
    "\n",
    "    rows, cols, eattr = [], [], []\n",
    "    for u in range(N):\n",
    "        for v in range(N):\n",
    "            if u == v:\n",
    "                continue\n",
    "            xuv = np.array([\n",
    "                F[u, v], J[u, v], K[u, v], D[u, v], P[u, v], S[u, v], H[u, v]\n",
    "            ], dtype='float32')\n",
    "\n",
    "            # cutoff (pick ONE rule and keep it fixed across dataset)\n",
    "            if np.max(np.abs(xuv)) >= tau:\n",
    "                rows.append(u); cols.append(v); eattr.append(xuv)\n",
    "\n",
    "    if len(rows) == 0:\n",
    "        # Ensure graph is not empty (rare but possible with aggressive tau)\n",
    "        return sparse.coo_matrix((np.zeros((0,), dtype='float32'), ([], [])), shape=(N, N)), \\\n",
    "               np.zeros((0, 7), dtype='float32')\n",
    "\n",
    "    # strongly connected graph\n",
    "    A = sparse.csr_matrix((np.ones(len(rows), dtype='float32'), (rows, cols)), shape=(N, N))\n",
    "\n",
    "    # edges: non-diagonal elements of the five SCF matrices\n",
    "    E = np.stack(eattr, axis=0)  # (E, 7)\n",
    "    return A, E\n",
    "\n",
    "\n",
    "class SCFAtomGraphDataset(Dataset):\n",
    "    def __init__(self, X, Y, tau=1e-4, **kwargs):\n",
    "        \"\"\"\n",
    "        Dataset for SCF atom graphs.\n",
    "        \"\"\"\n",
    "        self.X = X.astype('float32')         # (N, 5, 24, 24)\n",
    "        self.Y = Y.astype('float32')         # (N,)\n",
    "        self.tau = tau\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        graphs = []\n",
    "        for x, y in zip(self.X, self.Y):\n",
    "            H, F, P, J, K, D, S = x\n",
    "            # node features: take diagonal component of all five SCF matrix\n",
    "            x = np.stack([np.diag(m) for m in (F, J ,K, P, H)], axis=-1)  # (5, 24, 24)\n",
    "            a, e = edge_index_and_attr(F, J, K, P, H, D, S, tau=self.tau)\n",
    "\n",
    "            graphs.append(Graph(x=x, a=a, y=y, e=e))\n",
    "        return graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee009aab",
   "metadata": {},
   "source": [
    "### Setting up datasets and loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ce90b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = SCFAtomGraphDataset(X=x_train, Y=y_train_s, tau=1e-4)\n",
    "val_dataset = SCFAtomGraphDataset(X=x_val, Y=y_val_s, tau=1e-4)\n",
    "test_dataset = SCFAtomGraphDataset(X=x_test, Y=y_test_s, tau=1e-4)\n",
    "\n",
    "train_loader = DisjointLoader(train_dataset, batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "val_loader = DisjointLoader(val_dataset, batch_size=batch_size, epochs=epochs, shuffle=False)\n",
    "test_loader = DisjointLoader(test_dataset, batch_size=batch_size, epochs=epochs, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d5ed98",
   "metadata": {},
   "source": [
    "## Model Compilation\n",
    "Customize message passing, instead of just GraphSageConv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a257d5",
   "metadata": {},
   "source": [
    "### Model 1: Ordinary GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "61426d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.layers import GraphSageConv, GlobalSumPool\n",
    "'''\n",
    "tried: GCNConv (only accepts [x,a], cannot accept disjoint batches\n",
    "GCSConv (shape mismatch)\n",
    "GINConv (tf error)\n",
    "GraphSageConv + disable XLA flag + operate on CPU (forced). Both must be present for it work somehow.\n",
    "'''\n",
    "@keras.saving.register_keras_serializable(package=\"custom\")\n",
    "class GNNModel(tf.keras.Model):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        he_init = tf.keras.initializers.HeNormal()\n",
    "\n",
    "        # ReLU and GeLU layers are best with HeNormal. Default is GlorotUniform, which isn't the most ideal; does not affect performance\n",
    "        self.conv1 = GraphSageConv(64, activation='relu', kernel_initializer=he_init, bias_initializer='zeros') \n",
    "        self.conv2 = GraphSageConv(64, activation='relu', kernel_initializer=he_init, bias_initializer='zeros')\n",
    "        self.pool = GlobalSumPool()\n",
    "        self.dense = tf.keras.layers.Dense(1, \n",
    "                                           kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05),\n",
    "                                           bias_initializer='zeros')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # supports both with/without edge features\n",
    "        if len(inputs) == 4:\n",
    "            x, a, e, i = inputs\n",
    "            x = self.conv1([x, a, e])\n",
    "            x = self.conv2([x, a, e])\n",
    "        else:\n",
    "            x, a, i = inputs\n",
    "            x = self.conv1([x, a])\n",
    "            x = self.conv2([x, a])\n",
    "\n",
    "        out = self.pool([x, i])\n",
    "        return self.dense(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6ab550a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "def train_GNN(train_loader, val_loader,\n",
    "              epochs=10, batch_size=32, threshold=2.5, verbose=0):\n",
    "\n",
    "    model = GNNModel()\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1000, min_lr=1e-6)\n",
    "    # model.compile(optimizer='adam', loss='mse')\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='mse')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=1300, restore_best_weights=True)\n",
    "\n",
    "    # Train\n",
    "    history = model.fit(train_loader.load(), steps_per_epoch=train_loader.steps_per_epoch,\n",
    "                        validation_data=val_loader.load(), validation_steps=val_loader.steps_per_epoch,\n",
    "                        epochs=epochs, verbose=verbose,callbacks=[lr_scheduler, early_stop])    \n",
    "    \n",
    "    return model, history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "904c3823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizhou_chen/miniconda3/envs/base-ml/lib/python3.12/site-packages/spektral/data/utils.py:221: UserWarning: you are shuffling a 'SCFAtomGraphDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 1.1025 - val_loss: 0.7611 - learning_rate: 0.0010\n",
      "Epoch 2/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0320 - val_loss: 0.7688 - learning_rate: 0.0010\n",
      "Epoch 3/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m 24ms/step - loss: 1.0206 - val_loss: 0.8438 - learning_rate: 0.0010\n",
      "Epoch 4/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0163 - val_loss: 0.7914 - learning_rate: 0.0010\n",
      "Epoch 5/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9932 - val_loss: 0.7507 - learning_rate: 0.0010\n",
      "Epoch 6/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9978 - val_loss: 0.7496 - learning_rate: 0.0010\n",
      "Epoch 7/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0155 - val_loss: 0.7490 - learning_rate: 0.0010\n",
      "Epoch 8/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0223 - val_loss: 0.7511 - learning_rate: 0.0010\n",
      "Epoch 9/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0108 - val_loss: 0.7511 - learning_rate: 0.0010\n",
      "Epoch 10/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0232 - val_loss: 0.7831 - learning_rate: 0.0010\n",
      "Epoch 11/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9901 - val_loss: 0.7574 - learning_rate: 0.0010\n",
      "Epoch 12/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9849 - val_loss: 0.7533 - learning_rate: 0.0010\n",
      "Epoch 13/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0159 - val_loss: 0.7546 - learning_rate: 0.0010\n",
      "Epoch 14/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9979 - val_loss: 0.7647 - learning_rate: 0.0010\n",
      "Epoch 15/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.0428 - val_loss: 0.7533 - learning_rate: 0.0010\n",
      "Epoch 16/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9739 - val_loss: 0.7519 - learning_rate: 0.0010\n",
      "Epoch 17/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0106 - val_loss: 0.7501 - learning_rate: 0.0010\n",
      "Epoch 18/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0799 - val_loss: 0.7498 - learning_rate: 0.0010\n",
      "Epoch 19/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9291 - val_loss: 0.7572 - learning_rate: 0.0010\n",
      "Epoch 20/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0052 - val_loss: 0.8292 - learning_rate: 0.0010\n",
      "Epoch 21/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0327 - val_loss: 0.7553 - learning_rate: 0.0010\n",
      "Epoch 22/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9936 - val_loss: 0.7506 - learning_rate: 0.0010\n",
      "Epoch 23/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.0353 - val_loss: 0.7747 - learning_rate: 0.0010\n",
      "Epoch 24/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0073 - val_loss: 0.7496 - learning_rate: 0.0010\n",
      "Epoch 25/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9734 - val_loss: 0.7499 - learning_rate: 0.0010\n",
      "Epoch 26/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0100 - val_loss: 0.8221 - learning_rate: 0.0010\n",
      "Epoch 27/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.0554 - val_loss: 0.7490 - learning_rate: 0.0010\n",
      "Epoch 28/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9774 - val_loss: 0.7518 - learning_rate: 0.0010\n",
      "Epoch 29/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0060 - val_loss: 0.7622 - learning_rate: 0.0010\n",
      "Epoch 30/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0066 - val_loss: 0.7523 - learning_rate: 0.0010\n",
      "Epoch 31/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9942 - val_loss: 0.7756 - learning_rate: 0.0010\n",
      "Epoch 32/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0065 - val_loss: 0.7507 - learning_rate: 0.0010\n",
      "Epoch 33/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0075 - val_loss: 0.7523 - learning_rate: 0.0010\n",
      "Epoch 34/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0086 - val_loss: 0.7644 - learning_rate: 0.0010\n",
      "Epoch 35/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9866 - val_loss: 0.7504 - learning_rate: 0.0010\n",
      "Epoch 36/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0192 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 37/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.9915 - val_loss: 0.7572 - learning_rate: 0.0010\n",
      "Epoch 38/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.9986 - val_loss: 0.7516 - learning_rate: 0.0010\n",
      "Epoch 39/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0451 - val_loss: 0.7496 - learning_rate: 0.0010\n",
      "Epoch 40/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9843 - val_loss: 0.7604 - learning_rate: 0.0010\n",
      "Epoch 41/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0603 - val_loss: 0.7737 - learning_rate: 0.0010\n",
      "Epoch 42/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9572 - val_loss: 0.7512 - learning_rate: 0.0010\n",
      "Epoch 43/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0233 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 44/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9773 - val_loss: 0.7510 - learning_rate: 0.0010\n",
      "Epoch 45/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9967 - val_loss: 0.7598 - learning_rate: 0.0010\n",
      "Epoch 46/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9991 - val_loss: 0.7523 - learning_rate: 0.0010\n",
      "Epoch 47/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0300 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 48/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0335 - val_loss: 0.7553 - learning_rate: 0.0010\n",
      "Epoch 49/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9371 - val_loss: 0.7594 - learning_rate: 0.0010\n",
      "Epoch 50/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0438 - val_loss: 0.7515 - learning_rate: 0.0010\n",
      "Epoch 51/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9821 - val_loss: 0.7492 - learning_rate: 0.0010\n",
      "Epoch 52/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0001 - val_loss: 0.7600 - learning_rate: 0.0010\n",
      "Epoch 53/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9903 - val_loss: 0.7550 - learning_rate: 0.0010\n",
      "Epoch 54/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0756 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 55/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9538 - val_loss: 0.7495 - learning_rate: 0.0010\n",
      "Epoch 56/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9821 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 57/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0087 - val_loss: 0.7603 - learning_rate: 0.0010\n",
      "Epoch 58/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0117 - val_loss: 0.7541 - learning_rate: 0.0010\n",
      "Epoch 59/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0132 - val_loss: 0.7565 - learning_rate: 0.0010\n",
      "Epoch 60/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9671 - val_loss: 0.7522 - learning_rate: 0.0010\n",
      "Epoch 61/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0371 - val_loss: 0.7598 - learning_rate: 0.0010\n",
      "Epoch 62/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -33918us/step - loss: 1.0451 - val_loss: 0.7513 - learning_rate: 0.0010\n",
      "Epoch 63/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9364 - val_loss: 0.7594 - learning_rate: 0.0010\n",
      "Epoch 64/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0220 - val_loss: 0.7501 - learning_rate: 0.0010\n",
      "Epoch 65/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9895 - val_loss: 0.7549 - learning_rate: 0.0010\n",
      "Epoch 66/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0113 - val_loss: 0.7577 - learning_rate: 0.0010\n",
      "Epoch 67/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9894 - val_loss: 0.7529 - learning_rate: 0.0010\n",
      "Epoch 68/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9982 - val_loss: 0.7592 - learning_rate: 0.0010\n",
      "Epoch 69/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0178 - val_loss: 0.7604 - learning_rate: 0.0010\n",
      "Epoch 70/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9858 - val_loss: 0.7599 - learning_rate: 0.0010\n",
      "Epoch 71/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0018 - val_loss: 0.7532 - learning_rate: 0.0010\n",
      "Epoch 72/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9992 - val_loss: 0.7613 - learning_rate: 0.0010\n",
      "Epoch 73/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0307 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 74/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9743 - val_loss: 0.7572 - learning_rate: 0.0010\n",
      "Epoch 75/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0229 - val_loss: 0.7573 - learning_rate: 0.0010\n",
      "Epoch 76/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9877 - val_loss: 0.7530 - learning_rate: 0.0010\n",
      "Epoch 77/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9996 - val_loss: 0.7553 - learning_rate: 0.0010\n",
      "Epoch 78/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9967 - val_loss: 0.7548 - learning_rate: 0.0010\n",
      "Epoch 79/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0444 - val_loss: 0.7572 - learning_rate: 0.0010\n",
      "Epoch 80/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9934 - val_loss: 0.7600 - learning_rate: 0.0010\n",
      "Epoch 81/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0007 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 82/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9886 - val_loss: 0.7571 - learning_rate: 0.0010\n",
      "Epoch 83/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0890 - val_loss: 0.7566 - learning_rate: 0.0010\n",
      "Epoch 84/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.9341 - val_loss: 0.7584 - learning_rate: 0.0010\n",
      "Epoch 85/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.0115 - val_loss: 0.7541 - learning_rate: 0.0010\n",
      "Epoch 86/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.9820 - val_loss: 0.7545 - learning_rate: 0.0010\n",
      "Epoch 87/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0726 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 88/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9309 - val_loss: 0.7532 - learning_rate: 0.0010\n",
      "Epoch 89/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0946 - val_loss: 0.7587 - learning_rate: 0.0010\n",
      "Epoch 90/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9423 - val_loss: 0.7585 - learning_rate: 0.0010\n",
      "Epoch 91/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9739 - val_loss: 0.7506 - learning_rate: 0.0010\n",
      "Epoch 92/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0121 - val_loss: 0.7577 - learning_rate: 0.0010\n",
      "Epoch 93/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0118 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 94/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9911 - val_loss: 0.7584 - learning_rate: 0.0010\n",
      "Epoch 95/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9922 - val_loss: 0.7538 - learning_rate: 0.0010\n",
      "Epoch 96/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0287 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 97/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0910 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 98/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.8966 - val_loss: 0.7505 - learning_rate: 0.0010\n",
      "Epoch 99/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9880 - val_loss: 0.7583 - learning_rate: 0.0010\n",
      "Epoch 100/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0447 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 101/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9739 - val_loss: 0.7567 - learning_rate: 0.0010\n",
      "Epoch 102/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0081 - val_loss: 0.7527 - learning_rate: 0.0010\n",
      "Epoch 103/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9984 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 104/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0211 - val_loss: 0.7531 - learning_rate: 0.0010\n",
      "Epoch 105/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0016 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 106/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9708 - val_loss: 0.7528 - learning_rate: 0.0010\n",
      "Epoch 107/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0314 - val_loss: 0.7573 - learning_rate: 0.0010\n",
      "Epoch 108/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0005 - val_loss: 0.7572 - learning_rate: 0.0010\n",
      "Epoch 109/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9738 - val_loss: 0.7553 - learning_rate: 0.0010\n",
      "Epoch 110/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0172 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 111/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0135 - val_loss: 0.7582 - learning_rate: 0.0010\n",
      "Epoch 112/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9887 - val_loss: 0.7569 - learning_rate: 0.0010\n",
      "Epoch 113/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0210 - val_loss: 0.7537 - learning_rate: 0.0010\n",
      "Epoch 114/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9715 - val_loss: 0.7596 - learning_rate: 0.0010\n",
      "Epoch 115/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0076 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 116/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0051 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 117/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9987 - val_loss: 0.7551 - learning_rate: 0.0010\n",
      "Epoch 118/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0279 - val_loss: 0.7641 - learning_rate: 0.0010\n",
      "Epoch 119/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9903 - val_loss: 0.7525 - learning_rate: 0.0010\n",
      "Epoch 120/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0029 - val_loss: 0.7634 - learning_rate: 0.0010\n",
      "Epoch 121/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0030 - val_loss: 0.7531 - learning_rate: 0.0010\n",
      "Epoch 122/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0098 - val_loss: 0.7544 - learning_rate: 0.0010\n",
      "Epoch 123/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0064 - val_loss: 0.7550 - learning_rate: 0.0010\n",
      "Epoch 124/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -35621us/step - loss: 0.9581 - val_loss: 0.7550 - learning_rate: 0.0010\n",
      "Epoch 125/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0018 - val_loss: 0.7580 - learning_rate: 0.0010\n",
      "Epoch 126/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0081 - val_loss: 0.7543 - learning_rate: 0.0010\n",
      "Epoch 127/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0006 - val_loss: 0.7612 - learning_rate: 0.0010\n",
      "Epoch 128/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0373 - val_loss: 0.7547 - learning_rate: 0.0010\n",
      "Epoch 129/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9733 - val_loss: 0.7617 - learning_rate: 0.0010\n",
      "Epoch 130/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0299 - val_loss: 0.7548 - learning_rate: 0.0010\n",
      "Epoch 131/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9686 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 132/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0439 - val_loss: 0.7580 - learning_rate: 0.0010\n",
      "Epoch 133/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9734 - val_loss: 0.7537 - learning_rate: 0.0010\n",
      "Epoch 134/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9823 - val_loss: 0.7534 - learning_rate: 0.0010\n",
      "Epoch 135/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0003 - val_loss: 0.7568 - learning_rate: 0.0010\n",
      "Epoch 136/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0338 - val_loss: 0.7544 - learning_rate: 0.0010\n",
      "Epoch 137/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9960 - val_loss: 0.7569 - learning_rate: 0.0010\n",
      "Epoch 138/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9878 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 139/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0444 - val_loss: 0.7542 - learning_rate: 0.0010\n",
      "Epoch 140/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9529 - val_loss: 0.7578 - learning_rate: 0.0010\n",
      "Epoch 141/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9966 - val_loss: 0.7546 - learning_rate: 0.0010\n",
      "Epoch 142/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0054 - val_loss: 0.7569 - learning_rate: 0.0010\n",
      "Epoch 143/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0269 - val_loss: 0.7579 - learning_rate: 0.0010\n",
      "Epoch 144/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9729 - val_loss: 0.7575 - learning_rate: 0.0010\n",
      "Epoch 145/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0291 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 146/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9822 - val_loss: 0.7548 - learning_rate: 0.0010\n",
      "Epoch 147/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0289 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 148/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9760 - val_loss: 0.7542 - learning_rate: 0.0010\n",
      "Epoch 149/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0052 - val_loss: 0.7543 - learning_rate: 0.0010\n",
      "Epoch 150/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9990 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 151/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0023 - val_loss: 0.7550 - learning_rate: 0.0010\n",
      "Epoch 152/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0049 - val_loss: 0.7573 - learning_rate: 0.0010\n",
      "Epoch 153/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0442 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 154/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9518 - val_loss: 0.7550 - learning_rate: 0.0010\n",
      "Epoch 155/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0218 - val_loss: 0.7563 - learning_rate: 0.0010\n",
      "Epoch 156/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9886 - val_loss: 0.7551 - learning_rate: 0.0010\n",
      "Epoch 157/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0040 - val_loss: 0.7576 - learning_rate: 0.0010\n",
      "Epoch 158/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9942 - val_loss: 0.7544 - learning_rate: 0.0010\n",
      "Epoch 159/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0244 - val_loss: 0.7582 - learning_rate: 0.0010\n",
      "Epoch 160/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9739 - val_loss: 0.7531 - learning_rate: 0.0010\n",
      "Epoch 161/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9949 - val_loss: 0.7532 - learning_rate: 0.0010\n",
      "Epoch 162/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9936 - val_loss: 0.7569 - learning_rate: 0.0010\n",
      "Epoch 163/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0150 - val_loss: 0.7573 - learning_rate: 0.0010\n",
      "Epoch 164/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0153 - val_loss: 0.7527 - learning_rate: 0.0010\n",
      "Epoch 165/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9771 - val_loss: 0.7565 - learning_rate: 0.0010\n",
      "Epoch 166/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0152 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 167/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0029 - val_loss: 0.7576 - learning_rate: 0.0010\n",
      "Epoch 168/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9798 - val_loss: 0.7543 - learning_rate: 0.0010\n",
      "Epoch 169/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.0201 - val_loss: 0.7545 - learning_rate: 0.0010\n",
      "Epoch 170/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0410 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 171/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9611 - val_loss: 0.7570 - learning_rate: 0.0010\n",
      "Epoch 172/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9926 - val_loss: 0.7549 - learning_rate: 0.0010\n",
      "Epoch 173/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9906 - val_loss: 0.7542 - learning_rate: 0.0010\n",
      "Epoch 174/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0569 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 175/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9506 - val_loss: 0.7573 - learning_rate: 0.0010\n",
      "Epoch 176/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0380 - val_loss: 0.7567 - learning_rate: 0.0010\n",
      "Epoch 177/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9662 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 178/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0070 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 179/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9929 - val_loss: 0.7543 - learning_rate: 0.0010\n",
      "Epoch 180/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0326 - val_loss: 0.7546 - learning_rate: 0.0010\n",
      "Epoch 181/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9762 - val_loss: 0.7576 - learning_rate: 0.0010\n",
      "Epoch 182/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0003 - val_loss: 0.7534 - learning_rate: 0.0010\n",
      "Epoch 183/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0098 - val_loss: 0.7587 - learning_rate: 0.0010\n",
      "Epoch 184/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0107 - val_loss: 0.7566 - learning_rate: 0.0010\n",
      "Epoch 185/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9946 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 186/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -35316us/step - loss: 0.9923 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 187/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0001 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 188/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0634 - val_loss: 0.7521 - learning_rate: 0.0010\n",
      "Epoch 189/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9322 - val_loss: 0.7571 - learning_rate: 0.0010\n",
      "Epoch 190/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0296 - val_loss: 0.7570 - learning_rate: 0.0010\n",
      "Epoch 191/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9724 - val_loss: 0.7551 - learning_rate: 0.0010\n",
      "Epoch 192/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0001 - val_loss: 0.7538 - learning_rate: 0.0010\n",
      "Epoch 193/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0036 - val_loss: 0.7545 - learning_rate: 0.0010\n",
      "Epoch 194/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0056 - val_loss: 0.7578 - learning_rate: 0.0010\n",
      "Epoch 195/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9926 - val_loss: 0.7545 - learning_rate: 0.0010\n",
      "Epoch 196/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9988 - val_loss: 0.7537 - learning_rate: 0.0010\n",
      "Epoch 197/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.1108 - val_loss: 0.7582 - learning_rate: 0.0010\n",
      "Epoch 198/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.8874 - val_loss: 0.7548 - learning_rate: 0.0010\n",
      "Epoch 199/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0456 - val_loss: 0.7551 - learning_rate: 0.0010\n",
      "Epoch 200/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9915 - val_loss: 0.7537 - learning_rate: 0.0010\n",
      "Epoch 201/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9872 - val_loss: 0.7565 - learning_rate: 0.0010\n",
      "Epoch 202/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9899 - val_loss: 0.7617 - learning_rate: 0.0010\n",
      "Epoch 203/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0641 - val_loss: 0.7533 - learning_rate: 0.0010\n",
      "Epoch 204/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9469 - val_loss: 0.7521 - learning_rate: 0.0010\n",
      "Epoch 205/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0188 - val_loss: 0.7595 - learning_rate: 0.0010\n",
      "Epoch 206/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9826 - val_loss: 0.7548 - learning_rate: 0.0010\n",
      "Epoch 207/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0403 - val_loss: 0.7568 - learning_rate: 0.0010\n",
      "Epoch 208/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9923 - val_loss: 0.7565 - learning_rate: 0.0010\n",
      "Epoch 209/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9728 - val_loss: 0.7539 - learning_rate: 0.0010\n",
      "Epoch 210/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0001 - val_loss: 0.7565 - learning_rate: 0.0010\n",
      "Epoch 211/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0404 - val_loss: 0.7532 - learning_rate: 0.0010\n",
      "Epoch 212/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9715 - val_loss: 0.7594 - learning_rate: 0.0010\n",
      "Epoch 213/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9983 - val_loss: 0.7551 - learning_rate: 0.0010\n",
      "Epoch 214/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0064 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 215/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0164 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 216/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9720 - val_loss: 0.7545 - learning_rate: 0.0010\n",
      "Epoch 217/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0661 - val_loss: 0.7566 - learning_rate: 0.0010\n",
      "Epoch 218/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9604 - val_loss: 0.7547 - learning_rate: 0.0010\n",
      "Epoch 219/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9644 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 220/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0263 - val_loss: 0.7575 - learning_rate: 0.0010\n",
      "Epoch 221/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0052 - val_loss: 0.7564 - learning_rate: 0.0010\n",
      "Epoch 222/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0683 - val_loss: 0.7536 - learning_rate: 0.0010\n",
      "Epoch 223/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9067 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 224/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9969 - val_loss: 0.7584 - learning_rate: 0.0010\n",
      "Epoch 225/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0005 - val_loss: 0.7540 - learning_rate: 0.0010\n",
      "Epoch 226/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0875 - val_loss: 0.7564 - learning_rate: 0.0010\n",
      "Epoch 227/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9155 - val_loss: 0.7579 - learning_rate: 0.0010\n",
      "Epoch 228/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0230 - val_loss: 0.7571 - learning_rate: 0.0010\n",
      "Epoch 229/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9846 - val_loss: 0.7545 - learning_rate: 0.0010\n",
      "Epoch 230/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9997 - val_loss: 0.7572 - learning_rate: 0.0010\n",
      "Epoch 231/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0138 - val_loss: 0.7536 - learning_rate: 0.0010\n",
      "Epoch 232/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0074 - val_loss: 0.7573 - learning_rate: 0.0010\n",
      "Epoch 233/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0059 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 234/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9866 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 235/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0427 - val_loss: 0.7582 - learning_rate: 0.0010\n",
      "Epoch 236/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9471 - val_loss: 0.7528 - learning_rate: 0.0010\n",
      "Epoch 237/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0315 - val_loss: 0.7564 - learning_rate: 0.0010\n",
      "Epoch 238/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0032 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 239/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9845 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 240/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0217 - val_loss: 0.7571 - learning_rate: 0.0010\n",
      "Epoch 241/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9980 - val_loss: 0.7553 - learning_rate: 0.0010\n",
      "Epoch 242/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9622 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 243/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0420 - val_loss: 0.7563 - learning_rate: 0.0010\n",
      "Epoch 244/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9585 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 245/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0135 - val_loss: 0.7551 - learning_rate: 0.0010\n",
      "Epoch 246/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0402 - val_loss: 0.7567 - learning_rate: 0.0010\n",
      "Epoch 247/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9606 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 248/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9945 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 249/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -35265us/step - loss: 1.0118 - val_loss: 0.7565 - learning_rate: 0.0010\n",
      "Epoch 250/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9871 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 251/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0194 - val_loss: 0.7567 - learning_rate: 0.0010\n",
      "Epoch 252/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0218 - val_loss: 0.7547 - learning_rate: 0.0010\n",
      "Epoch 253/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9792 - val_loss: 0.7547 - learning_rate: 0.0010\n",
      "Epoch 254/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9962 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 255/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0208 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 256/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9768 - val_loss: 0.7536 - learning_rate: 0.0010\n",
      "Epoch 257/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9913 - val_loss: 0.7563 - learning_rate: 0.0010\n",
      "Epoch 258/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0477 - val_loss: 0.7590 - learning_rate: 0.0010\n",
      "Epoch 259/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9737 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 260/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9885 - val_loss: 0.7549 - learning_rate: 0.0010\n",
      "Epoch 261/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9958 - val_loss: 0.7564 - learning_rate: 0.0010\n",
      "Epoch 262/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9976 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 263/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0212 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 264/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0205 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 265/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0073 - val_loss: 0.7547 - learning_rate: 0.0010\n",
      "Epoch 266/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9798 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 267/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9928 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 268/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0195 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 269/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9834 - val_loss: 0.7553 - learning_rate: 0.0010\n",
      "Epoch 270/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9774 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 271/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0643 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 272/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9302 - val_loss: 0.7573 - learning_rate: 0.0010\n",
      "Epoch 273/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0264 - val_loss: 0.7550 - learning_rate: 0.0010\n",
      "Epoch 274/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0496 - val_loss: 0.7542 - learning_rate: 0.0010\n",
      "Epoch 275/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9361 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 276/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0744 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 277/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9569 - val_loss: 0.7570 - learning_rate: 0.0010\n",
      "Epoch 278/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9911 - val_loss: 0.7548 - learning_rate: 0.0010\n",
      "Epoch 279/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9982 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 280/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0166 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 281/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9894 - val_loss: 0.7566 - learning_rate: 0.0010\n",
      "Epoch 282/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9737 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 283/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0176 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 284/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0105 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 285/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9871 - val_loss: 0.7551 - learning_rate: 0.0010\n",
      "Epoch 286/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9863 - val_loss: 0.7577 - learning_rate: 0.0010\n",
      "Epoch 287/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0199 - val_loss: 0.7570 - learning_rate: 0.0010\n",
      "Epoch 288/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0310 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 289/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9688 - val_loss: 0.7535 - learning_rate: 0.0010\n",
      "Epoch 290/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9923 - val_loss: 0.7540 - learning_rate: 0.0010\n",
      "Epoch 291/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0019 - val_loss: 0.7567 - learning_rate: 0.0010\n",
      "Epoch 292/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0266 - val_loss: 0.7567 - learning_rate: 0.0010\n",
      "Epoch 293/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9665 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 294/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0297 - val_loss: 0.7566 - learning_rate: 0.0010\n",
      "Epoch 295/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9887 - val_loss: 0.7549 - learning_rate: 0.0010\n",
      "Epoch 296/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0039 - val_loss: 0.7548 - learning_rate: 0.0010\n",
      "Epoch 297/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9923 - val_loss: 0.7570 - learning_rate: 0.0010\n",
      "Epoch 298/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0223 - val_loss: 0.7545 - learning_rate: 0.0010\n",
      "Epoch 299/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9787 - val_loss: 0.7572 - learning_rate: 0.0010\n",
      "Epoch 300/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0053 - val_loss: 0.7569 - learning_rate: 0.0010\n",
      "Epoch 301/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0049 - val_loss: 0.7546 - learning_rate: 0.0010\n",
      "Epoch 302/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0172 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 303/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9719 - val_loss: 0.7547 - learning_rate: 0.0010\n",
      "Epoch 304/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0309 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 305/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9852 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 306/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9826 - val_loss: 0.7567 - learning_rate: 0.0010\n",
      "Epoch 307/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0194 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 308/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9914 - val_loss: 0.7549 - learning_rate: 0.0010\n",
      "Epoch 309/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9972 - val_loss: 0.7570 - learning_rate: 0.0010\n",
      "Epoch 310/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0126 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 311/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9920 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 312/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -37484us/step - loss: 0.9836 - val_loss: 0.7549 - learning_rate: 0.0010\n",
      "Epoch 313/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0182 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 314/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0483 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 315/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9528 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 316/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0004 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 317/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9896 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 318/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0172 - val_loss: 0.7551 - learning_rate: 0.0010\n",
      "Epoch 319/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0020 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 320/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9809 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 321/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0102 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 322/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9860 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 323/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0331 - val_loss: 0.7553 - learning_rate: 0.0010\n",
      "Epoch 324/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0012 - val_loss: 0.7545 - learning_rate: 0.0010\n",
      "Epoch 325/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9750 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 326/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0127 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 327/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0117 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 328/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9821 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 329/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0127 - val_loss: 0.7566 - learning_rate: 0.0010\n",
      "Epoch 330/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9695 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 331/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0064 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 332/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0197 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 333/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9769 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 334/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.0202 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 335/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9958 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 336/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0247 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 337/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0420 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 338/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9199 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 339/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0127 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 340/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0087 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 341/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9976 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 342/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0106 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 343/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0338 - val_loss: 0.7553 - learning_rate: 0.0010\n",
      "Epoch 344/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9614 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 345/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9730 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 346/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0031 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 347/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0159 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 348/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9905 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 349/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9912 - val_loss: 0.7553 - learning_rate: 0.0010\n",
      "Epoch 350/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0010 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 351/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0184 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 352/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9778 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 353/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0783 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 354/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9441 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 355/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9929 - val_loss: 0.7553 - learning_rate: 0.0010\n",
      "Epoch 356/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0051 - val_loss: 0.7551 - learning_rate: 0.0010\n",
      "Epoch 357/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9996 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 358/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9965 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 359/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9938 - val_loss: 0.7553 - learning_rate: 0.0010\n",
      "Epoch 360/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9981 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 361/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0254 - val_loss: 0.7564 - learning_rate: 0.0010\n",
      "Epoch 362/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0536 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 363/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9534 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 364/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9675 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 365/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0091 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 366/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0546 - val_loss: 0.7551 - learning_rate: 0.0010\n",
      "Epoch 367/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9490 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 368/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0178 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 369/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0025 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 370/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9804 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 371/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9906 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 372/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0096 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 373/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9970 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 374/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -37003us/step - loss: 0.9967 - val_loss: 0.7553 - learning_rate: 0.0010\n",
      "Epoch 375/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0031 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 376/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9858 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 377/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0003 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 378/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0249 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 379/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0066 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 380/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9792 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 381/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0150 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 382/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9800 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 383/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0204 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 384/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9929 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 385/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9925 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 386/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0065 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 387/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0006 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 388/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9926 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 389/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9957 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 390/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0259 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 391/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9932 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 392/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0256 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 393/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9582 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 394/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0050 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 395/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0378 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 396/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9561 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 397/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9961 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 398/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0516 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 399/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9714 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 400/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9890 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 401/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0064 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 402/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9858 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 403/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0303 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 404/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9870 - val_loss: 0.7553 - learning_rate: 0.0010\n",
      "Epoch 405/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9848 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 406/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0231 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 407/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9775 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 408/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0226 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 409/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9934 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 410/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9838 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 411/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0277 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 412/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9730 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 413/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0232 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 414/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9757 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 415/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0964 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 416/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9120 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 417/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0077 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 418/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9762 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 419/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0064 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 420/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0158 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 421/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9900 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 422/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0125 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 423/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0153 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 424/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9708 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 425/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0567 - val_loss: 0.7553 - learning_rate: 0.0010\n",
      "Epoch 426/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9625 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 427/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0093 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 428/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0040 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 429/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9829 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 430/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0180 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 431/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9808 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 432/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9790 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 433/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0044 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 434/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0334 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 435/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9872 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 436/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9908 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 437/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -37436us/step - loss: 1.0043 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 438/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9971 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 439/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0525 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 440/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0365 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 441/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9357 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 442/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9684 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 443/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0366 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 444/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9655 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 445/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0133 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 446/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9672 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 447/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0059 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 448/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0193 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 449/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9949 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 450/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0068 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 451/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0182 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 452/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0218 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 453/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9573 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 454/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9854 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 455/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0588 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 456/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9674 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 457/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9860 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 458/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9986 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 459/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9976 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 460/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0439 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 461/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9423 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 462/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0030 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 463/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0491 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 464/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9721 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 465/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9919 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 466/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0252 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 467/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0577 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 468/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9253 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 469/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9818 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 470/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0299 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 471/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9957 - val_loss: 0.7564 - learning_rate: 0.0010\n",
      "Epoch 472/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9847 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 473/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0272 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 474/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9723 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 475/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9921 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 476/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0024 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 477/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0192 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 478/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0160 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 479/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9751 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 480/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0392 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 481/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9470 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 482/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0305 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 483/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9825 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 484/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0138 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 485/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9939 - val_loss: 0.7553 - learning_rate: 0.0010\n",
      "Epoch 486/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0075 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 487/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9741 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 488/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0024 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 489/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9934 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 490/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0245 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 491/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0100 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 492/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9709 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 493/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0874 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 494/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9409 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 495/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9891 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 496/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9904 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 497/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -50529us/step - loss: 1.0056 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 498/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0248 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 499/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9891 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 500/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9909 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 501/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0036 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 502/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9933 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 503/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0173 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 504/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9690 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 505/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0237 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 506/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9740 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 507/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0173 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 508/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9923 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 509/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0012 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 510/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9896 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 511/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0075 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 512/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9979 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 513/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0095 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 514/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0185 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 515/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0049 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 516/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9785 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 517/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0006 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 518/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9971 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 519/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0124 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 520/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9929 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 521/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.0143 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 522/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0560 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 523/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0153 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 524/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9247 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 525/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9825 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 526/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9967 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 527/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0186 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 528/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0416 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 529/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9737 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 530/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9982 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 531/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9698 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 532/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0262 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 533/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9924 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 534/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9897 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 535/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9879 - val_loss: 0.7553 - learning_rate: 0.0010\n",
      "Epoch 536/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0178 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 537/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9928 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 538/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0147 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 539/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9854 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 540/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9990 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 541/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0168 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 542/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9795 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 543/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0242 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 544/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9879 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 545/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0499 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 546/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9491 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 547/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0225 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 548/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9583 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 549/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0475 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 550/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9572 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 551/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0023 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 552/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9977 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 553/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0336 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 554/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9836 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 555/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9890 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 556/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9879 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 557/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0369 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 558/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0039 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 559/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -43725us/step - loss: 0.9758 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 560/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0178 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 561/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0050 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 562/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9674 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 563/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0087 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 564/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0018 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 565/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0071 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 566/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9869 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 567/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0221 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 568/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9881 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 569/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9900 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 570/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0027 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 571/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9962 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 572/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9999 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 573/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0610 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 574/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9469 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 575/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0025 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 576/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0036 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 577/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9787 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 578/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0174 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 579/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9869 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 580/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0442 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 581/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9927 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 582/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9644 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 583/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0190 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 584/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9924 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 585/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0081 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 586/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9788 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 587/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0819 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 588/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9261 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 589/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0319 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 590/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9820 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 591/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0008 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 592/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9731 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 593/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.1141 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 594/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9134 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 595/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9879 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 596/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0170 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 597/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9894 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 598/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0233 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 599/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9772 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 600/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0134 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 601/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9729 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 602/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0107 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 603/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9828 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 604/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0482 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 605/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9622 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 606/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0238 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 607/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9846 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 608/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9990 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 609/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9881 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 610/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0206 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 611/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0098 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 612/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0127 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 613/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9830 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 614/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0298 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 615/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9702 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 616/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9930 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 617/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0121 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 618/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9683 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 619/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0404 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 620/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -38890us/step - loss: 1.0187 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 621/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9487 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 622/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0235 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 623/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0073 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 624/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9820 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 625/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0689 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 626/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9288 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 627/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0107 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 628/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0205 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 629/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9675 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 630/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9874 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 631/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0376 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 632/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9601 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 633/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0040 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 634/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0067 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 635/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9967 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 636/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0028 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 637/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9957 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 638/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.9963 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 639/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0126 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 640/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9885 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 641/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0091 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 642/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9909 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 643/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0044 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 644/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.1076 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 645/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9054 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 646/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.9909 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 647/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.0006 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 648/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.0282 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 649/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.9976 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 650/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.9710 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 651/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.9977 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 652/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.0051 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 653/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.9897 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 654/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.0648 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 655/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.9357 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 656/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.0157 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 657/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.9982 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 658/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.9997 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 659/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.0197 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 660/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.9736 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 661/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.0022 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 662/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.0160 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 663/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.9832 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 664/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.9939 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 665/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.9991 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 666/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.9995 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 667/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.0992 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 668/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.8953 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 669/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.0726 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 670/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.9589 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 671/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.0147 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 672/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.0123 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 673/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -32757us/step - loss: 0.9684 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 674/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.9854 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 675/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.9936 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 676/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.0105 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 677/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.0954 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 678/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.9201 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 679/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.9955 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 680/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.0092 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 681/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.9852 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 682/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.9838 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 683/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.0072 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 684/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.9922 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 685/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.0327 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 686/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.9814 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 687/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.9996 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 688/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.9926 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 689/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.0175 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 690/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.9778 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 691/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0085 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 692/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9944 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 693/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9928 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 694/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0376 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 695/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0008 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 696/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9746 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 697/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0047 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 698/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9972 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 699/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9912 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 700/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.9934 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 701/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0242 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 702/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0207 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 703/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9825 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 704/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0510 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 705/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9463 - val_loss: 0.7559 - learning_rate: 0.0010\n",
      "Epoch 706/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9787 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 707/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0053 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 708/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0043 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 709/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9973 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 710/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0172 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 711/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9830 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 712/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0254 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 713/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9949 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 714/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9751 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 715/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0191 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 716/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0246 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 717/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0242 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 718/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9495 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 719/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0183 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 720/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9719 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 721/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0242 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 722/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9909 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 723/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9845 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 724/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0078 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 725/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0203 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 726/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9839 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 727/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0111 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 728/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9825 - val_loss: 0.7557 - learning_rate: 0.0010\n",
      "Epoch 729/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0040 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 730/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0180 - val_loss: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 731/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -43628us/step - loss: 0.9817 - val_loss: 0.7556 - learning_rate: 0.0010\n",
      "Epoch 732/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.0285 - val_loss: 0.7555 - learning_rate: 0.0010\n",
      "Epoch 733/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0024 - val_loss: 0.6049 - learning_rate: 0.0010\n",
      "Epoch 734/5000\n",
      "\u001b[1m 7/22\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0398"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizhou_chen/miniconda3/envs/base-ml/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9672 - learning_rate: 0.0010\n",
      "Epoch 735/5000\n",
      "\u001b[1m 7/22\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0424"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizhou_chen/miniconda3/envs/base-ml/lib/python3.12/site-packages/keras/src/callbacks/callback_list.py:145: UserWarning: Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,learning_rate.\n",
      "  callback.on_epoch_end(epoch, logs)\n",
      "/home/yizhou_chen/miniconda3/envs/base-ml/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:99: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,learning_rate\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9915 - learning_rate: 0.0010\n",
      "Epoch 736/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0166 - learning_rate: 0.0010\n",
      "Epoch 737/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9861 - learning_rate: 0.0010\n",
      "Epoch 738/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0328 - learning_rate: 0.0010\n",
      "Epoch 739/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0148 - learning_rate: 0.0010\n",
      "Epoch 740/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9545 - learning_rate: 0.0010\n",
      "Epoch 741/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0134 - learning_rate: 0.0010\n",
      "Epoch 742/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0018 - learning_rate: 0.0010\n",
      "Epoch 743/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9966 - learning_rate: 0.0010\n",
      "Epoch 744/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0116 - learning_rate: 0.0010\n",
      "Epoch 745/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9838 - learning_rate: 0.0010\n",
      "Epoch 746/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0643 - learning_rate: 0.0010\n",
      "Epoch 747/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9388 - learning_rate: 0.0010\n",
      "Epoch 748/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9733 - learning_rate: 0.0010\n",
      "Epoch 749/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0082 - learning_rate: 0.0010\n",
      "Epoch 750/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0295 - learning_rate: 0.0010\n",
      "Epoch 751/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0129 - learning_rate: 0.0010\n",
      "Epoch 752/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9834 - learning_rate: 0.0010\n",
      "Epoch 753/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0091 - learning_rate: 0.0010\n",
      "Epoch 754/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0375 - learning_rate: 0.0010\n",
      "Epoch 755/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9434 - learning_rate: 0.0010\n",
      "Epoch 756/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0004 - learning_rate: 0.0010\n",
      "Epoch 757/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0113 - learning_rate: 0.0010\n",
      "Epoch 758/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9815 - learning_rate: 0.0010\n",
      "Epoch 759/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0268 - learning_rate: 0.0010\n",
      "Epoch 760/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.9800 - learning_rate: 0.0010\n",
      "Epoch 761/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.9972 - learning_rate: 0.0010\n",
      "Epoch 762/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0154 - learning_rate: 0.0010\n",
      "Epoch 763/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9827 - learning_rate: 0.0010\n",
      "Epoch 764/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0211 - learning_rate: 0.0010\n",
      "Epoch 765/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0572 - learning_rate: 0.0010\n",
      "Epoch 766/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.9302 - learning_rate: 0.0010\n",
      "Epoch 767/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0705 - learning_rate: 0.0010\n",
      "Epoch 768/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9291 - learning_rate: 0.0010\n",
      "Epoch 769/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9875 - learning_rate: 0.0010\n",
      "Epoch 770/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0118 - learning_rate: 0.0010\n",
      "Epoch 771/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9800 - learning_rate: 0.0010\n",
      "Epoch 772/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0161 - learning_rate: 0.0010\n",
      "Epoch 773/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0139 - learning_rate: 0.0010\n",
      "Epoch 774/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9804 - learning_rate: 0.0010\n",
      "Epoch 775/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9990 - learning_rate: 0.0010\n",
      "Epoch 776/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0185 - learning_rate: 0.0010\n",
      "Epoch 777/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9943 - learning_rate: 0.0010\n",
      "Epoch 778/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9823 - learning_rate: 0.0010\n",
      "Epoch 779/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9979 - learning_rate: 0.0010\n",
      "Epoch 780/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0465 - learning_rate: 0.0010\n",
      "Epoch 781/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9967 - learning_rate: 0.0010\n",
      "Epoch 782/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9642 - learning_rate: 0.0010\n",
      "Epoch 783/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0007 - learning_rate: 0.0010\n",
      "Epoch 784/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0013 - learning_rate: 0.0010\n",
      "Epoch 785/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0261 - learning_rate: 0.0010\n",
      "Epoch 786/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9753 - learning_rate: 0.0010\n",
      "Epoch 787/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0529 - learning_rate: 0.0010\n",
      "Epoch 788/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9649 - learning_rate: 0.0010\n",
      "Epoch 789/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9813 - learning_rate: 0.0010\n",
      "Epoch 790/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.9990 - learning_rate: 0.0010\n",
      "Epoch 791/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0255 - learning_rate: 0.0010\n",
      "Epoch 792/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0087 - learning_rate: 0.0010\n",
      "Epoch 793/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9637 - learning_rate: 0.0010\n",
      "Epoch 794/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0409 - learning_rate: 0.0010\n",
      "Epoch 795/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9752 - learning_rate: 0.0010\n",
      "Epoch 796/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9905 - learning_rate: 0.0010\n",
      "Epoch 797/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0024 - learning_rate: 0.0010\n",
      "Epoch 798/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0299 - learning_rate: 0.0010\n",
      "Epoch 799/5000\n",
      "\u001b[1m10/22\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0362"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:49:51.075511: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9651 - learning_rate: 0.0010\n",
      "Epoch 800/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0179 - learning_rate: 0.0010\n",
      "Epoch 801/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9861 - learning_rate: 0.0010\n",
      "Epoch 802/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -55733us/step - loss: 1.0048 - learning_rate: 0.0010\n",
      "Epoch 803/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0386 - learning_rate: 0.0010\n",
      "Epoch 804/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9498 - learning_rate: 0.0010\n",
      "Epoch 805/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0196 - learning_rate: 0.0010\n",
      "Epoch 806/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0020 - learning_rate: 0.0010\n",
      "Epoch 807/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9894 - learning_rate: 0.0010\n",
      "Epoch 808/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0151 - learning_rate: 0.0010\n",
      "Epoch 809/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9844 - learning_rate: 0.0010\n",
      "Epoch 810/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9978 - learning_rate: 0.0010\n",
      "Epoch 811/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0083 - learning_rate: 0.0010\n",
      "Epoch 812/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9915 - learning_rate: 0.0010\n",
      "Epoch 813/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0011 - learning_rate: 0.0010\n",
      "Epoch 814/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0009 - learning_rate: 0.0010\n",
      "Epoch 815/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0114 - learning_rate: 0.0010\n",
      "Epoch 816/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9982 - learning_rate: 0.0010\n",
      "Epoch 817/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0054 - learning_rate: 0.0010\n",
      "Epoch 818/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9709 - learning_rate: 0.0010\n",
      "Epoch 819/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0160 - learning_rate: 0.0010\n",
      "Epoch 820/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9875 - learning_rate: 0.0010\n",
      "Epoch 821/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0079 - learning_rate: 0.0010\n",
      "Epoch 822/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0045 - learning_rate: 0.0010\n",
      "Epoch 823/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0180 - learning_rate: 0.0010\n",
      "Epoch 824/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9685 - learning_rate: 0.0010\n",
      "Epoch 825/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0089 - learning_rate: 0.0010\n",
      "Epoch 826/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0187 - learning_rate: 0.0010\n",
      "Epoch 827/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9850 - learning_rate: 0.0010\n",
      "Epoch 828/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9913 - learning_rate: 0.0010\n",
      "Epoch 829/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0238 - learning_rate: 0.0010\n",
      "Epoch 830/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9935 - learning_rate: 0.0010\n",
      "Epoch 831/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9976 - learning_rate: 0.0010\n",
      "Epoch 832/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0226 - learning_rate: 0.0010\n",
      "Epoch 833/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9711 - learning_rate: 0.0010\n",
      "Epoch 834/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0506 - learning_rate: 0.0010\n",
      "Epoch 835/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9914 - learning_rate: 0.0010\n",
      "Epoch 836/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.9413 - learning_rate: 0.0010\n",
      "Epoch 837/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0116 - learning_rate: 0.0010\n",
      "Epoch 838/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0508 - learning_rate: 0.0010\n",
      "Epoch 839/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9716 - learning_rate: 0.0010\n",
      "Epoch 840/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9994 - learning_rate: 0.0010\n",
      "Epoch 841/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0205 - learning_rate: 0.0010\n",
      "Epoch 842/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9582 - learning_rate: 0.0010\n",
      "Epoch 843/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9981 - learning_rate: 0.0010\n",
      "Epoch 844/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0336 - learning_rate: 0.0010\n",
      "Epoch 845/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9579 - learning_rate: 0.0010\n",
      "Epoch 846/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0114 - learning_rate: 0.0010\n",
      "Epoch 847/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9874 - learning_rate: 0.0010\n",
      "Epoch 848/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9984 - learning_rate: 0.0010\n",
      "Epoch 849/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0153 - learning_rate: 0.0010\n",
      "Epoch 850/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0195 - learning_rate: 0.0010\n",
      "Epoch 851/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9818 - learning_rate: 0.0010\n",
      "Epoch 852/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0023 - learning_rate: 0.0010\n",
      "Epoch 853/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0193 - learning_rate: 0.0010\n",
      "Epoch 854/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9695 - learning_rate: 0.0010\n",
      "Epoch 855/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0167 - learning_rate: 0.0010\n",
      "Epoch 856/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0182 - learning_rate: 0.0010\n",
      "Epoch 857/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9986 - learning_rate: 0.0010\n",
      "Epoch 858/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9919 - learning_rate: 0.0010\n",
      "Epoch 859/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0126 - learning_rate: 0.0010\n",
      "Epoch 860/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9780 - learning_rate: 0.0010\n",
      "Epoch 861/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0113 - learning_rate: 0.0010\n",
      "Epoch 862/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9919 - learning_rate: 0.0010\n",
      "Epoch 863/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0296 - learning_rate: 0.0010\n",
      "Epoch 864/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9548 - learning_rate: 0.0010\n",
      "Epoch 865/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0140 - learning_rate: 0.0010\n",
      "Epoch 866/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0190 - learning_rate: 0.0010\n",
      "Epoch 867/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9807 - learning_rate: 0.0010\n",
      "Epoch 868/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9869 - learning_rate: 0.0010\n",
      "Epoch 869/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9987 - learning_rate: 0.0010\n",
      "Epoch 870/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0056 - learning_rate: 0.0010\n",
      "Epoch 871/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0241 - learning_rate: 0.0010\n",
      "Epoch 872/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9993 - learning_rate: 0.0010\n",
      "Epoch 873/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9711 - learning_rate: 0.0010\n",
      "Epoch 874/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0465 - learning_rate: 0.0010\n",
      "Epoch 875/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -52933us/step - loss: 0.9911 - learning_rate: 0.0010\n",
      "Epoch 876/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9762 - learning_rate: 0.0010\n",
      "Epoch 877/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9889 - learning_rate: 0.0010\n",
      "Epoch 878/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0026 - learning_rate: 0.0010\n",
      "Epoch 879/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0105 - learning_rate: 0.0010\n",
      "Epoch 880/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0337 - learning_rate: 0.0010\n",
      "Epoch 881/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9541 - learning_rate: 0.0010\n",
      "Epoch 882/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0167 - learning_rate: 0.0010\n",
      "Epoch 883/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9932 - learning_rate: 0.0010\n",
      "Epoch 884/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9962 - learning_rate: 0.0010\n",
      "Epoch 885/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9904 - learning_rate: 0.0010\n",
      "Epoch 886/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0058 - learning_rate: 0.0010\n",
      "Epoch 887/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0818 - learning_rate: 0.0010\n",
      "Epoch 888/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9330 - learning_rate: 0.0010\n",
      "Epoch 889/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0126 - learning_rate: 0.0010\n",
      "Epoch 890/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9655 - learning_rate: 0.0010\n",
      "Epoch 891/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9983 - learning_rate: 0.0010\n",
      "Epoch 892/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0294 - learning_rate: 0.0010\n",
      "Epoch 893/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0089 - learning_rate: 0.0010\n",
      "Epoch 894/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9864 - learning_rate: 0.0010\n",
      "Epoch 895/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9854 - learning_rate: 0.0010\n",
      "Epoch 896/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0212 - learning_rate: 0.0010\n",
      "Epoch 897/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9863 - learning_rate: 0.0010\n",
      "Epoch 898/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9837 - learning_rate: 0.0010\n",
      "Epoch 899/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0418 - learning_rate: 0.0010\n",
      "Epoch 900/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9671 - learning_rate: 0.0010\n",
      "Epoch 901/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.0051 - learning_rate: 0.0010\n",
      "Epoch 902/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0337 - learning_rate: 0.0010\n",
      "Epoch 903/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9646 - learning_rate: 0.0010\n",
      "Epoch 904/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9981 - learning_rate: 0.0010\n",
      "Epoch 905/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.9975 - learning_rate: 0.0010\n",
      "Epoch 906/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.0102 - learning_rate: 0.0010\n",
      "Epoch 907/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0071 - learning_rate: 0.0010\n",
      "Epoch 908/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9895 - learning_rate: 0.0010\n",
      "Epoch 909/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0068 - learning_rate: 0.0010\n",
      "Epoch 910/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9814 - learning_rate: 0.0010\n",
      "Epoch 911/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0695 - learning_rate: 0.0010\n",
      "Epoch 912/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9486 - learning_rate: 0.0010\n",
      "Epoch 913/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9716 - learning_rate: 0.0010\n",
      "Epoch 914/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0167 - learning_rate: 0.0010\n",
      "Epoch 915/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0027 - learning_rate: 0.0010\n",
      "Epoch 916/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0123 - learning_rate: 0.0010\n",
      "Epoch 917/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9795 - learning_rate: 0.0010\n",
      "Epoch 918/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0088 - learning_rate: 0.0010\n",
      "Epoch 919/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0012 - learning_rate: 0.0010\n",
      "Epoch 920/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9985 - learning_rate: 0.0010\n",
      "Epoch 921/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0074 - learning_rate: 0.0010\n",
      "Epoch 922/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9916 - learning_rate: 0.0010\n",
      "Epoch 923/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9928 - learning_rate: 0.0010\n",
      "Epoch 924/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0217 - learning_rate: 0.0010\n",
      "Epoch 925/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 926/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 927/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 928/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 929/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 930/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 931/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 932/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 933/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 934/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 935/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 936/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 937/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 938/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 939/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 940/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 941/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 942/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 943/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 944/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 945/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 946/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 947/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 948/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 949/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 950/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 951/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 952/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 953/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 954/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 955/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 956/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 957/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 958/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 959/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 960/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 961/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 962/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 963/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 964/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 965/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 966/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 967/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 968/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 969/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 970/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 971/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 972/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 973/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 974/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 975/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 976/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 977/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 978/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 979/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 980/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 981/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 982/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 983/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 984/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 985/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 986/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 987/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 988/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 989/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 990/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 991/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 992/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 993/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 994/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 995/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 996/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 997/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 998/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 999/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1000/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1001/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1002/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1003/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1004/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1005/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1006/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1007/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1008/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1009/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1010/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1011/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1012/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1013/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1014/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1015/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1016/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1017/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1018/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1019/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1020/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1021/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1022/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1023/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1024/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1025/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1026/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1027/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1028/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1029/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1030/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1031/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1032/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1033/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1034/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1035/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1036/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1037/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1038/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1039/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1040/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1041/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1042/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1043/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1044/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1045/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1046/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1047/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1048/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1049/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1050/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1051/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1052/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1053/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1054/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1055/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1056/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1057/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1058/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1059/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1060/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1061/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1062/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1063/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1064/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1065/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1066/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -67966us/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1067/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1068/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1069/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1070/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1071/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1072/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1073/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1074/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1075/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1076/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1077/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1078/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1079/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1080/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1081/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1082/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1083/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1084/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1085/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1086/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1087/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1088/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1089/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1090/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1091/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1092/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1093/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1094/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1095/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1096/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1097/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1098/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1099/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1100/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1101/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1102/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1103/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1104/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1105/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1106/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1107/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1108/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1109/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1110/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1111/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1112/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1113/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1114/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1115/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1116/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1117/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1118/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1119/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1120/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1121/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1122/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1123/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1124/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1125/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1126/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1127/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1128/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1129/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1130/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1131/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1132/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1133/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1134/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1135/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1136/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1137/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1138/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1139/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1140/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1141/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1142/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1143/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1144/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1145/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1146/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1147/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1148/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1149/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1150/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1151/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1152/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1153/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1154/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1155/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1156/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1157/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1158/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1159/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1160/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1161/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1162/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1163/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1164/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1165/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1166/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1167/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1168/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1169/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1170/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1171/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1172/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1173/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1174/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1175/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1176/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1177/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1178/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1179/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1180/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1181/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1182/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1183/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1184/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1185/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1186/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1187/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1188/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1189/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1190/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1191/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1192/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1193/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1194/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1195/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1196/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1197/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1198/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1199/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1200/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1201/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1202/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1203/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1204/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1205/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1206/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1207/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1208/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1209/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1210/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1211/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1212/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1213/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1214/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1215/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1216/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1217/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1218/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1219/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1220/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1221/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1222/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1223/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1224/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1225/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1226/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1227/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1228/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1229/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1230/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1231/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1232/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1233/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1234/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1235/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1236/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1237/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1238/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1239/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1240/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1241/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1242/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1243/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1244/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1245/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1246/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1247/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1248/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1249/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1250/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1251/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1252/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1253/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1254/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1255/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1256/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1257/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1258/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1259/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1260/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1261/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1262/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1263/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1264/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1265/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1266/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1267/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1268/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1269/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1270/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1271/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1272/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1273/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1274/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1275/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1276/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1277/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1278/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1279/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1280/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1281/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1282/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1283/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1284/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1285/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1286/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1287/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1288/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1289/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1290/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1291/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1292/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1293/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1294/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1295/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1296/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1297/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1298/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1299/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1300/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1301/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1302/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1303/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1304/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1305/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1306/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1307/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1308/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1309/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1310/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1311/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1312/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1313/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1314/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1315/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1316/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1317/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1318/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1319/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1320/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1321/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1322/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1323/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1324/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1325/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1326/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1327/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1328/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1329/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1330/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1331/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1332/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1333/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1334/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1335/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1336/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1337/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1338/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1339/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1340/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1341/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1342/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1343/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1344/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1345/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1346/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1347/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1348/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1349/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1350/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1351/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1352/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1353/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1354/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1355/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1356/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1357/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1358/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1359/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1360/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1361/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1362/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1363/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1364/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1365/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1366/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1367/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1368/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1369/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1370/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1371/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1372/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1373/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1374/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1375/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1376/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1377/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1378/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1379/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1380/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1381/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1382/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1383/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1384/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1385/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1386/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1387/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1388/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1389/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1390/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1391/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1392/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1393/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1394/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1395/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1396/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1397/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1398/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1399/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1400/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1401/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1402/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1403/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1404/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1405/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1406/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1407/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1408/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1409/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1410/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1411/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1412/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1413/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1414/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1415/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1416/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1417/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1418/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1419/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1420/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1421/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1422/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1423/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1424/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1425/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1426/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1427/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1428/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1429/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1430/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1431/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1432/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1433/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1434/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1435/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1436/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1437/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1438/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1439/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1440/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1441/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1442/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1443/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1444/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1445/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1446/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1447/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1448/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1449/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1450/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1451/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1452/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1453/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1454/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1455/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1456/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1457/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1458/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1459/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1460/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1461/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1462/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1463/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1464/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1465/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1466/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1467/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1468/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1469/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1470/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1471/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1472/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1473/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1474/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1475/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1476/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1477/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1478/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1479/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1480/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1481/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1482/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1483/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1484/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1485/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1486/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1487/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1488/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1489/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1490/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1491/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1492/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1493/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1494/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1495/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1496/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1497/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1498/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1499/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1500/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1501/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1502/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1503/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1504/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1505/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1506/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1507/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1508/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1509/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1510/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1511/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1512/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1513/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1514/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1515/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1516/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1517/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1518/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1519/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1520/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1521/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1522/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1523/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1524/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1525/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1526/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1527/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1528/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1529/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1530/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1531/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1532/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1533/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1534/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1535/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1536/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1537/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1538/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1539/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1540/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1541/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1542/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1543/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1544/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1545/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1546/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1547/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1548/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1549/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1550/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1551/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1552/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1553/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1554/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1555/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1556/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1557/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1558/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1559/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1560/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1561/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1562/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1563/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1564/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1565/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1566/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1567/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1568/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1569/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1570/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1571/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1572/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1573/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1574/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1575/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1576/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1577/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1578/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1579/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1580/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1581/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1582/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1583/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1584/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1585/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1586/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1587/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1588/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1589/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1590/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1591/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1592/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1593/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1594/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1595/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1596/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1597/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1598/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1599/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1600/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1601/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1602/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1603/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1604/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1605/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1606/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1607/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1608/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1609/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1610/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1611/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1612/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1613/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1614/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1615/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1616/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1617/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1618/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1619/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1620/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1621/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1622/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1623/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1624/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1625/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1626/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1627/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1628/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1629/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1630/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1631/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1632/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1633/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1634/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1635/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1636/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1637/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1638/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1639/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1640/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1641/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1642/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1643/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1644/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1645/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1646/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1647/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1648/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1649/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1650/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1651/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1652/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1653/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1654/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1655/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1656/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1657/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1658/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1659/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1660/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1661/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1662/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1663/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1664/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1665/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1666/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1667/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1668/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1669/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1670/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1671/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1672/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1673/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1674/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1675/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1676/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1677/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1678/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -66688us/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1679/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1680/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1681/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1682/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1683/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1684/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1685/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1686/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1687/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1688/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1689/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1690/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1691/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1692/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1693/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1694/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1695/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1696/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1697/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1698/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1699/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1700/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1701/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1702/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1703/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1704/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1705/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1706/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1707/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1708/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1709/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1710/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1711/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1712/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1713/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1714/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1715/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1716/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1717/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1718/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1719/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1720/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1721/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1722/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1723/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1724/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1725/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1726/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1727/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1728/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1729/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1730/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1731/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1732/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1733/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1734/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1735/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1736/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1737/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1738/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1739/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1740/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1741/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1742/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1743/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1744/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1745/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1746/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1747/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1748/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1749/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1750/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1751/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1752/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1753/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1754/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1755/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1756/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1757/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1758/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1759/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1760/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1761/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1762/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1763/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1764/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1765/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1766/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1767/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1768/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1769/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1770/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1771/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1772/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1773/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1774/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1775/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1776/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1777/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1778/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1779/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1780/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1781/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1782/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1783/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1784/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1785/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1786/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1787/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1788/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1789/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1790/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1791/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1792/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1793/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1794/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1795/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1796/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1797/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1798/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1799/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1800/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1801/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1802/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1803/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1804/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1805/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1806/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1807/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1808/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1809/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1810/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1811/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1812/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1813/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1814/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1815/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1816/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1817/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1818/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1819/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1820/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1821/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1822/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1823/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1824/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1825/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1826/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1827/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1828/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1829/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1830/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1831/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1832/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1833/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1834/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1835/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1836/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1837/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1838/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1839/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1840/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1841/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1842/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1843/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1844/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1845/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1846/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1847/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1848/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1849/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1850/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1851/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1852/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1853/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1854/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1855/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1856/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1857/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1858/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1859/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1860/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1861/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1862/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1863/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1864/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1865/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1866/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1867/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1868/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1869/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1870/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1871/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1872/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1873/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1874/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1875/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1876/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1877/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1878/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1879/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1880/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1881/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1882/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1883/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1884/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1885/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1886/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1887/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1888/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1889/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1890/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1891/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1892/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1893/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1894/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1895/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1896/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1897/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1898/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1899/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1900/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1901/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1902/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1903/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1904/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1905/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1906/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1907/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1908/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1909/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1910/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1911/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1912/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1913/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1914/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1915/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1916/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1917/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1918/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1919/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1920/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1921/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1922/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1923/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1924/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1925/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1926/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1927/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1928/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1929/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1930/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1931/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1932/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1933/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1934/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1935/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1936/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1937/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1938/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1939/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1940/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1941/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1942/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1943/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1944/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1945/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1946/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1947/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1948/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1949/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1950/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1951/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1952/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1953/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1954/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1955/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1956/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1957/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1958/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1959/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1960/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1961/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1962/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1963/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1964/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1965/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1966/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1967/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1968/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1969/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1970/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1971/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1972/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1973/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1974/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1975/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1976/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1977/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1978/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1979/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1980/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1981/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1982/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1983/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1984/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1985/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1986/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1987/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1988/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1989/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1990/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1991/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1992/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1993/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1994/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1995/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1996/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1997/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1998/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 1999/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2000/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2001/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2002/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2003/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2004/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2005/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2006/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2007/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2008/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2009/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2010/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2011/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2012/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2013/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2014/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2015/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2016/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2017/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2018/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2019/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2020/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2021/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2022/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2023/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2024/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2025/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2026/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2027/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2028/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2029/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2030/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2031/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2032/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2033/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2034/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2035/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2036/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2037/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2038/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2039/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2040/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2041/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2042/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2043/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2044/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2045/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2046/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2047/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2048/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2049/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2050/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2051/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2052/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2053/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2054/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2055/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2056/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2057/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2058/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2059/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2060/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2061/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2062/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2063/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2064/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2065/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2066/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2067/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2068/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2069/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2070/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2071/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2072/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2073/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2074/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2075/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2076/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2077/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2078/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2079/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2080/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2081/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2082/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2083/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2084/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2085/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2086/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2087/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2088/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2089/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2090/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2091/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2092/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2093/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2094/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2095/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2096/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2097/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2098/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2099/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2100/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2101/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2102/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2103/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2104/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2105/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2106/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2107/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2108/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2109/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2110/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2111/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2112/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2113/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2114/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2115/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2116/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2117/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2118/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2119/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2120/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2121/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2122/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2123/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2124/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2125/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2126/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2127/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2128/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2129/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2130/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2131/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2132/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2133/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2134/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2135/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2136/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2137/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2138/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2139/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2140/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2141/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2142/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2143/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2144/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2145/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2146/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2147/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2148/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2149/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2150/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2151/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2152/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2153/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2154/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2155/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2156/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2157/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2158/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2159/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2160/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2161/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2162/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2163/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2164/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2165/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2166/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2167/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2168/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2169/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2170/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2171/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2172/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2173/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2174/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2175/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2176/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2177/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2178/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2179/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2180/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2181/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2182/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2183/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2184/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2185/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2186/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2187/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2188/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2189/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2190/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2191/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2192/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2193/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2194/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2195/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2196/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2197/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2198/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2199/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2200/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2201/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2202/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2203/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2204/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2205/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2206/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2207/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2208/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2209/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2210/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2211/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2212/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2213/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2214/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2215/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2216/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2217/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2218/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2219/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2220/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2221/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2222/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2223/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2224/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2225/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2226/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2227/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2228/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2229/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2230/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2231/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2232/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2233/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2234/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2235/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2236/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2237/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2238/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2239/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2240/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2241/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2242/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2243/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2244/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2245/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2246/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2247/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2248/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2249/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2250/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2251/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2252/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2253/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2254/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2255/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2256/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2257/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2258/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2259/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2260/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2261/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2262/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2263/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2264/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2265/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2266/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2267/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2268/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2269/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2270/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2271/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2272/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2273/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2274/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2275/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2276/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2277/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2278/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2279/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2280/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2281/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2282/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2283/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2284/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -60756us/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2285/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2286/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2287/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2288/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2289/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2290/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2291/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2292/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2293/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2294/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2295/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2296/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2297/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2298/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2299/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2300/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2301/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2302/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2303/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2304/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2305/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2306/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2307/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2308/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2309/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2310/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2311/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2312/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2313/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2314/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2315/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2316/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2317/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2318/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2319/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2320/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2321/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2322/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2323/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2324/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2325/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2326/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2327/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2328/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2329/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2330/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2331/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2332/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2333/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2334/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2335/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2336/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2337/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2338/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2339/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2340/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2341/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2342/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2343/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2344/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2345/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2346/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2347/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2348/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2349/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2350/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2351/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2352/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2353/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2354/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2355/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2356/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2357/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2358/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2359/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2360/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2361/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2362/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2363/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2364/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2365/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2366/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2367/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2368/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2369/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2370/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2371/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2372/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2373/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2374/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2375/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2376/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2377/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2378/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2379/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2380/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2381/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2382/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2383/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2384/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2385/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2386/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2387/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2388/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2389/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2390/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2391/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2392/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2393/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2394/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2395/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2396/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2397/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2398/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2399/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2400/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2401/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2402/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2403/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2404/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2405/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2406/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2407/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2408/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2409/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2410/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2411/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2412/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2413/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2414/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2415/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2416/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2417/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2418/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2419/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2420/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2421/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2422/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2423/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2424/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2425/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2426/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2427/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2428/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2429/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2430/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2431/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2432/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2433/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2434/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2435/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2436/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2437/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2438/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2439/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2440/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2441/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2442/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2443/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2444/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2445/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2446/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2447/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2448/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2449/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2450/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2451/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2452/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2453/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2454/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2455/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2456/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2457/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2458/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2459/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2460/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2461/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2462/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2463/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2464/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2465/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2466/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2467/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2468/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2469/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2470/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2471/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2472/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2473/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2474/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2475/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2476/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2477/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2478/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2479/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2480/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2481/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2482/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2483/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2484/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2485/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2486/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2487/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2488/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2489/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2490/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2491/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2492/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2493/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2494/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2495/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2496/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2497/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2498/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2499/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2500/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2501/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2502/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2503/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2504/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2505/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2506/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2507/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2508/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2509/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2510/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2511/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2512/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2513/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2514/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2515/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2516/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2517/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2518/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2519/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2520/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2521/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2522/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2523/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2524/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2525/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2526/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2527/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2528/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2529/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2530/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2531/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2532/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2533/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2534/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2535/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2536/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2537/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2538/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2539/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2540/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2541/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2542/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2543/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2544/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2545/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2546/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2547/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2548/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2549/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2550/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2551/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2552/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2553/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2554/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2555/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2556/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2557/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2558/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2559/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2560/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2561/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2562/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2563/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2564/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2565/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2566/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2567/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2568/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2569/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2570/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2571/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2572/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2573/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2574/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2575/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2576/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2577/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2578/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2579/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2580/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2581/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2582/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2583/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2584/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2585/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2586/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2587/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2588/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2589/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2590/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2591/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2592/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2593/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2594/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2595/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2596/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2597/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2598/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2599/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2600/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2601/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2602/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2603/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2604/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2605/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2606/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2607/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2608/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2609/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2610/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2611/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2612/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2613/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2614/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2615/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2616/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2617/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2618/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2619/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2620/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2621/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2622/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2623/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2624/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2625/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2626/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2627/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2628/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2629/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2630/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2631/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2632/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2633/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2634/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2635/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2636/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2637/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2638/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2639/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2640/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2641/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2642/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2643/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2644/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2645/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2646/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2647/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2648/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2649/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2650/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2651/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2652/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2653/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2654/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2655/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2656/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2657/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2658/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2659/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2660/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2661/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2662/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2663/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2664/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2665/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2666/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2667/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2668/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2669/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2670/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2671/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2672/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2673/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2674/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2675/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2676/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2677/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2678/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2679/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2680/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2681/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2682/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2683/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2684/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2685/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2686/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2687/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2688/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2689/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2690/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2691/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2692/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2693/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2694/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2695/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2696/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2697/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2698/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2699/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2700/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2701/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2702/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2703/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2704/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2705/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2706/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2707/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2708/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2709/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2710/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2711/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2712/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2713/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2714/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2715/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2716/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2717/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2718/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2719/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2720/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2721/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2722/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2723/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2724/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2725/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2726/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2727/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2728/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2729/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2730/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2731/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2732/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2733/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2734/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2735/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2736/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2737/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2738/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2739/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2740/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2741/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2742/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2743/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2744/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2745/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2746/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2747/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2748/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2749/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2750/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2751/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2752/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2753/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2754/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2755/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2756/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2757/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2758/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2759/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2760/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2761/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2762/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2763/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2764/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2765/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2766/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2767/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2768/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2769/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2770/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2771/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2772/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2773/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2774/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2775/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2776/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2777/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2778/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2779/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2780/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2781/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2782/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2783/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2784/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2785/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2786/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2787/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2788/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2789/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2790/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2791/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2792/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2793/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2794/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2795/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2796/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2797/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2798/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2799/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2800/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2801/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2802/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2803/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2804/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2805/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2806/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2807/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2808/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2809/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2810/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2811/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2812/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2813/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2814/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2815/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2816/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2817/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2818/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2819/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2820/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2821/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2822/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2823/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2824/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2825/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2826/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2827/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2828/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2829/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2830/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -63378us/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2831/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2832/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2833/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2834/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2835/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2836/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2837/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2838/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2839/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2840/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2841/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2842/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2843/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2844/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2845/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2846/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2847/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2848/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2849/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2850/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2851/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2852/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2853/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2854/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2855/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2856/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2857/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2858/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2859/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2860/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2861/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2862/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2863/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2864/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2865/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2866/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2867/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2868/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2869/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2870/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2871/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2872/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2873/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2874/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2875/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2876/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2877/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2878/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2879/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2880/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2881/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2882/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2883/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2884/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2885/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2886/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2887/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2888/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2889/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2890/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2891/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2892/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2893/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2894/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2895/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2896/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2897/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2898/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2899/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2900/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2901/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2902/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2903/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2904/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2905/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2906/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2907/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2908/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2909/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2910/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2911/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2912/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2913/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2914/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2915/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2916/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2917/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2918/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2919/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2920/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2921/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2922/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2923/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2924/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2925/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2926/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2927/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2928/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2929/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2930/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2931/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2932/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2933/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2934/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2935/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2936/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2937/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2938/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2939/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2940/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2941/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2942/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2943/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2944/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2945/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2946/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2947/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2948/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2949/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2950/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2951/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2952/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2953/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2954/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2955/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2956/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2957/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2958/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2959/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2960/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2961/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2962/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2963/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2964/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2965/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2966/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2967/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2968/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2969/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2970/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2971/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2972/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2973/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2974/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2975/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2976/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2977/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2978/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2979/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2980/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2981/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2982/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2983/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2984/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2985/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2986/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2987/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2988/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2989/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2990/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2991/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2992/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2993/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2994/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2995/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2996/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2997/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2998/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2999/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3000/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3001/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3002/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3003/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3004/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3005/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3006/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3007/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3008/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3009/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3010/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3011/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3012/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3013/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3014/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3015/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3016/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3017/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3018/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3019/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3020/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3021/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3022/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3023/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3024/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3025/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3026/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3027/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3028/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3029/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3030/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3031/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3032/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3033/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3034/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3035/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3036/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3037/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3038/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3039/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3040/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3041/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3042/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3043/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3044/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3045/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3046/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3047/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3048/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3049/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3050/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3051/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3052/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3053/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3054/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3055/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3056/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3057/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3058/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3059/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3060/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3061/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3062/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3063/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3064/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3065/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3066/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3067/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3068/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3069/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3070/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3071/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3072/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3073/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3074/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3075/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3076/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3077/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3078/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3079/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3080/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3081/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3082/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3083/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3084/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3085/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3086/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3087/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3088/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3089/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3090/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3091/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3092/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3093/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3094/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3095/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3096/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3097/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3098/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3099/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3100/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3101/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3102/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3103/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3104/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3105/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3106/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3107/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3108/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3109/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3110/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3111/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3112/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3113/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3114/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3115/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3116/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3117/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3118/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3119/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3120/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3121/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3122/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3123/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3124/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3125/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3126/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3127/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3128/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3129/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3130/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3131/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3132/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3133/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3134/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3135/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3136/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3137/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3138/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3139/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3140/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3141/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3142/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3143/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3144/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3145/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3146/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3147/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3148/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3149/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3150/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3151/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3152/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3153/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3154/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3155/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3156/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3157/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3158/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3159/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3160/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3161/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3162/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3163/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3164/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3165/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3166/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3167/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3168/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3169/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3170/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3171/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3172/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3173/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3174/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3175/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3176/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3177/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3178/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3179/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3180/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3181/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3182/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3183/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3184/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3185/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3186/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3187/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3188/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3189/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3190/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3191/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3192/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3193/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3194/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3195/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3196/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3197/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3198/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3199/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3200/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3201/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3202/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3203/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3204/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3205/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3206/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3207/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3208/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3209/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3210/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3211/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3212/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3213/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3214/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3215/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3216/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3217/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3218/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3219/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3220/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3221/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3222/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3223/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3224/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3225/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3226/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3227/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3228/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3229/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3230/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3231/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3232/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3233/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3234/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3235/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3236/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3237/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3238/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3239/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3240/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3241/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3242/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3243/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3244/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3245/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3246/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3247/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3248/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3249/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3250/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3251/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3252/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3253/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3254/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3255/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3256/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3257/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3258/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3259/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3260/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3261/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3262/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3263/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3264/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3265/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3266/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3267/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3268/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3269/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3270/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3271/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3272/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3273/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3274/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3275/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3276/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3277/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3278/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3279/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3280/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3281/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3282/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3283/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3284/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3285/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3286/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3287/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3288/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3289/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3290/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3291/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3292/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3293/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3294/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3295/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3296/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3297/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3298/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3299/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3300/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3301/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3302/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3303/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3304/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3305/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3306/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3307/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3308/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3309/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3310/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3311/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3312/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3313/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3314/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3315/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3316/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3317/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3318/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3319/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3320/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3321/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3322/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3323/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3324/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3325/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3326/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3327/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3328/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3329/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3330/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3331/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3332/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3333/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3334/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3335/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3336/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3337/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3338/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3339/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3340/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3341/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3342/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3343/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3344/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3345/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3346/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3347/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3348/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3349/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3350/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3351/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3352/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3353/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3354/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3355/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3356/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3357/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3358/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3359/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3360/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3361/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3362/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3363/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3364/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3365/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3366/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3367/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3368/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3369/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3370/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3371/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3372/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3373/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3374/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3375/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3376/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3377/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3378/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3379/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3380/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3381/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3382/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3383/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3384/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3385/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3386/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3387/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3388/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3389/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3390/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3391/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3392/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3393/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3394/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3395/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3396/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3397/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3398/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3399/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3400/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3401/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3402/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3403/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3404/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3405/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3406/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3407/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3408/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3409/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3410/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3411/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3412/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3413/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3414/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3415/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3416/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3417/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3418/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3419/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3420/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3421/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3422/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3423/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3424/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3425/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3426/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3427/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3428/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3429/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3430/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3431/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3432/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3433/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3434/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3435/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3436/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3437/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3438/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3439/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3440/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3441/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3442/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3443/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3444/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3445/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3446/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3447/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3448/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3449/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3450/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3451/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3452/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3453/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3454/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3455/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3456/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3457/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3458/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3459/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3460/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3461/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3462/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3463/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3464/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3465/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3466/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3467/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3468/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3469/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3470/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3471/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3472/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3473/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3474/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3475/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3476/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3477/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3478/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3479/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3480/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3481/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -62138us/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3482/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3483/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3484/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3485/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3486/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3487/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3488/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3489/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3490/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3491/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3492/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3493/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3494/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3495/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3496/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3497/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3498/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3499/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3500/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3501/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3502/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3503/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3504/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3505/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3506/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3507/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3508/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3509/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3510/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3511/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3512/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3513/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3514/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3515/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3516/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3517/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3518/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3519/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3520/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3521/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3522/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3523/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3524/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3525/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3526/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3527/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3528/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3529/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3530/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3531/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3532/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3533/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3534/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3535/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3536/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3537/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3538/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3539/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3540/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3541/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3542/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3543/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3544/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3545/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3546/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3547/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3548/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3549/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3550/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3551/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3552/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3553/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3554/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3555/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3556/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3557/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3558/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3559/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3560/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3561/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3562/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3563/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3564/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3565/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3566/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3567/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3568/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3569/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3570/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3571/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3572/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3573/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3574/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3575/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3576/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3577/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3578/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3579/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3580/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3581/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3582/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3583/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3584/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3585/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3586/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3587/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3588/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3589/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3590/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3591/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3592/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3593/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3594/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3595/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3596/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3597/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3598/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3599/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3600/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3601/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3602/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3603/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3604/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3605/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3606/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3607/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3608/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3609/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3610/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3611/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3612/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3613/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3614/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3615/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3616/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3617/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3618/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3619/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3620/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3621/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3622/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3623/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3624/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3625/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3626/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3627/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3628/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3629/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3630/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3631/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3632/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3633/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3634/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3635/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3636/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3637/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3638/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3639/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3640/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3641/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3642/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3643/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3644/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3645/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3646/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3647/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3648/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3649/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3650/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3651/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3652/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3653/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3654/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3655/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3656/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3657/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3658/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3659/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3660/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3661/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3662/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3663/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3664/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3665/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3666/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3667/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3668/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3669/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3670/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3671/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3672/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3673/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3674/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3675/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3676/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3677/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3678/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3679/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3680/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3681/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3682/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3683/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3684/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3685/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3686/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3687/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3688/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3689/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3690/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3691/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3692/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3693/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3694/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3695/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3696/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3697/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3698/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3699/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3700/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3701/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3702/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3703/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3704/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3705/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3706/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3707/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3708/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3709/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3710/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3711/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3712/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3713/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3714/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3715/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3716/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3717/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3718/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3719/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3720/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3721/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3722/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3723/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3724/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3725/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3726/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3727/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3728/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3729/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3730/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3731/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3732/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3733/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3734/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3735/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3736/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3737/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3738/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3739/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3740/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3741/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3742/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3743/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3744/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3745/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3746/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3747/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3748/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3749/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3750/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3751/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3752/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3753/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3754/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3755/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3756/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3757/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3758/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3759/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3760/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3761/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3762/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3763/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3764/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3765/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3766/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3767/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3768/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3769/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3770/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3771/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3772/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3773/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3774/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3775/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3776/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3777/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3778/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3779/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3780/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3781/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3782/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3783/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3784/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3785/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3786/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3787/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3788/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3789/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3790/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3791/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3792/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3793/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3794/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3795/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3796/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3797/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3798/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3799/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3800/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3801/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3802/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3803/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3804/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3805/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3806/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3807/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3808/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3809/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3810/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3811/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3812/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3813/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3814/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3815/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3816/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3817/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3818/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3819/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3820/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3821/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3822/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3823/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3824/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3825/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3826/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3827/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3828/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3829/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3830/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3831/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3832/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3833/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3834/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3835/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3836/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3837/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3838/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3839/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3840/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3841/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3842/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3843/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3844/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3845/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3846/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3847/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3848/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3849/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3850/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3851/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3852/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3853/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3854/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3855/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3856/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3857/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3858/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3859/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3860/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3861/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3862/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3863/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3864/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3865/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3866/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3867/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3868/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3869/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3870/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3871/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3872/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3873/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3874/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3875/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3876/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3877/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3878/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3879/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3880/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3881/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3882/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3883/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3884/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3885/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3886/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3887/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3888/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3889/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3890/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3891/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3892/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3893/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3894/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3895/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3896/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3897/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3898/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3899/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3900/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3901/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3902/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3903/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3904/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3905/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3906/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3907/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3908/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3909/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3910/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3911/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3912/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3913/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3914/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3915/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3916/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3917/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3918/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3919/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3920/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3921/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3922/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3923/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3924/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3925/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3926/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3927/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3928/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3929/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3930/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3931/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3932/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3933/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3934/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3935/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3936/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3937/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3938/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3939/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3940/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3941/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3942/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3943/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3944/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3945/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3946/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3947/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3948/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3949/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3950/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3951/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3952/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3953/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3954/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3955/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3956/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3957/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3958/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3959/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3960/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3961/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3962/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3963/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3964/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3965/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3966/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3967/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3968/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3969/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3970/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3971/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3972/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3973/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3974/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3975/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3976/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3977/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3978/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3979/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3980/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3981/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3982/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3983/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3984/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3985/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3986/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3987/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3988/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3989/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3990/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3991/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3992/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3993/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3994/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3995/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3996/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3997/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3998/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3999/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4000/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4001/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4002/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4003/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4004/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4005/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4006/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4007/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4008/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4009/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4010/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4011/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4012/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4013/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4014/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4015/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4016/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4017/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4018/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4019/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4020/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4021/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4022/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4023/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4024/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4025/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4026/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4027/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4028/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4029/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4030/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4031/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4032/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4033/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4034/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4035/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4036/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4037/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4038/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4039/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4040/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4041/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4042/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4043/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4044/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4045/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4046/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4047/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4048/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4049/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4050/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4051/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4052/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4053/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4054/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4055/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4056/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4057/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4058/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4059/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4060/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4061/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4062/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4063/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4064/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4065/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4066/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4067/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4068/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4069/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4070/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4071/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4072/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4073/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4074/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4075/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4076/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4077/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4078/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4079/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4080/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4081/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4082/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4083/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4084/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4085/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4086/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4087/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4088/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4089/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4090/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4091/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4092/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4093/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4094/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4095/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4096/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4097/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4098/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4099/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4100/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4101/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4102/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4103/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4104/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4105/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4106/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4107/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4108/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4109/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4110/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4111/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4112/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4113/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4114/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4115/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4116/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4117/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4118/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4119/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4120/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -64962us/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4121/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4122/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4123/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4124/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4125/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4126/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4127/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4128/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4129/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4130/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4131/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4132/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4133/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4134/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4135/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4136/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4137/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4138/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4139/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4140/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4141/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4142/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4143/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4144/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4145/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4146/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4147/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4148/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4149/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4150/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4151/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4152/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4153/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4154/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4155/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4156/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4157/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4158/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4159/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4160/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4161/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4162/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4163/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4164/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4165/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4166/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4167/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4168/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4169/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4170/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4171/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4172/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4173/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4174/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4175/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4176/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4177/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4178/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4179/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4180/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4181/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4182/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4183/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4184/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4185/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4186/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4187/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4188/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4189/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4190/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4191/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4192/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4193/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4194/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4195/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4196/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4197/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4198/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4199/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4200/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4201/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4202/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4203/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4204/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4205/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4206/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4207/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4208/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4209/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4210/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4211/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4212/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4213/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4214/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4215/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4216/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4217/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4218/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4219/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4220/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4221/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4222/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4223/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4224/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4225/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4226/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4227/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4228/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4229/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4230/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4231/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4232/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4233/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4234/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4235/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4236/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4237/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4238/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4239/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4240/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4241/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4242/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4243/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4244/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4245/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4246/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4247/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4248/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4249/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4250/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4251/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4252/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4253/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4254/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4255/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4256/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4257/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4258/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4259/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4260/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4261/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4262/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4263/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4264/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4265/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4266/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4267/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4268/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4269/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4270/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4271/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4272/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4273/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4274/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4275/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4276/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4277/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4278/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4279/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4280/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4281/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4282/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4283/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4284/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4285/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4286/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4287/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4288/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4289/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4290/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4291/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4292/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4293/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4294/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4295/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4296/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4297/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4298/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4299/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4300/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4301/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4302/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4303/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4304/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4305/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4306/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4307/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4308/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4309/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4310/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4311/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4312/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4313/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4314/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4315/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4316/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4317/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4318/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4319/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4320/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4321/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4322/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4323/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4324/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4325/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4326/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4327/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4328/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4329/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4330/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4331/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4332/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4333/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4334/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4335/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4336/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4337/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4338/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4339/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4340/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4341/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4342/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4343/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4344/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4345/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4346/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4347/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4348/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4349/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4350/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4351/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4352/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4353/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4354/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4355/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4356/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4357/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4358/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4359/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4360/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4361/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4362/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4363/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4364/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4365/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4366/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4367/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4368/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4369/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4370/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4371/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4372/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4373/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4374/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4375/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4376/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4377/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4378/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4379/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4380/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4381/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4382/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4383/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4384/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4385/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4386/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4387/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4388/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4389/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4390/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4391/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4392/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4393/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4394/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4395/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4396/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4397/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4398/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4399/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4400/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4401/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4402/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4403/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4404/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4405/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4406/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4407/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4408/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4409/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4410/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4411/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4412/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4413/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4414/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4415/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4416/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4417/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4418/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4419/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4420/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4421/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4422/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4423/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4424/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4425/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4426/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4427/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4428/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4429/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4430/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4431/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4432/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4433/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4434/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4435/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4436/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4437/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4438/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4439/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4440/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4441/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4442/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4443/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4444/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4445/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4446/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4447/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4448/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4449/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4450/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4451/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4452/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4453/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4454/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4455/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4456/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4457/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4458/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4459/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4460/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4461/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4462/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4463/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4464/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4465/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4466/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4467/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4468/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4469/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4470/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4471/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4472/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4473/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4474/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4475/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4476/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4477/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4478/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4479/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4480/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4481/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4482/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4483/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4484/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4485/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4486/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4487/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4488/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4489/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4490/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4491/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4492/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4493/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4494/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4495/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4496/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4497/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4498/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4499/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4500/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4501/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4502/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4503/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4504/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4505/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4506/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4507/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4508/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4509/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4510/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4511/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4512/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4513/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4514/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4515/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4516/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4517/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4518/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4519/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4520/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4521/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4522/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4523/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4524/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4525/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4526/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4527/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4528/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4529/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4530/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4531/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4532/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4533/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4534/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4535/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4536/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4537/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4538/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4539/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4540/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4541/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4542/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4543/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4544/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4545/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4546/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4547/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4548/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4549/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4550/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4551/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4552/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4553/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4554/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4555/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4556/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4557/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4558/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4559/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4560/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4561/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4562/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4563/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4564/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4565/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4566/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4567/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4568/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4569/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4570/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4571/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4572/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4573/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4574/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4575/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4576/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4577/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4578/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4579/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4580/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4581/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4582/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4583/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4584/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4585/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4586/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4587/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4588/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4589/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4590/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4591/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4592/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4593/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4594/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4595/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4596/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4597/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4598/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4599/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4600/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4601/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4602/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4603/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4604/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4605/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4606/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4607/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4608/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4609/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4610/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4611/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4612/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4613/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4614/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4615/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4616/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4617/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4618/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4619/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4620/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4621/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4622/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4623/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4624/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4625/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4626/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4627/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4628/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4629/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4630/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4631/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4632/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4633/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4634/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4635/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4636/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4637/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4638/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4639/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4640/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4641/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4642/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4643/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4644/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4645/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4646/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4647/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4648/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4649/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4650/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4651/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4652/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4653/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4654/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4655/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4656/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4657/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4658/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4659/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4660/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4661/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4662/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4663/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4664/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4665/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4666/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4667/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4668/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4669/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4670/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4671/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4672/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4673/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4674/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4675/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4676/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4677/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4678/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4679/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4680/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4681/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4682/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4683/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4684/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4685/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4686/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4687/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4688/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4689/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4690/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4691/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4692/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4693/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4694/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4695/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4696/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4697/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4698/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4699/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4700/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4701/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4702/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4703/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4704/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4705/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4706/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4707/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4708/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4709/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4710/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4711/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4712/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4713/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4714/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4715/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4716/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4717/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4718/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4719/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4720/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4721/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4722/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4723/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4724/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4725/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4726/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4727/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4728/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4729/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4730/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4731/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4732/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4733/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4734/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4735/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4736/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4737/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4738/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4739/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4740/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4741/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4742/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4743/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -67092us/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4744/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4745/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4746/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4747/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4748/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4749/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4750/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4751/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4752/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4753/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4754/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4755/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4756/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4757/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4758/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4759/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4760/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4761/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4762/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4763/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4764/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4765/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4766/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4767/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4768/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4769/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4770/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4771/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4772/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4773/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4774/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4775/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4776/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4777/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4778/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4779/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4780/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4781/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4782/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4783/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4784/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4785/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4786/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4787/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4788/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4789/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4790/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4791/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4792/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4793/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4794/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4795/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4796/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4797/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4798/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4799/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4800/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4801/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4802/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4803/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4804/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4805/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4806/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4807/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4808/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4809/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4810/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4811/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4812/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4813/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4814/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4815/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4816/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4817/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4818/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4819/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4820/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4821/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4822/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4823/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4824/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4825/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4826/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4827/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4828/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4829/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4830/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4831/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4832/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4833/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4834/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4835/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4836/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4837/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4838/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4839/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4840/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4841/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4842/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4843/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4844/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4845/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4846/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4847/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4848/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4849/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4850/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4851/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4852/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4853/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4854/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4855/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4856/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4857/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4858/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4859/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4860/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4861/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4862/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4863/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4864/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4865/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4866/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4867/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4868/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4869/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4870/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4871/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4872/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4873/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4874/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4875/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4876/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4877/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4878/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4879/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4880/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4881/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4882/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4883/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4884/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4885/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4886/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4887/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4888/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4889/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4890/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4891/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4892/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4893/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4894/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4895/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4896/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4897/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4898/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4899/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4900/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4901/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4902/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4903/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4904/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4905/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4906/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4907/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4908/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4909/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4910/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4911/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4912/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4913/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4914/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4915/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4916/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4917/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4918/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4919/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4920/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4921/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4922/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4923/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4924/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4925/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4926/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4927/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4928/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4929/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4930/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4931/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4932/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4933/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4934/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4935/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4936/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4937/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4938/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4939/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4940/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4941/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4942/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4943/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4944/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4945/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4946/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4947/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4948/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4949/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4950/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4951/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4952/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4953/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4954/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4955/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4956/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4957/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4958/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4959/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4960/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4961/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:54:08.274241: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4962/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4963/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4964/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4965/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4966/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4967/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4968/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4969/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4970/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4971/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4972/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4973/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4974/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4975/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4976/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4977/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4978/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4979/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4980/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4981/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4982/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4983/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4984/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4985/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4986/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4987/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4988/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4989/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4990/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4991/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4992/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4993/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4994/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4995/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4996/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4997/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4998/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4999/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 5000/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "gnn_model, history = train_GNN(train_loader=train_loader, val_loader=val_loader,\n",
    "                           epochs=5000, verbose=1, threshold=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c1f873",
   "metadata": {},
   "source": [
    "### Model 2: OrbNet (from ChatGPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "35c1ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# OrbNet-style GNN (minimal, no Dataset code)\n",
    "# Nodes: 5 features (e.g., [F,J,K,P,H]); Edges: 7 ([F,J,K,D,P,S,H])\n",
    "# =========================\n",
    "import math, numpy as np, tensorflow as tf\n",
    "\n",
    "# -------- Cutoff helpers (from raw operator tensors: x_train shaped (N, 7, n, n) or (N, n, n, 7)) --------\n",
    "def ensure_channels_first(X, expected_channels=7):\n",
    "    X = np.asarray(X); assert X.ndim == 4, f\"Expected 4D, got {X.shape}\"\n",
    "    N, a1, a2, a3 = X.shape\n",
    "    if expected_channels in (a1, a2, a3):\n",
    "        c_ax = [a1, a2, a3].index(expected_channels) + 1\n",
    "    else:\n",
    "        if a1 == a2: c_ax = 3\n",
    "        elif a1 == a3: c_ax = 2\n",
    "        elif a2 == a3: c_ax = 1\n",
    "        else: c_ax = int(np.argmin([a1, a2, a3])) + 1\n",
    "    mat_axes = [ax for ax in (1,2,3) if ax != c_ax]\n",
    "    assert X.shape[mat_axes[0]] == X.shape[mat_axes[1]], \"Matrix axes must be square\"\n",
    "    return np.transpose(X, axes=[0, c_ax, mat_axes[0], mat_axes[1]])  # (N, C, n, n)\n",
    "\n",
    "def compute_cutoffs_any(X, pct=99.5, nonzero_only=True, expected_channels=7):\n",
    "    Xcf = ensure_channels_first(X, expected_channels)   # (N, C, n, n)\n",
    "    N, C, n, _ = Xcf.shape\n",
    "    offmask_flat = (~np.eye(n, dtype=bool)).reshape(-1)\n",
    "    c_nodes = np.empty(C, dtype='f4'); c_edges = np.empty(C, dtype='f4')\n",
    "    for c in range(C):\n",
    "        M = Xcf[:, c, :, :]                                   # (N, n, n)\n",
    "        di = np.abs(np.diagonal(M, axis1=1, axis2=2)).ravel()\n",
    "        if nonzero_only: di = di[di != 0]\n",
    "        c_nodes[c] = np.percentile(di, pct) if di.size else 1.0\n",
    "        flat = M.reshape(N, -1)\n",
    "        off = np.abs(flat[:, offmask_flat]).ravel()\n",
    "        if nonzero_only: off = off[off != 0]\n",
    "        c_edges[c] = np.percentile(off, pct) if off.size else c_nodes[c]\n",
    "    return np.maximum(c_nodes, 1e-6), np.maximum(c_edges, 1e-6)\n",
    "\n",
    "# -------------------- Core layers --------------------\n",
    "def he_trunc():\n",
    "    return tf.keras.initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='truncated_normal')\n",
    "\n",
    "class NormAct(tf.keras.layers.Layer):\n",
    "    def __init__(self): super().__init__(); self.ln=tf.keras.layers.LayerNormalization(epsilon=1e-5)\n",
    "    def call(self,x): return tf.keras.activations.gelu(self.ln(x))\n",
    "\n",
    "class NodeSineRBF(tf.keras.layers.Layer):\n",
    "    \"\"\" φ_n^h(r)=sin(π n r), n=1..nr; input (N, d_node), output (N, d_node*nr) \"\"\"\n",
    "    def __init__(self, nr, c_nodes):\n",
    "        super().__init__()\n",
    "        self.nr = int(nr)\n",
    "        self.c_nodes = tf.constant(c_nodes, tf.float32)\n",
    "        self.d_node = int(self.c_nodes.shape[0])\n",
    "    def call(self, x):\n",
    "        x = x / self.c_nodes\n",
    "        n = tf.range(1, self.nr + 1, dtype=tf.float32)[None, None, :]\n",
    "        bases = tf.sin(tf.constant(math.pi, tf.float32) * n * x[:, :, None])   # (N, d_node, nr)\n",
    "        out = tf.reshape(bases, [-1, self.d_node * self.nr])\n",
    "        out.set_shape([None, self.d_node * self.nr])\n",
    "        return out\n",
    "\n",
    "class EdgeBesselRBF(tf.keras.layers.Layer):\n",
    "    \"\"\" φ_m^e(r)=√2/c * sin(π m r/c)/(r/c) * I(r), m=1..mr; input (E, e_dim) -> (E, e_dim*mr) \"\"\"\n",
    "    def __init__(self, mr, c_edges, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.mr = int(mr)\n",
    "        self.c = tf.constant(c_edges, tf.float32)  # (e_dim,)\n",
    "        self.e_dim = int(self.c.shape[0])\n",
    "        self.eps = eps\n",
    "    def call(self, e):\n",
    "        c = self.c[None, :]                       # (1, e_dim)\n",
    "        r = e                                     # (E, e_dim)\n",
    "        abs_r = tf.abs(r)\n",
    "        in_cut = tf.cast(abs_r < c, tf.float32)\n",
    "        I = tf.exp(-(c**2) * ((abs_r - c)**2 + 1.0)) * in_cut\n",
    "        m = tf.range(1, self.mr + 1, dtype=tf.float32)[None, None, :]\n",
    "        z = tf.constant(math.pi, tf.float32) * m * (r[:, :, None] / c[:, :, None])\n",
    "        sinz_over_z = tf.where(tf.abs(z) > self.eps, tf.sin(z) / z, tf.ones_like(z))\n",
    "        phi = (tf.sqrt(2.0) / c[:, :, None]) * sinz_over_z * I[:, :, None]\n",
    "        out = tf.reshape(phi, [-1, self.e_dim * self.mr])\n",
    "        out.set_shape([None, self.e_dim * self.mr])\n",
    "        return out\n",
    "\n",
    "class ResidualMLP3(tf.keras.layers.Layer):\n",
    "    def __init__(self, width, p=0.0):\n",
    "        super().__init__()\n",
    "        self.d1=tf.keras.layers.Dense(width,kernel_initializer=he_trunc(),bias_initializer='zeros')\n",
    "        self.d2=tf.keras.layers.Dense(width,kernel_initializer=he_trunc(),bias_initializer='zeros')\n",
    "        self.d3=tf.keras.layers.Dense(width,kernel_initializer=he_trunc(),bias_initializer='zeros')\n",
    "        self.na=NormAct(); self.drop=tf.keras.layers.Dropout(p)\n",
    "    def call(self,x,training=False):\n",
    "        y1=tf.keras.activations.gelu(self.d1(x))\n",
    "        y2=tf.keras.activations.gelu(self.d2(self.drop(y1,training=training)))\n",
    "        y3=self.d3(self.drop(y2,training=training))\n",
    "        return self.na(y3 + y1)\n",
    "\n",
    "class OrbNetMPL(tf.keras.layers.Layer):\n",
    "    \"\"\" One message-passing layer per Eqs. (16)-(19) with multi-head sigmoid attention. \"\"\"\n",
    "    def __init__(self, d_h, n_e, heads=4, msg_dim=None, p=0.0):\n",
    "        super().__init__()\n",
    "        self.d_h, self.n_e, self.H = d_h, n_e, heads\n",
    "        self.msg = msg_dim or d_h\n",
    "        self.drop = tf.keras.layers.Dropout(p)\n",
    "        self.Wm1 = tf.keras.layers.Dense(n_e, kernel_initializer=he_trunc(), bias_initializer='zeros')\n",
    "        self.Wm2 = tf.keras.layers.Dense(self.msg, kernel_initializer=he_trunc(), bias_initializer='zeros')\n",
    "        self.Wa  = [tf.keras.layers.Dense(n_e, kernel_initializer=he_trunc(), bias_initializer='zeros') for _ in range(self.H)]\n",
    "        self.Wh  = tf.keras.layers.Dense(d_h, kernel_initializer=he_trunc(), bias_initializer='zeros')\n",
    "        self.We  = tf.keras.layers.Dense(n_e, kernel_initializer=he_trunc(), bias_initializer='zeros')\n",
    "        self.naH, self.naE = NormAct(), NormAct()\n",
    "        self.sigA = tf.keras.activations.sigmoid\n",
    "        self._eaux_cache = None  # set by parent model each forward\n",
    "    def call(self, inputs, training=False):\n",
    "        x, a, e, i = inputs                         # a: tf.SparseTensor\n",
    "        idx = tf.cast(a.indices, tf.int32); u, v = idx[:,0], idx[:,1]\n",
    "        hu = tf.gather(x, u); hv = tf.gather(x, v)\n",
    "        triple = self.Wm1(hu) * self.Wm1(hv) * e\n",
    "        m = self.drop(self.Wm2(triple), training=training)          # (E, msg)\n",
    "        N = tf.shape(x)[0]; eaux = self._eaux_cache if self._eaux_cache is not None else e\n",
    "        agg = []\n",
    "        for Wa in self.Wa:\n",
    "            au, av = Wa(hu), Wa(hv)\n",
    "            s = tf.reduce_mean(au * av * e * eaux, axis=-1, keepdims=True)  # (E,1)\n",
    "            w = self.sigA(s); mw = w * m\n",
    "            agg.append(tf.math.unsorted_segment_sum(mw, u, N))             # (N, msg)\n",
    "        Hcat = tf.concat(agg, axis=-1)                                      # (N, H*msg)\n",
    "        x = x + self.naH(self.Wh(Hcat))\n",
    "        e = self.naE(self.We(m))\n",
    "        return x, a, e, i\n",
    "\n",
    "# -------------------- Full model --------------------\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "@keras.saving.register_keras_serializable(package=\"notebook\", name=\"OrbNetModel\")\n",
    "class OrbNetModel(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Inputs (from your DisjointLoader): (x_nodes, a_sparse, e_edges, i_segment)\n",
    "      x_nodes: (N_nodes_in_batch,  d_node)   [d_node=5]\n",
    "      e_edges: (E_edges_in_batch,  e_dim)    [e_dim=7]\n",
    "    \"\"\"\n",
    "    def __init__(self, d_h=128, n_e=64, heads=4, L=3, nr=8, mr=8,\n",
    "                 c_nodes=None, c_edges=None, dropout=0.1, y_bias=0.0,\n",
    "                 **kwargs):                                # <-- accept Keras kwargs\n",
    "        super().__init__(**kwargs)                         # <-- forward them\n",
    "\n",
    "        # save hyperparams for get_config()\n",
    "        self.d_h = d_h\n",
    "        self.n_e = n_e\n",
    "        self.heads = heads\n",
    "        self.L = L\n",
    "        self.nr = nr\n",
    "        self.mr = mr\n",
    "        self.c_nodes = c_nodes\n",
    "        self.c_edges = c_edges\n",
    "        self.dropout = dropout\n",
    "        self.y_bias_init = float(y_bias)\n",
    "\n",
    "        # embeddings (custom layers must be serializable/registered, see note below)\n",
    "        self.node_rbf = NodeSineRBF(nr, c_nodes)\n",
    "        self.edge_rbf = EdgeBesselRBF(mr, c_edges)\n",
    "        self.Ench = ResidualMLP3(d_h, dropout)\n",
    "        self.Ence = ResidualMLP3(n_e, dropout)\n",
    "        self.Aux  = tf.keras.layers.Dense(n_e, use_bias=False, kernel_initializer=he_trunc())\n",
    "\n",
    "        # MPL stack\n",
    "        self.mpls = [OrbNetMPL(d_h, n_e, heads, msg_dim=d_h, p=dropout) for _ in range(L)]\n",
    "\n",
    "        # per-layer decoders\n",
    "        self.Dec  = [tf.keras.Sequential([\n",
    "                        tf.keras.layers.Dense(d_h, activation='gelu', kernel_initializer=he_trunc(), bias_initializer='zeros'),\n",
    "                        tf.keras.layers.Dense(1, kernel_initializer=he_trunc(), bias_initializer='zeros'),\n",
    "                    ]) for _ in range(L+1)]\n",
    "\n",
    "        # trainable bias\n",
    "        self.yb = tf.Variable(self.y_bias_init, trainable=True, dtype=tf.float32, name=\"y_bias\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x_raw, a, e_raw, i = inputs\n",
    "        # embeddings\n",
    "        h0 = self.Ench(self.node_rbf(x_raw), training=training)  # (N, d_h)\n",
    "        erbf = self.edge_rbf(e_raw)                              # (E, 7*mr)\n",
    "        e0 = self.Ence(erbf, training=training)                  # (E, n_e)\n",
    "        eaux = self.Aux(erbf)                                    # (E, n_e)\n",
    "        for layer in self.mpls:\n",
    "            layer._eaux_cache = eaux\n",
    "\n",
    "        # decode l=0 (size-extensive via segment_sum)\n",
    "        y = tf.math.segment_sum(tf.squeeze(self.Dec[0](h0), -1), tf.cast(i, tf.int32))\n",
    "\n",
    "        # MPLs + decode per layer\n",
    "        h, e = h0, e0\n",
    "        for l, mpl in enumerate(self.mpls, start=1):\n",
    "            h, a, e, i = mpl([h, a, e, i], training=training)\n",
    "            y += tf.math.segment_sum(tf.squeeze(self.Dec[l](h), -1), tf.cast(i, tf.int32))\n",
    "        return y + self.yb\n",
    "\n",
    "    # ---- Serialization hooks ----\n",
    "    def get_config(self):\n",
    "        base = super().get_config()\n",
    "        base.update({\n",
    "            \"d_h\": self.d_h, \"n_e\": self.n_e, \"heads\": self.heads, \"L\": self.L,\n",
    "            \"nr\": self.nr, \"mr\": self.mr, \"c_nodes\": self.c_nodes, \"c_edges\": self.c_edges,\n",
    "            \"dropout\": self.dropout, \"y_bias\": float(self.y_bias_init),\n",
    "        })\n",
    "        return base\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Keras may pass trainable/dtype/name in `base`; they’re handled by super().__init__(**kwargs)\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac36fb5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d8f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizhou_chen/miniconda3/envs/base-ml/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py:857: UserWarning: Gradients do not exist for variables ['orb_net_model_1/orb_net_mpl_5/dense_69/kernel', 'orb_net_model_1/orb_net_mpl_5/dense_69/bias', 'orb_net_model_1/orb_net_mpl_5/norm_act_15/layer_normalization_15/gamma', 'orb_net_model_1/orb_net_mpl_5/norm_act_15/layer_normalization_15/beta'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n",
      "/home/yizhou_chen/miniconda3/envs/base-ml/lib/python3.12/site-packages/spektral/data/utils.py:221: UserWarning: you are shuffling a 'SCFAtomGraphDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - loss: 6175.2285 - val_loss: 370.4222 - learning_rate: 3.0000e-04\n",
      "Epoch 2/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 977ms/step - loss: 706.3958 - val_loss: 956.3312 - learning_rate: 3.0000e-04\n",
      "Epoch 3/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 515.6021 - val_loss: 99.6206 - learning_rate: 3.0000e-04\n",
      "Epoch 4/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 392.2156 - val_loss: 412.2973 - learning_rate: 3.0000e-04\n",
      "Epoch 5/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 970ms/step - loss: 94.5350 - val_loss: 107.1236 - learning_rate: 3.0000e-04\n",
      "Epoch 6/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 56.0759 - val_loss: 36.2266 - learning_rate: 3.0000e-04\n",
      "Epoch 7/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 45.6463 - val_loss: 108.1883 - learning_rate: 3.0000e-04\n",
      "Epoch 8/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 965ms/step - loss: 53.2860 - val_loss: 5.5902 - learning_rate: 3.0000e-04\n",
      "Epoch 9/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 51.8250 - val_loss: 268.4921 - learning_rate: 3.0000e-04\n",
      "Epoch 10/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 999ms/step - loss: 120.6519 - val_loss: 136.8234 - learning_rate: 3.0000e-04\n",
      "Epoch 11/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 962ms/step - loss: 213.9625 - val_loss: 3.3949 - learning_rate: 3.0000e-04\n",
      "Epoch 12/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 56.3052 - val_loss: 106.3574 - learning_rate: 3.0000e-04\n",
      "Epoch 13/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 51.9496 - val_loss: 28.6924 - learning_rate: 3.0000e-04\n",
      "Epoch 14/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 959ms/step - loss: 37.5485 - val_loss: 39.8523 - learning_rate: 3.0000e-04\n",
      "Epoch 15/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 34.2699 - val_loss: 52.8659 - learning_rate: 3.0000e-04\n",
      "Epoch 16/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 33.6507 - val_loss: 26.2163 - learning_rate: 3.0000e-04\n",
      "Epoch 17/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 957ms/step - loss: 32.4429 - val_loss: 28.3744 - learning_rate: 3.0000e-04\n",
      "Epoch 18/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 31.2538 - val_loss: 37.3123 - learning_rate: 3.0000e-04\n",
      "Epoch 19/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 30.9137 - val_loss: 31.5482 - learning_rate: 3.0000e-04\n",
      "Epoch 20/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 960ms/step - loss: 28.9182 - val_loss: 19.9201 - learning_rate: 3.0000e-04\n",
      "Epoch 21/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 29.3283 - val_loss: 30.3357 - learning_rate: 3.0000e-04\n",
      "Epoch 22/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 26.3137 - val_loss: 32.2963 - learning_rate: 3.0000e-04\n",
      "Epoch 23/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 963ms/step - loss: 27.2549 - val_loss: 14.0963 - learning_rate: 3.0000e-04\n",
      "Epoch 24/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 28.9055 - val_loss: 22.9393 - learning_rate: 3.0000e-04\n",
      "Epoch 25/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 998ms/step - loss: 27.4491 - val_loss: 34.8743 - learning_rate: 3.0000e-04\n",
      "Epoch 26/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 964ms/step - loss: 28.2259 - val_loss: 10.3952 - learning_rate: 3.0000e-04\n",
      "Epoch 27/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 28.9415 - val_loss: 15.2011 - learning_rate: 3.0000e-04\n",
      "Epoch 28/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 953ms/step - loss: 26.4157 - val_loss: 38.5609 - learning_rate: 3.0000e-04\n",
      "Epoch 29/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 964ms/step - loss: 27.7467 - val_loss: 7.7897 - learning_rate: 3.0000e-04\n",
      "Epoch 30/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 28.2803 - val_loss: 14.3456 - learning_rate: 3.0000e-04\n",
      "Epoch 31/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 962ms/step - loss: 24.9375 - val_loss: 37.5474 - learning_rate: 3.0000e-04\n",
      "Epoch 32/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 26.5341 - val_loss: 6.1770 - learning_rate: 3.0000e-04\n",
      "Epoch 33/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 27.5159 - val_loss: 11.2620 - learning_rate: 3.0000e-04\n",
      "Epoch 34/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 958ms/step - loss: 23.4879 - val_loss: 37.7834 - learning_rate: 3.0000e-04\n",
      "Epoch 35/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 26.4763 - val_loss: 4.3360 - learning_rate: 3.0000e-04\n",
      "Epoch 36/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 14.1882 - val_loss: 13.1344 - learning_rate: 3.0000e-04\n",
      "Epoch 37/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 965ms/step - loss: 20.2909 - val_loss: 12.3949 - learning_rate: 3.0000e-04\n",
      "Epoch 38/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 20.2976 - val_loss: 16.0040 - learning_rate: 3.0000e-04\n",
      "Epoch 39/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 18.6338 - val_loss: 26.1700 - learning_rate: 3.0000e-04\n",
      "Epoch 40/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 980ms/step - loss: 19.8381 - val_loss: 7.6085 - learning_rate: 3.0000e-04\n",
      "Epoch 41/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 21.3274 - val_loss: 11.1666 - learning_rate: 3.0000e-04\n",
      "Epoch 42/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 18.9117 - val_loss: 29.5685 - learning_rate: 3.0000e-04\n",
      "Epoch 43/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 20.7608 - val_loss: 4.4359 - learning_rate: 3.0000e-04\n",
      "Epoch 44/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 22.5525 - val_loss: 6.8778 - learning_rate: 3.0000e-04\n",
      "Epoch 45/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 18.4145 - val_loss: 32.7720 - learning_rate: 3.0000e-04\n",
      "Epoch 46/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 964ms/step - loss: 18.9760 - val_loss: 6.8519 - learning_rate: 3.0000e-04\n",
      "Epoch 47/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 999ms/step - loss: 18.3433 - val_loss: 11.4250 - learning_rate: 3.0000e-04\n",
      "Epoch 48/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 15.8293 - val_loss: 24.6440 - learning_rate: 3.0000e-04\n",
      "Epoch 49/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 981ms/step - loss: 16.6594 - val_loss: 6.4081 - learning_rate: 3.0000e-04\n",
      "Epoch 50/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 17.7265 - val_loss: 8.6384 - learning_rate: 3.0000e-04\n",
      "Epoch 51/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 16.4330 - val_loss: 26.6192 - learning_rate: 3.0000e-04\n",
      "Epoch 52/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 981ms/step - loss: 17.7539 - val_loss: 4.6385 - learning_rate: 3.0000e-04\n",
      "Epoch 53/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 18.1698 - val_loss: 7.4899 - learning_rate: 3.0000e-04\n",
      "Epoch 54/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 15.8835 - val_loss: 21.0784 - learning_rate: 3.0000e-04\n",
      "Epoch 55/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 979ms/step - loss: 21.0724 - val_loss: 32.6998 - learning_rate: 3.0000e-04\n",
      "Epoch 56/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 18.3108 - val_loss: 39.2986 - learning_rate: 3.0000e-04\n",
      "Epoch 57/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 999ms/step - loss: 18.2999 - val_loss: 4.1725 - learning_rate: 3.0000e-04\n",
      "Epoch 58/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 952ms/step - loss: 17.0380 - val_loss: 24.0316 - learning_rate: 3.0000e-04\n",
      "Epoch 59/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 998ms/step - loss: 13.7686 - val_loss: 29.8069 - learning_rate: 3.0000e-04\n",
      "Epoch 60/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 997ms/step - loss: 14.9848 - val_loss: 5.1293 - learning_rate: 3.0000e-04\n",
      "Epoch 61/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 961ms/step - loss: 13.8165 - val_loss: 18.5282 - learning_rate: 3.0000e-04\n",
      "Epoch 62/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 994ms/step - loss: 12.4264 - val_loss: 23.9290 - learning_rate: 3.0000e-04\n",
      "Epoch 63/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 997ms/step - loss: 12.7789 - val_loss: 7.2413 - learning_rate: 3.0000e-04\n",
      "Epoch 64/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 957ms/step - loss: 13.0491 - val_loss: 16.2812 - learning_rate: 3.0000e-04\n",
      "Epoch 65/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 995ms/step - loss: 12.1499 - val_loss: 18.8125 - learning_rate: 3.0000e-04\n",
      "Epoch 66/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 995ms/step - loss: 11.8978 - val_loss: 10.4201 - learning_rate: 3.0000e-04\n",
      "Epoch 67/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 987ms/step - loss: 12.0075 - val_loss: 11.4580 - learning_rate: 3.0000e-04\n",
      "Epoch 68/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 11.3564 - val_loss: 15.2442 - learning_rate: 3.0000e-04\n",
      "Epoch 69/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 11.4606 - val_loss: 11.2547 - learning_rate: 3.0000e-04\n",
      "Epoch 70/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 985ms/step - loss: 11.6441 - val_loss: 7.9614 - learning_rate: 3.0000e-04\n",
      "Epoch 71/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - loss: 11.2567 - val_loss: 11.8588 - learning_rate: 3.0000e-04\n",
      "Epoch 72/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 963ms/step - loss: 10.9335 - val_loss: 14.5905 - learning_rate: 3.0000e-04\n",
      "Epoch 73/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 11.5793 - val_loss: 4.5069 - learning_rate: 3.0000e-04\n",
      "Epoch 74/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 964ms/step - loss: 11.8163 - val_loss: 8.6651 - learning_rate: 3.0000e-04\n",
      "Epoch 75/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 965ms/step - loss: 11.1841 - val_loss: 16.6658 - learning_rate: 3.0000e-04\n",
      "Epoch 76/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 11.7128 - val_loss: 4.4044 - learning_rate: 3.0000e-04\n",
      "Epoch 77/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 993ms/step - loss: 11.6297 - val_loss: 6.9363 - learning_rate: 3.0000e-04\n",
      "Epoch 78/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 987ms/step - loss: 10.5970 - val_loss: 17.3498 - learning_rate: 3.0000e-04\n",
      "Epoch 79/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 11.6261 - val_loss: 3.1362 - learning_rate: 3.0000e-04\n",
      "Epoch 80/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 12.2510 - val_loss: 5.5123 - learning_rate: 3.0000e-04\n",
      "Epoch 81/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 968ms/step - loss: 10.7238 - val_loss: 17.9541 - learning_rate: 3.0000e-04\n",
      "Epoch 82/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 997ms/step - loss: 11.8224 - val_loss: 2.7812 - learning_rate: 3.0000e-04\n",
      "Epoch 83/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 956ms/step - loss: 12.7082 - val_loss: 5.4881 - learning_rate: 3.0000e-04\n",
      "Epoch 84/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 999ms/step - loss: 10.3395 - val_loss: 16.2840 - learning_rate: 3.0000e-04\n",
      "Epoch 85/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 998ms/step - loss: 10.8146 - val_loss: 3.0145 - learning_rate: 3.0000e-04\n",
      "Epoch 86/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 950ms/step - loss: 12.0644 - val_loss: 5.6737 - learning_rate: 3.0000e-04\n",
      "Epoch 87/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 996ms/step - loss: 10.4801 - val_loss: 16.9846 - learning_rate: 3.0000e-04\n",
      "Epoch 88/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 999ms/step - loss: 10.9342 - val_loss: 2.4401 - learning_rate: 3.0000e-04\n",
      "Epoch 89/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 954ms/step - loss: 11.6200 - val_loss: 4.1287 - learning_rate: 3.0000e-04\n",
      "Epoch 90/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 995ms/step - loss: 10.1514 - val_loss: 17.1757 - learning_rate: 3.0000e-04\n",
      "Epoch 91/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 10.9703 - val_loss: 1.8975 - learning_rate: 3.0000e-04\n",
      "Epoch 92/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 955ms/step - loss: 13.5840 - val_loss: 1.9409 - learning_rate: 3.0000e-04\n",
      "Epoch 93/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 991ms/step - loss: 19.9063 - val_loss: 13.3664 - learning_rate: 3.0000e-04\n",
      "Epoch 94/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 998ms/step - loss: 13.6157 - val_loss: 20.9553 - learning_rate: 3.0000e-04\n",
      "Epoch 95/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 958ms/step - loss: 11.5257 - val_loss: 3.5960 - learning_rate: 3.0000e-04\n",
      "Epoch 96/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 993ms/step - loss: 9.5554 - val_loss: 5.7214 - learning_rate: 3.0000e-04\n",
      "Epoch 97/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 993ms/step - loss: 9.5109 - val_loss: 16.5851 - learning_rate: 3.0000e-04\n",
      "Epoch 98/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 958ms/step - loss: 8.8805 - val_loss: 2.4321 - learning_rate: 3.0000e-04\n",
      "Epoch 99/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 8.5386 - val_loss: 4.4287 - learning_rate: 3.0000e-04\n",
      "Epoch 100/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 993ms/step - loss: 8.5197 - val_loss: 16.3880 - learning_rate: 3.0000e-04\n",
      "Epoch 101/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 957ms/step - loss: 8.5476 - val_loss: 2.0689 - learning_rate: 3.0000e-04\n",
      "Epoch 102/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 998ms/step - loss: 8.1094 - val_loss: 3.8204 - learning_rate: 3.0000e-04\n",
      "Epoch 103/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 974ms/step - loss: 8.0430 - val_loss: 15.7523 - learning_rate: 3.0000e-04\n",
      "Epoch 104/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 977ms/step - loss: 7.7983 - val_loss: 2.2876 - learning_rate: 3.0000e-04\n",
      "Epoch 105/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 7.4936 - val_loss: 4.4178 - learning_rate: 3.0000e-04\n",
      "Epoch 106/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 7.6300 - val_loss: 14.7742 - learning_rate: 3.0000e-04\n",
      "Epoch 107/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 996ms/step - loss: 8.0779 - val_loss: 2.3447 - learning_rate: 3.0000e-04\n",
      "Epoch 108/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 7.1670 - val_loss: 4.2839 - learning_rate: 3.0000e-04\n",
      "Epoch 109/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 8.0184 - val_loss: 12.1328 - learning_rate: 3.0000e-04\n",
      "Epoch 110/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 962ms/step - loss: 8.0181 - val_loss: 3.2127 - learning_rate: 3.0000e-04\n",
      "Epoch 111/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 994ms/step - loss: 7.1824 - val_loss: 5.7654 - learning_rate: 3.0000e-04\n",
      "Epoch 112/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 995ms/step - loss: 7.5422 - val_loss: 10.4670 - learning_rate: 3.0000e-04\n",
      "Epoch 113/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 961ms/step - loss: 7.9462 - val_loss: 3.9636 - learning_rate: 3.0000e-04\n",
      "Epoch 114/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 7.3601 - val_loss: 6.8927 - learning_rate: 3.0000e-04\n",
      "Epoch 115/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 997ms/step - loss: 8.0888 - val_loss: 8.8076 - learning_rate: 3.0000e-04\n",
      "Epoch 116/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 989ms/step - loss: 7.9835 - val_loss: 3.5731 - learning_rate: 3.0000e-04\n",
      "Epoch 117/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 987ms/step - loss: 7.2523 - val_loss: 6.4882 - learning_rate: 3.0000e-04\n",
      "Epoch 118/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 993ms/step - loss: 8.3777 - val_loss: 8.3825 - learning_rate: 3.0000e-04\n",
      "Epoch 119/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 40s/step - loss: 8.1130 - val_loss: 4.3479 - learning_rate: 3.0000e-04\n",
      "Epoch 120/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 7.2557 - val_loss: 7.8182 - learning_rate: 3.0000e-04\n",
      "Epoch 121/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 8.9671 - val_loss: 6.6123 - learning_rate: 3.0000e-04\n",
      "Epoch 122/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 994ms/step - loss: 8.4025 - val_loss: 4.9728 - learning_rate: 3.0000e-04\n",
      "Epoch 123/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 999ms/step - loss: 7.0451 - val_loss: 8.6176 - learning_rate: 3.0000e-04\n",
      "Epoch 124/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 6.1146 - val_loss: 1.1872 - learning_rate: 3.0000e-04\n",
      "Epoch 125/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 977ms/step - loss: 21.2697 - val_loss: 0.5645 - learning_rate: 3.0000e-04\n",
      "Epoch 126/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 972ms/step - loss: 3.9081 - val_loss: 8.9069 - learning_rate: 3.0000e-04\n",
      "Epoch 127/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 966ms/step - loss: 17.1083 - val_loss: 4.2878 - learning_rate: 3.0000e-04\n",
      "Epoch 128/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 963ms/step - loss: 16.8073 - val_loss: 38.3912 - learning_rate: 3.0000e-04\n",
      "Epoch 129/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 955ms/step - loss: 16.4606 - val_loss: 19.1341 - learning_rate: 3.0000e-04\n",
      "Epoch 130/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 961ms/step - loss: 16.4584 - val_loss: 13.3448 - learning_rate: 3.0000e-04\n",
      "Epoch 131/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 963ms/step - loss: 15.1178 - val_loss: 5.6003 - learning_rate: 3.0000e-04\n",
      "Epoch 132/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 959ms/step - loss: 15.4991 - val_loss: 23.3475 - learning_rate: 3.0000e-04\n",
      "Epoch 133/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 955ms/step - loss: 14.7203 - val_loss: 9.7799 - learning_rate: 3.0000e-04\n",
      "Epoch 134/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 964ms/step - loss: 14.7352 - val_loss: 20.3252 - learning_rate: 3.0000e-04\n",
      "Epoch 135/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 959ms/step - loss: 13.8027 - val_loss: 10.2103 - learning_rate: 3.0000e-04\n",
      "Epoch 136/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 953ms/step - loss: 15.3323 - val_loss: 15.7824 - learning_rate: 3.0000e-04\n",
      "Epoch 137/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 963ms/step - loss: 14.7330 - val_loss: 6.0643 - learning_rate: 3.0000e-04\n",
      "Epoch 138/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 964ms/step - loss: 13.9619 - val_loss: 23.9949 - learning_rate: 3.0000e-04\n",
      "Epoch 139/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 956ms/step - loss: 13.4528 - val_loss: 14.0794 - learning_rate: 3.0000e-04\n",
      "Epoch 140/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 960ms/step - loss: 16.2936 - val_loss: 13.4299 - learning_rate: 3.0000e-04\n",
      "Epoch 141/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 971ms/step - loss: 15.7640 - val_loss: 4.9630 - learning_rate: 3.0000e-04\n",
      "Epoch 142/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 14.0255 - val_loss: 25.2357 - learning_rate: 3.0000e-04\n",
      "Epoch 143/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 13.4214 - val_loss: 14.3828 - learning_rate: 3.0000e-04\n",
      "Epoch 144/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 996ms/step - loss: 15.8272 - val_loss: 9.8765 - learning_rate: 3.0000e-04\n",
      "Epoch 145/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 994ms/step - loss: 15.8554 - val_loss: 2.9323 - learning_rate: 3.0000e-04\n",
      "Epoch 146/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 981ms/step - loss: 14.0886 - val_loss: 24.3504 - learning_rate: 3.0000e-04\n",
      "Epoch 147/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 963ms/step - loss: 13.4812 - val_loss: 12.3288 - learning_rate: 3.0000e-04\n",
      "Epoch 148/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 984ms/step - loss: 15.1559 - val_loss: 10.6735 - learning_rate: 3.0000e-04\n",
      "Epoch 149/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 975ms/step - loss: 14.4070 - val_loss: 3.2594 - learning_rate: 3.0000e-04\n",
      "Epoch 150/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 982ms/step - loss: 9.3834 - val_loss: 0.5972 - learning_rate: 3.0000e-04\n",
      "Epoch 151/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 970ms/step - loss: 32.2648 - val_loss: 1.4599 - learning_rate: 3.0000e-04\n",
      "Epoch 152/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 975ms/step - loss: 5.7712 - val_loss: 0.9737 - learning_rate: 3.0000e-04\n",
      "Epoch 153/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 978ms/step - loss: 4.8982 - val_loss: 0.1743 - learning_rate: 3.0000e-04\n",
      "Epoch 154/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 973ms/step - loss: 23.6777 - val_loss: 6.9062 - learning_rate: 3.0000e-04\n",
      "Epoch 155/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 983ms/step - loss: 10.6011 - val_loss: 0.9849 - learning_rate: 3.0000e-04\n",
      "Epoch 156/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 982ms/step - loss: 9.9927 - val_loss: 1.1761 - learning_rate: 3.0000e-04\n",
      "Epoch 157/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 998ms/step - loss: 8.4310 - val_loss: 2.6894 - learning_rate: 3.0000e-04\n",
      "Epoch 158/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 994ms/step - loss: 9.2064 - val_loss: 0.9158 - learning_rate: 3.0000e-04\n",
      "Epoch 159/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 8.1941 - val_loss: 0.2673 - learning_rate: 3.0000e-04\n",
      "Epoch 160/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 991ms/step - loss: 9.4069 - val_loss: 21.6234 - learning_rate: 3.0000e-04\n",
      "Epoch 161/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 995ms/step - loss: 8.2769 - val_loss: 10.4506 - learning_rate: 3.0000e-04\n",
      "Epoch 162/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 12.2187 - val_loss: 1.5925 - learning_rate: 3.0000e-04\n",
      "Epoch 163/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 11.4219 - val_loss: 28.3290 - learning_rate: 3.0000e-04\n",
      "Epoch 164/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 981ms/step - loss: 11.9419 - val_loss: 16.5363 - learning_rate: 3.0000e-04\n",
      "Epoch 165/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 994ms/step - loss: 6.9625 - val_loss: 0.1540 - learning_rate: 3.0000e-04\n",
      "Epoch 166/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 18.0663 - val_loss: 22.5525 - learning_rate: 3.0000e-04\n",
      "Epoch 167/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 994ms/step - loss: 15.0461 - val_loss: 37.0979 - learning_rate: 3.0000e-04\n",
      "Epoch 168/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 992ms/step - loss: 5.5190 - val_loss: 3.4044 - learning_rate: 3.0000e-04\n",
      "Epoch 169/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 982ms/step - loss: 2.2350 - val_loss: 0.7650 - learning_rate: 3.0000e-04\n",
      "Epoch 170/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 975ms/step - loss: 2.3222 - val_loss: 0.9361 - learning_rate: 3.0000e-04\n",
      "Epoch 171/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.8089 - val_loss: 4.9792 - learning_rate: 3.0000e-04\n",
      "Epoch 172/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 994ms/step - loss: 1.8619 - val_loss: 0.6813 - learning_rate: 3.0000e-04\n",
      "Epoch 173/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 992ms/step - loss: 1.4319 - val_loss: 1.8863 - learning_rate: 3.0000e-04\n",
      "Epoch 174/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.3459 - val_loss: 0.6897 - learning_rate: 3.0000e-04\n",
      "Epoch 175/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 991ms/step - loss: 1.3710 - val_loss: 1.6198 - learning_rate: 3.0000e-04\n",
      "Epoch 176/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.3094 - val_loss: 0.7481 - learning_rate: 3.0000e-04\n",
      "Epoch 177/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 989ms/step - loss: 1.3507 - val_loss: 1.3893 - learning_rate: 3.0000e-04\n",
      "Epoch 178/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.3458 - val_loss: 1.1398 - learning_rate: 3.0000e-04\n",
      "Epoch 179/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 956ms/step - loss: 1.4633 - val_loss: 1.0362 - learning_rate: 3.0000e-04\n",
      "Epoch 180/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 956ms/step - loss: 1.3749 - val_loss: 1.3331 - learning_rate: 3.0000e-04\n",
      "Epoch 181/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.5396 - val_loss: 1.0484 - learning_rate: 3.0000e-04\n",
      "Epoch 182/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 981ms/step - loss: 1.3181 - val_loss: 1.0835 - learning_rate: 3.0000e-04\n",
      "Epoch 183/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.3784 - val_loss: 1.2526 - learning_rate: 3.0000e-04\n",
      "Epoch 184/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 989ms/step - loss: 1.2132 - val_loss: 1.1317 - learning_rate: 3.0000e-04\n",
      "Epoch 185/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 964ms/step - loss: 1.4944 - val_loss: 0.8690 - learning_rate: 3.0000e-04\n",
      "Epoch 186/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 985ms/step - loss: 1.3053 - val_loss: 1.1378 - learning_rate: 3.0000e-04\n",
      "Epoch 187/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 999ms/step - loss: 1.3718 - val_loss: 0.8535 - learning_rate: 3.0000e-04\n",
      "Epoch 188/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 993ms/step - loss: 1.3874 - val_loss: 1.5231 - learning_rate: 3.0000e-04\n",
      "Epoch 189/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 987ms/step - loss: 1.5317 - val_loss: 0.6791 - learning_rate: 3.0000e-04\n",
      "Epoch 190/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.5247 - val_loss: 1.3354 - learning_rate: 3.0000e-04\n",
      "Epoch 191/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 975ms/step - loss: 1.5659 - val_loss: 0.7754 - learning_rate: 3.0000e-04\n",
      "Epoch 192/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 989ms/step - loss: 1.4097 - val_loss: 1.4913 - learning_rate: 3.0000e-04\n",
      "Epoch 193/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.8676 - val_loss: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 194/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 953ms/step - loss: 1.6827 - val_loss: 1.4249 - learning_rate: 3.0000e-04\n",
      "Epoch 195/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 991ms/step - loss: 1.7202 - val_loss: 0.8341 - learning_rate: 3.0000e-04\n",
      "Epoch 196/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.3799 - val_loss: 1.3654 - learning_rate: 3.0000e-04\n",
      "Epoch 197/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 968ms/step - loss: 1.4448 - val_loss: 1.6147 - learning_rate: 3.0000e-04\n",
      "Epoch 198/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 984ms/step - loss: 1.8958 - val_loss: 0.5141 - learning_rate: 3.0000e-04\n",
      "Epoch 199/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.6178 - val_loss: 0.2529 - learning_rate: 3.0000e-04\n",
      "Epoch 200/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 969ms/step - loss: 2.0723 - val_loss: 1.4507 - learning_rate: 3.0000e-04\n",
      "Epoch 201/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 999ms/step - loss: 6.3664 - val_loss: 0.1052 - learning_rate: 3.0000e-04\n",
      "Epoch 202/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 10.1254 - val_loss: 5.2413 - learning_rate: 3.0000e-04\n",
      "Epoch 203/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 968ms/step - loss: 10.0517 - val_loss: 6.7238 - learning_rate: 3.0000e-04\n",
      "Epoch 204/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 992ms/step - loss: 7.9589 - val_loss: 22.8325 - learning_rate: 3.0000e-04\n",
      "Epoch 205/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 9.0382 - val_loss: 0.3861 - learning_rate: 3.0000e-04\n",
      "Epoch 206/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 967ms/step - loss: 8.0313 - val_loss: 10.6554 - learning_rate: 3.0000e-04\n",
      "Epoch 207/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 8.2079 - val_loss: 2.1154 - learning_rate: 3.0000e-04\n",
      "Epoch 208/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 7.7235 - val_loss: 12.4319 - learning_rate: 3.0000e-04\n",
      "Epoch 209/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 986ms/step - loss: 8.8931 - val_loss: 3.1179 - learning_rate: 3.0000e-04\n",
      "Epoch 210/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 7.4638 - val_loss: 18.7440 - learning_rate: 3.0000e-04\n",
      "Epoch 211/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 9.3334 - val_loss: 0.1946 - learning_rate: 3.0000e-04\n",
      "Epoch 212/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 981ms/step - loss: 4.0088 - val_loss: 1.3807 - learning_rate: 3.0000e-04\n",
      "Epoch 213/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.8372 - val_loss: 0.3086 - learning_rate: 3.0000e-04\n",
      "Epoch 214/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 2.5288 - val_loss: 1.5897 - learning_rate: 3.0000e-04\n",
      "Epoch 215/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 970ms/step - loss: 3.1867 - val_loss: 4.9748 - learning_rate: 3.0000e-04\n",
      "Epoch 216/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 996ms/step - loss: 3.1313 - val_loss: 1.6101 - learning_rate: 3.0000e-04\n",
      "Epoch 217/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 2.8947 - val_loss: 3.0219 - learning_rate: 3.0000e-04\n",
      "Epoch 218/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 972ms/step - loss: 3.4677 - val_loss: 2.4243 - learning_rate: 3.0000e-04\n",
      "Epoch 219/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 983ms/step - loss: 2.5800 - val_loss: 6.6459 - learning_rate: 3.0000e-04\n",
      "Epoch 220/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 992ms/step - loss: 2.2171 - val_loss: 18.9631 - learning_rate: 3.0000e-04\n",
      "Epoch 221/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 955ms/step - loss: 12.4187 - val_loss: 18.4024 - learning_rate: 3.0000e-04\n",
      "Epoch 222/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 977ms/step - loss: 3.9440 - val_loss: 15.9737 - learning_rate: 3.0000e-04\n",
      "Epoch 223/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 982ms/step - loss: 6.8630 - val_loss: 0.5992 - learning_rate: 3.0000e-04\n",
      "Epoch 224/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 953ms/step - loss: 7.5197 - val_loss: 1.2367 - learning_rate: 3.0000e-04\n",
      "Epoch 225/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 2.3045 - val_loss: 14.8510 - learning_rate: 3.0000e-04\n",
      "Epoch 226/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 990ms/step - loss: 6.0605 - val_loss: 0.7868 - learning_rate: 3.0000e-04\n",
      "Epoch 227/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 992ms/step - loss: 4.5078 - val_loss: 0.7518 - learning_rate: 3.0000e-04\n",
      "Epoch 228/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 4.7033 - val_loss: 1.3239 - learning_rate: 3.0000e-04\n",
      "Epoch 229/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 4.6025 - val_loss: 0.2048 - learning_rate: 3.0000e-04\n",
      "Epoch 230/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 4.2577 - val_loss: 1.6592 - learning_rate: 3.0000e-04\n",
      "Epoch 231/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.9945 - val_loss: 1.0264 - learning_rate: 3.0000e-04\n",
      "Epoch 232/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.9210 - val_loss: 1.3658 - learning_rate: 3.0000e-04\n",
      "Epoch 233/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.6201 - val_loss: 1.4475 - learning_rate: 3.0000e-04\n",
      "Epoch 234/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.4752 - val_loss: 0.8498 - learning_rate: 3.0000e-04\n",
      "Epoch 235/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.4821 - val_loss: 0.7908 - learning_rate: 3.0000e-04\n",
      "Epoch 236/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.4546 - val_loss: 0.5103 - learning_rate: 3.0000e-04\n",
      "Epoch 237/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 2.6379 - val_loss: 0.8705 - learning_rate: 3.0000e-04\n",
      "Epoch 238/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 2.5795 - val_loss: 2.2077 - learning_rate: 3.0000e-04\n",
      "Epoch 239/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 3.0027 - val_loss: 2.9797 - learning_rate: 3.0000e-04\n",
      "Epoch 240/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 3.0985 - val_loss: 1.9367 - learning_rate: 3.0000e-04\n",
      "Epoch 241/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 2.7760 - val_loss: 3.2658 - learning_rate: 3.0000e-04\n",
      "Epoch 242/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 3.4061 - val_loss: 2.2220 - learning_rate: 3.0000e-04\n",
      "Epoch 243/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 2.9209 - val_loss: 1.5686 - learning_rate: 3.0000e-04\n",
      "Epoch 244/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 2.6685 - val_loss: 2.8433 - learning_rate: 3.0000e-04\n",
      "Epoch 245/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 3.2379 - val_loss: 2.2348 - learning_rate: 3.0000e-04\n",
      "Epoch 246/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 2.0936 - val_loss: 6.9719 - learning_rate: 3.0000e-04\n",
      "Epoch 247/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 2.5257 - val_loss: 0.1633 - learning_rate: 3.0000e-04\n",
      "Epoch 248/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 2.7110 - val_loss: 6.3660 - learning_rate: 3.0000e-04\n",
      "Epoch 249/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 11.0221 - val_loss: 1.6919 - learning_rate: 3.0000e-04\n",
      "Epoch 250/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 10.4051 - val_loss: 0.5812 - learning_rate: 3.0000e-04\n",
      "Epoch 251/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 4.1085 - val_loss: 3.8886 - learning_rate: 3.0000e-04\n",
      "Epoch 252/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 3.9768 - val_loss: 0.5130 - learning_rate: 3.0000e-04\n",
      "Epoch 253/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 1.0547 - val_loss: 3.8509 - learning_rate: 3.0000e-04\n",
      "Epoch 254/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 3.7993 - val_loss: 2.7177 - learning_rate: 3.0000e-04\n",
      "Epoch 255/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 3.6253 - val_loss: 1.2899 - learning_rate: 3.0000e-04\n",
      "Epoch 256/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 2.1955 - val_loss: 6.2816 - learning_rate: 3.0000e-04\n",
      "Epoch 257/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - loss: 4.4951 - val_loss: 0.2481 - learning_rate: 3.0000e-04\n",
      "Epoch 258/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - loss: 0.8989 - val_loss: 0.2150 - learning_rate: 3.0000e-04\n",
      "Epoch 259/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 0.8977 - val_loss: 0.0609 - learning_rate: 3.0000e-04\n",
      "Epoch 260/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 1.0231 - val_loss: 1.3521 - learning_rate: 3.0000e-04\n",
      "Epoch 261/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.8829 - val_loss: 0.1966 - learning_rate: 3.0000e-04\n",
      "Epoch 262/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.8111 - val_loss: 1.0655 - learning_rate: 3.0000e-04\n",
      "Epoch 263/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.7876 - val_loss: 0.3696 - learning_rate: 3.0000e-04\n",
      "Epoch 264/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 0.8667 - val_loss: 0.5822 - learning_rate: 3.0000e-04\n",
      "Epoch 265/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.8740 - val_loss: 0.6540 - learning_rate: 3.0000e-04\n",
      "Epoch 266/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 0.9623 - val_loss: 0.2295 - learning_rate: 3.0000e-04\n",
      "Epoch 267/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 1.0512 - val_loss: 0.8813 - learning_rate: 3.0000e-04\n",
      "Epoch 268/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 3.7285 - val_loss: 2.6513 - learning_rate: 3.0000e-04\n",
      "Epoch 269/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 1.4100 - val_loss: 0.8474 - learning_rate: 3.0000e-04\n",
      "Epoch 270/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 1.2159 - val_loss: 0.0968 - learning_rate: 3.0000e-04\n",
      "Epoch 271/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 0.9918 - val_loss: 2.5130 - learning_rate: 3.0000e-04\n",
      "Epoch 272/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.9376 - val_loss: 0.0899 - learning_rate: 3.0000e-04\n",
      "Epoch 273/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 0.8870 - val_loss: 2.3627 - learning_rate: 3.0000e-04\n",
      "Epoch 274/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - loss: 0.8460 - val_loss: 0.0653 - learning_rate: 3.0000e-04\n",
      "Epoch 275/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - loss: 0.7745 - val_loss: 2.0433 - learning_rate: 3.0000e-04\n",
      "Epoch 276/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.7546 - val_loss: 0.0591 - learning_rate: 3.0000e-04\n",
      "Epoch 277/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.7161 - val_loss: 1.8592 - learning_rate: 3.0000e-04\n",
      "Epoch 278/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 0.6967 - val_loss: 0.0645 - learning_rate: 3.0000e-04\n",
      "Epoch 279/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 0.6513 - val_loss: 1.6264 - learning_rate: 3.0000e-04\n",
      "Epoch 280/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 0.7116 - val_loss: 0.0768 - learning_rate: 3.0000e-04\n",
      "Epoch 281/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.6567 - val_loss: 1.3645 - learning_rate: 3.0000e-04\n",
      "Epoch 282/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.6421 - val_loss: 0.1400 - learning_rate: 3.0000e-04\n",
      "Epoch 283/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.6542 - val_loss: 1.0718 - learning_rate: 3.0000e-04\n",
      "Epoch 284/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.6489 - val_loss: 0.2196 - learning_rate: 3.0000e-04\n",
      "Epoch 285/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 0.7289 - val_loss: 0.6514 - learning_rate: 3.0000e-04\n",
      "Epoch 286/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 0.6897 - val_loss: 0.3783 - learning_rate: 3.0000e-04\n",
      "Epoch 287/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 0.8113 - val_loss: 0.5311 - learning_rate: 3.0000e-04\n",
      "Epoch 288/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.8274 - val_loss: 0.5463 - learning_rate: 3.0000e-04\n",
      "Epoch 289/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.8545 - val_loss: 0.5406 - learning_rate: 3.0000e-04\n",
      "Epoch 290/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 0.8216 - val_loss: 0.4783 - learning_rate: 3.0000e-04\n",
      "Epoch 291/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - loss: 0.8591 - val_loss: 0.4162 - learning_rate: 3.0000e-04\n",
      "Epoch 292/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 0.8771 - val_loss: 0.5925 - learning_rate: 3.0000e-04\n",
      "Epoch 293/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.9127 - val_loss: 0.4564 - learning_rate: 3.0000e-04\n",
      "Epoch 294/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.8997 - val_loss: 0.6257 - learning_rate: 3.0000e-04\n",
      "Epoch 295/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.8461 - val_loss: 0.4735 - learning_rate: 3.0000e-04\n",
      "Epoch 296/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 0.8856 - val_loss: 0.2837 - learning_rate: 3.0000e-04\n",
      "Epoch 297/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 0.7857 - val_loss: 0.9076 - learning_rate: 3.0000e-04\n",
      "Epoch 298/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11275s\u001b[0m 537s/step - loss: 0.6768 - val_loss: 0.2496 - learning_rate: 3.0000e-04\n",
      "Epoch 299/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - loss: 0.7078 - val_loss: 0.6509 - learning_rate: 3.0000e-04\n",
      "Epoch 300/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 938ms/step - loss: 0.7302 - val_loss: 0.3220 - learning_rate: 3.0000e-04\n",
      "Epoch 301/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.6888 - val_loss: 0.6991 - learning_rate: 3.0000e-04\n",
      "Epoch 302/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.7335 - val_loss: 0.3645 - learning_rate: 3.0000e-04\n",
      "Epoch 303/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 986ms/step - loss: 0.7420 - val_loss: 0.5098 - learning_rate: 3.0000e-04\n",
      "Epoch 304/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.7618 - val_loss: 0.5311 - learning_rate: 3.0000e-04\n",
      "Epoch 305/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.8362 - val_loss: 0.4576 - learning_rate: 3.0000e-04\n",
      "Epoch 306/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 979ms/step - loss: 0.7115 - val_loss: 0.1909 - learning_rate: 3.0000e-04\n",
      "Epoch 307/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.6563 - val_loss: 0.8865 - learning_rate: 3.0000e-04\n",
      "Epoch 308/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.6410 - val_loss: 0.2296 - learning_rate: 3.0000e-04\n",
      "Epoch 309/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 915ms/step - loss: 0.6332 - val_loss: 0.6568 - learning_rate: 3.0000e-04\n",
      "Epoch 310/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.6427 - val_loss: 0.3218 - learning_rate: 3.0000e-04\n",
      "Epoch 311/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.6874 - val_loss: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 312/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 948ms/step - loss: 0.7778 - val_loss: 0.5445 - learning_rate: 3.0000e-04\n",
      "Epoch 313/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.8173 - val_loss: 0.3713 - learning_rate: 3.0000e-04\n",
      "Epoch 314/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.7392 - val_loss: 0.2257 - learning_rate: 3.0000e-04\n",
      "Epoch 315/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 936ms/step - loss: 0.6306 - val_loss: 0.5902 - learning_rate: 3.0000e-04\n",
      "Epoch 316/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.7538 - val_loss: 2.7302 - learning_rate: 3.0000e-04\n",
      "Epoch 317/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 927ms/step - loss: 0.6837 - val_loss: 0.6457 - learning_rate: 3.0000e-04\n",
      "Epoch 318/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.8184 - val_loss: 0.7533 - learning_rate: 3.0000e-04\n",
      "Epoch 319/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - loss: 2.6209 - val_loss: 0.7913 - learning_rate: 3.0000e-04\n",
      "Epoch 320/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 2.6418 - val_loss: 5.1693 - learning_rate: 3.0000e-04\n",
      "Epoch 321/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.7314 - val_loss: 0.4205 - learning_rate: 3.0000e-04\n",
      "Epoch 322/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 929ms/step - loss: 2.4536 - val_loss: 8.0781 - learning_rate: 3.0000e-04\n",
      "Epoch 323/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 8.8171 - val_loss: 0.5229 - learning_rate: 3.0000e-04\n",
      "Epoch 324/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.7386 - val_loss: 0.5173 - learning_rate: 3.0000e-04\n",
      "Epoch 325/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 928ms/step - loss: 1.6387 - val_loss: 0.0687 - learning_rate: 3.0000e-04\n",
      "Epoch 326/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 1.5230 - val_loss: 0.3027 - learning_rate: 3.0000e-04\n",
      "Epoch 327/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 918ms/step - loss: 2.5912 - val_loss: 6.5674 - learning_rate: 3.0000e-04\n",
      "Epoch 328/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 2.8267 - val_loss: 0.1607 - learning_rate: 3.0000e-04\n",
      "Epoch 329/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 2.1312 - val_loss: 0.5153 - learning_rate: 3.0000e-04\n",
      "Epoch 330/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 919ms/step - loss: 1.5093 - val_loss: 4.8570 - learning_rate: 3.0000e-04\n",
      "Epoch 331/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 2.0632 - val_loss: 2.4731 - learning_rate: 3.0000e-04\n",
      "Epoch 332/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 1.6709 - val_loss: 1.5431 - learning_rate: 3.0000e-04\n",
      "Epoch 333/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 926ms/step - loss: 1.5667 - val_loss: 1.0983 - learning_rate: 3.0000e-04\n",
      "Epoch 334/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.5405 - val_loss: 1.4168 - learning_rate: 3.0000e-04\n",
      "Epoch 335/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 925ms/step - loss: 1.5548 - val_loss: 2.4563 - learning_rate: 3.0000e-04\n",
      "Epoch 336/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 928ms/step - loss: 1.6645 - val_loss: 0.5342 - learning_rate: 3.0000e-04\n",
      "Epoch 337/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 1.7828 - val_loss: 0.9050 - learning_rate: 3.0000e-04\n",
      "Epoch 338/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 928ms/step - loss: 1.6257 - val_loss: 3.2766 - learning_rate: 3.0000e-04\n",
      "Epoch 339/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 1.9642 - val_loss: 0.2555 - learning_rate: 3.0000e-04\n",
      "Epoch 340/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.9515 - val_loss: 2.2763 - learning_rate: 3.0000e-04\n",
      "Epoch 341/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 927ms/step - loss: 1.4421 - val_loss: 3.9005 - learning_rate: 3.0000e-04\n",
      "Epoch 342/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.5518 - val_loss: 1.7487 - learning_rate: 3.0000e-04\n",
      "Epoch 343/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.3338 - val_loss: 5.8966 - learning_rate: 3.0000e-04\n",
      "Epoch 344/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 932ms/step - loss: 2.6014 - val_loss: 3.2040 - learning_rate: 3.0000e-04\n",
      "Epoch 345/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 8.2829 - val_loss: 3.2991 - learning_rate: 3.0000e-04\n",
      "Epoch 346/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 929ms/step - loss: 5.1009 - val_loss: 5.1414 - learning_rate: 3.0000e-04\n",
      "Epoch 347/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 4.4495 - val_loss: 1.9814 - learning_rate: 3.0000e-04\n",
      "Epoch 348/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 4.1308 - val_loss: 6.1368 - learning_rate: 3.0000e-04\n",
      "Epoch 349/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 922ms/step - loss: 3.7610 - val_loss: 3.5515 - learning_rate: 3.0000e-04\n",
      "Epoch 350/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 4.5529 - val_loss: 2.8475 - learning_rate: 3.0000e-04\n",
      "Epoch 351/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 2.4514 - val_loss: 3.8311 - learning_rate: 3.0000e-04\n",
      "Epoch 352/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 922ms/step - loss: 2.0039 - val_loss: 0.3561 - learning_rate: 3.0000e-04\n",
      "Epoch 353/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 3.5566 - val_loss: 4.1443 - learning_rate: 3.0000e-04\n",
      "Epoch 354/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 4.6120 - val_loss: 1.0243 - learning_rate: 3.0000e-04\n",
      "Epoch 355/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 931ms/step - loss: 3.3702 - val_loss: 0.9511 - learning_rate: 3.0000e-04\n",
      "Epoch 356/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966ms/step - loss: 0.5563\n",
      "Epoch 356: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.5744 - val_loss: 0.1511 - learning_rate: 3.0000e-04\n",
      "Epoch 357/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 929ms/step - loss: 0.7306 - val_loss: 1.9024 - learning_rate: 1.5000e-04\n",
      "Epoch 358/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.6908 - val_loss: 0.1627 - learning_rate: 1.5000e-04\n",
      "Epoch 359/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 1.2968 - val_loss: 0.8537 - learning_rate: 1.5000e-04\n",
      "Epoch 360/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 920ms/step - loss: 0.7678 - val_loss: 0.1507 - learning_rate: 1.5000e-04\n",
      "Epoch 361/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.7195 - val_loss: 0.3528 - learning_rate: 1.5000e-04\n",
      "Epoch 362/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.6742 - val_loss: 0.8497 - learning_rate: 1.5000e-04\n",
      "Epoch 363/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 915ms/step - loss: 0.4347 - val_loss: 0.0414 - learning_rate: 1.5000e-04\n",
      "Epoch 364/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.4917 - val_loss: 1.1621 - learning_rate: 1.5000e-04\n",
      "Epoch 365/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.7483 - val_loss: 0.9967 - learning_rate: 1.5000e-04\n",
      "Epoch 366/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 938ms/step - loss: 0.7733 - val_loss: 3.2041 - learning_rate: 1.5000e-04\n",
      "Epoch 367/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.8009 - val_loss: 0.1959 - learning_rate: 1.5000e-04\n",
      "Epoch 368/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 929ms/step - loss: 0.6225 - val_loss: 0.0463 - learning_rate: 1.5000e-04\n",
      "Epoch 369/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.6420 - val_loss: 0.1874 - learning_rate: 1.5000e-04\n",
      "Epoch 370/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.7502 - val_loss: 0.0376 - learning_rate: 1.5000e-04\n",
      "Epoch 371/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 921ms/step - loss: 0.7677 - val_loss: 1.4133 - learning_rate: 1.5000e-04\n",
      "Epoch 372/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.4729 - val_loss: 3.2137 - learning_rate: 1.5000e-04\n",
      "Epoch 373/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.8161 - val_loss: 0.1460 - learning_rate: 1.5000e-04\n",
      "Epoch 374/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 922ms/step - loss: 0.6166 - val_loss: 0.0475 - learning_rate: 1.5000e-04\n",
      "Epoch 375/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.6297 - val_loss: 0.3521 - learning_rate: 1.5000e-04\n",
      "Epoch 376/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 920ms/step - loss: 0.7465 - val_loss: 0.0380 - learning_rate: 1.5000e-04\n",
      "Epoch 377/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 936ms/step - loss: 0.7897 - val_loss: 1.2764 - learning_rate: 1.5000e-04\n",
      "Epoch 378/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.2506 - val_loss: 0.0371 - learning_rate: 1.5000e-04\n",
      "Epoch 379/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 935ms/step - loss: 0.7209 - val_loss: 4.5843 - learning_rate: 1.5000e-04\n",
      "Epoch 380/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.4872 - val_loss: 0.0748 - learning_rate: 1.5000e-04\n",
      "Epoch 381/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.2378 - val_loss: 1.0858 - learning_rate: 1.5000e-04\n",
      "Epoch 382/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 923ms/step - loss: 0.9081 - val_loss: 1.0599 - learning_rate: 1.5000e-04\n",
      "Epoch 383/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.8928 - val_loss: 3.2417 - learning_rate: 1.5000e-04\n",
      "Epoch 384/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.9608 - val_loss: 0.0493 - learning_rate: 1.5000e-04\n",
      "Epoch 385/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 918ms/step - loss: 0.8572 - val_loss: 0.5316 - learning_rate: 1.5000e-04\n",
      "Epoch 386/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.8657 - val_loss: 0.6662 - learning_rate: 1.5000e-04\n",
      "Epoch 387/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 932ms/step - loss: 0.8268 - val_loss: 2.2365 - learning_rate: 1.5000e-04\n",
      "Epoch 388/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.9029 - val_loss: 0.0501 - learning_rate: 1.5000e-04\n",
      "Epoch 389/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.7823 - val_loss: 0.8610 - learning_rate: 1.5000e-04\n",
      "Epoch 390/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 935ms/step - loss: 0.8940 - val_loss: 0.3400 - learning_rate: 1.5000e-04\n",
      "Epoch 391/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.9253 - val_loss: 1.5217 - learning_rate: 1.5000e-04\n",
      "Epoch 392/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.7539 - val_loss: 0.0473 - learning_rate: 1.5000e-04\n",
      "Epoch 393/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 926ms/step - loss: 0.2947 - val_loss: 0.6175 - learning_rate: 1.5000e-04\n",
      "Epoch 394/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.3560 - val_loss: 0.8429 - learning_rate: 1.5000e-04\n",
      "Epoch 395/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.2620 - val_loss: 0.0333 - learning_rate: 1.5000e-04\n",
      "Epoch 396/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 916ms/step - loss: 0.2176 - val_loss: 0.5129 - learning_rate: 1.5000e-04\n",
      "Epoch 397/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.2059 - val_loss: 0.0321 - learning_rate: 1.5000e-04\n",
      "Epoch 398/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 933ms/step - loss: 0.2071 - val_loss: 0.2839 - learning_rate: 1.5000e-04\n",
      "Epoch 399/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.2188 - val_loss: 0.5184 - learning_rate: 1.5000e-04\n",
      "Epoch 400/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.6041 - val_loss: 2.2788 - learning_rate: 1.5000e-04\n",
      "Epoch 401/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 935ms/step - loss: 0.5613 - val_loss: 0.3637 - learning_rate: 1.5000e-04\n",
      "Epoch 402/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.6197 - val_loss: 0.3497 - learning_rate: 1.5000e-04\n",
      "Epoch 403/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.6085 - val_loss: 0.3113 - learning_rate: 1.5000e-04\n",
      "Epoch 404/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 927ms/step - loss: 0.6187 - val_loss: 0.1987 - learning_rate: 1.5000e-04\n",
      "Epoch 405/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.7774 - val_loss: 0.6092 - learning_rate: 1.5000e-04\n",
      "Epoch 406/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 940ms/step - loss: 0.7752 - val_loss: 0.2174 - learning_rate: 1.5000e-04\n",
      "Epoch 407/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 917ms/step - loss: 0.6342 - val_loss: 0.0616 - learning_rate: 1.5000e-04\n",
      "Epoch 408/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.5624 - val_loss: 0.7202 - learning_rate: 1.5000e-04\n",
      "Epoch 409/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 933ms/step - loss: 1.0193 - val_loss: 4.6428 - learning_rate: 1.5000e-04\n",
      "Epoch 410/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 1.5698 - val_loss: 0.1511 - learning_rate: 1.5000e-04\n",
      "Epoch 411/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.4147 - val_loss: 0.3446 - learning_rate: 1.5000e-04\n",
      "Epoch 412/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 927ms/step - loss: 0.3458 - val_loss: 0.8647 - learning_rate: 1.5000e-04\n",
      "Epoch 413/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 1.1438 - val_loss: 1.1310 - learning_rate: 1.5000e-04\n",
      "Epoch 414/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.2787 - val_loss: 0.0263 - learning_rate: 1.5000e-04\n",
      "Epoch 415/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 932ms/step - loss: 0.2084 - val_loss: 0.1054 - learning_rate: 1.5000e-04\n",
      "Epoch 416/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.2641 - val_loss: 1.1557 - learning_rate: 1.5000e-04\n",
      "Epoch 417/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 913ms/step - loss: 0.5874 - val_loss: 0.1162 - learning_rate: 1.5000e-04\n",
      "Epoch 418/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.6253 - val_loss: 0.1738 - learning_rate: 1.5000e-04\n",
      "Epoch 419/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.6515 - val_loss: 0.5805 - learning_rate: 1.5000e-04\n",
      "Epoch 420/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 904ms/step - loss: 1.0755 - val_loss: 0.0399 - learning_rate: 1.5000e-04\n",
      "Epoch 421/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.9044 - val_loss: 4.2812 - learning_rate: 1.5000e-04\n",
      "Epoch 422/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 1.0985 - val_loss: 0.0363 - learning_rate: 1.5000e-04\n",
      "Epoch 423/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 903ms/step - loss: 0.5565 - val_loss: 0.6636 - learning_rate: 1.5000e-04\n",
      "Epoch 424/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.5548 - val_loss: 0.1273 - learning_rate: 1.5000e-04\n",
      "Epoch 425/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.5878 - val_loss: 0.7563 - learning_rate: 1.5000e-04\n",
      "Epoch 426/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 913ms/step - loss: 0.6385 - val_loss: 0.0661 - learning_rate: 1.5000e-04\n",
      "Epoch 427/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - loss: 0.4336 - val_loss: 0.1843 - learning_rate: 1.5000e-04\n",
      "Epoch 428/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.2173 - val_loss: 0.2602 - learning_rate: 1.5000e-04\n",
      "Epoch 429/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1937 - val_loss: 0.0627 - learning_rate: 1.5000e-04\n",
      "Epoch 430/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 909ms/step - loss: 0.1561 - val_loss: 0.7959 - learning_rate: 1.5000e-04\n",
      "Epoch 431/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1756 - val_loss: 0.1550 - learning_rate: 1.5000e-04\n",
      "Epoch 432/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1784 - val_loss: 0.4518 - learning_rate: 1.5000e-04\n",
      "Epoch 433/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 928ms/step - loss: 0.3717 - val_loss: 1.5376 - learning_rate: 1.5000e-04\n",
      "Epoch 434/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.5436 - val_loss: 0.0633 - learning_rate: 1.5000e-04\n",
      "Epoch 435/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 921ms/step - loss: 0.2977 - val_loss: 0.6176 - learning_rate: 1.5000e-04\n",
      "Epoch 436/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.3549 - val_loss: 0.2568 - learning_rate: 1.5000e-04\n",
      "Epoch 437/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.4211 - val_loss: 0.1266 - learning_rate: 1.5000e-04\n",
      "Epoch 438/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 926ms/step - loss: 1.4136 - val_loss: 1.6515 - learning_rate: 1.5000e-04\n",
      "Epoch 439/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 1.4303 - val_loss: 0.0823 - learning_rate: 1.5000e-04\n",
      "Epoch 440/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.3857 - val_loss: 0.6783 - learning_rate: 1.5000e-04\n",
      "Epoch 441/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 929ms/step - loss: 0.3974 - val_loss: 0.1723 - learning_rate: 1.5000e-04\n",
      "Epoch 442/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 1.5665 - val_loss: 0.0812 - learning_rate: 1.5000e-04\n",
      "Epoch 443/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 926ms/step - loss: 1.6449 - val_loss: 0.3155 - learning_rate: 1.5000e-04\n",
      "Epoch 444/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 926ms/step - loss: 0.6692 - val_loss: 1.4986 - learning_rate: 1.5000e-04\n",
      "Epoch 445/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.7355 - val_loss: 0.0323 - learning_rate: 1.5000e-04\n",
      "Epoch 446/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 919ms/step - loss: 0.5618 - val_loss: 0.3741 - learning_rate: 1.5000e-04\n",
      "Epoch 447/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.5201 - val_loss: 0.7601 - learning_rate: 1.5000e-04\n",
      "Epoch 448/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.5998 - val_loss: 0.3876 - learning_rate: 1.5000e-04\n",
      "Epoch 449/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 918ms/step - loss: 0.6599 - val_loss: 2.9154 - learning_rate: 1.5000e-04\n",
      "Epoch 450/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.6201 - val_loss: 0.0380 - learning_rate: 1.5000e-04\n",
      "Epoch 451/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1644 - val_loss: 0.4404 - learning_rate: 1.5000e-04\n",
      "Epoch 452/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 927ms/step - loss: 0.4616 - val_loss: 1.0176 - learning_rate: 1.5000e-04\n",
      "Epoch 453/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 1.0607 - val_loss: 0.1096 - learning_rate: 1.5000e-04\n",
      "Epoch 454/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 926ms/step - loss: 0.8503 - val_loss: 0.0947 - learning_rate: 1.5000e-04\n",
      "Epoch 455/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.6391 - val_loss: 3.5324 - learning_rate: 1.5000e-04\n",
      "Epoch 456/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.9495 - val_loss: 0.2261 - learning_rate: 1.5000e-04\n",
      "Epoch 457/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 946ms/step - loss: 0.8935 - val_loss: 0.3156 - learning_rate: 1.5000e-04\n",
      "Epoch 458/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.8546 - val_loss: 0.9320 - learning_rate: 1.5000e-04\n",
      "Epoch 459/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.7125 - val_loss: 2.6237 - learning_rate: 1.5000e-04\n",
      "Epoch 460/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 937ms/step - loss: 0.7795 - val_loss: 0.0349 - learning_rate: 1.5000e-04\n",
      "Epoch 461/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.7064 - val_loss: 0.4537 - learning_rate: 1.5000e-04\n",
      "Epoch 462/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.7509 - val_loss: 0.5777 - learning_rate: 1.5000e-04\n",
      "Epoch 463/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 922ms/step - loss: 0.7045 - val_loss: 1.9650 - learning_rate: 1.5000e-04\n",
      "Epoch 464/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.7915 - val_loss: 0.0338 - learning_rate: 1.5000e-04\n",
      "Epoch 465/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 929ms/step - loss: 0.6784 - val_loss: 0.6986 - learning_rate: 1.5000e-04\n",
      "Epoch 466/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.7762 - val_loss: 0.3534 - learning_rate: 1.5000e-04\n",
      "Epoch 467/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.7963 - val_loss: 1.4688 - learning_rate: 1.5000e-04\n",
      "Epoch 468/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 930ms/step - loss: 0.6615 - val_loss: 0.0233 - learning_rate: 1.5000e-04\n",
      "Epoch 469/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.5555 - val_loss: 1.6741 - learning_rate: 1.5000e-04\n",
      "Epoch 470/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.5378 - val_loss: 0.6039 - learning_rate: 1.5000e-04\n",
      "Epoch 471/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 925ms/step - loss: 0.9680 - val_loss: 1.0366 - learning_rate: 1.5000e-04\n",
      "Epoch 472/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.8756 - val_loss: 0.3897 - learning_rate: 1.5000e-04\n",
      "Epoch 473/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.2065 - val_loss: 0.8871 - learning_rate: 1.5000e-04\n",
      "Epoch 474/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 921ms/step - loss: 0.2157 - val_loss: 0.3373 - learning_rate: 1.5000e-04\n",
      "Epoch 475/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.7628 - val_loss: 0.2695 - learning_rate: 1.5000e-04\n",
      "Epoch 476/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 931ms/step - loss: 0.8131 - val_loss: 1.0872 - learning_rate: 1.5000e-04\n",
      "Epoch 477/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.6900 - val_loss: 2.7436 - learning_rate: 1.5000e-04\n",
      "Epoch 478/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.7686 - val_loss: 0.0380 - learning_rate: 1.5000e-04\n",
      "Epoch 479/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 932ms/step - loss: 0.6772 - val_loss: 0.4137 - learning_rate: 1.5000e-04\n",
      "Epoch 480/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.7349 - val_loss: 0.5852 - learning_rate: 1.5000e-04\n",
      "Epoch 481/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.6970 - val_loss: 1.9137 - learning_rate: 1.5000e-04\n",
      "Epoch 482/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 923ms/step - loss: 0.7870 - val_loss: 0.0342 - learning_rate: 1.5000e-04\n",
      "Epoch 483/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.6950 - val_loss: 0.7783 - learning_rate: 1.5000e-04\n",
      "Epoch 484/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.5844 - val_loss: 0.0448 - learning_rate: 1.5000e-04\n",
      "Epoch 485/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 936ms/step - loss: 0.1654 - val_loss: 0.4465 - learning_rate: 1.5000e-04\n",
      "Epoch 486/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.4648 - val_loss: 0.0891 - learning_rate: 1.5000e-04\n",
      "Epoch 487/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 930ms/step - loss: 0.2051 - val_loss: 0.2316 - learning_rate: 1.5000e-04\n",
      "Epoch 488/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.4940 - val_loss: 0.7011 - learning_rate: 1.5000e-04\n",
      "Epoch 489/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.2857 - val_loss: 1.5337 - learning_rate: 1.5000e-04\n",
      "Epoch 490/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 922ms/step - loss: 0.4731 - val_loss: 0.5209 - learning_rate: 1.5000e-04\n",
      "Epoch 491/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.3533 - val_loss: 0.0278 - learning_rate: 1.5000e-04\n",
      "Epoch 492/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.3899 - val_loss: 1.0782 - learning_rate: 1.5000e-04\n",
      "Epoch 493/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 918ms/step - loss: 0.4184 - val_loss: 0.7421 - learning_rate: 1.5000e-04\n",
      "Epoch 494/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.3033 - val_loss: 0.3236 - learning_rate: 1.5000e-04\n",
      "Epoch 495/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 938ms/step - loss: 0.3823 - val_loss: 0.3344 - learning_rate: 1.5000e-04\n",
      "Epoch 496/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 930ms/step - loss: 0.2976 - val_loss: 0.1364 - learning_rate: 1.5000e-04\n",
      "Epoch 497/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.2519 - val_loss: 0.0743 - learning_rate: 1.5000e-04\n",
      "Epoch 498/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 930ms/step - loss: 0.2497 - val_loss: 1.3025 - learning_rate: 1.5000e-04\n",
      "Epoch 499/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.2970 - val_loss: 0.6492 - learning_rate: 1.5000e-04\n",
      "Epoch 500/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.2878 - val_loss: 0.5013 - learning_rate: 1.5000e-04\n",
      "Epoch 501/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 929ms/step - loss: 0.2906 - val_loss: 0.2314 - learning_rate: 1.5000e-04\n",
      "Epoch 502/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.7558 - val_loss: 0.1819 - learning_rate: 1.5000e-04\n",
      "Epoch 503/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.6619 - val_loss: 0.0634 - learning_rate: 1.5000e-04\n",
      "Epoch 504/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 929ms/step - loss: 0.5624 - val_loss: 0.1014 - learning_rate: 1.5000e-04\n",
      "Epoch 505/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.5324 - val_loss: 0.3949 - learning_rate: 1.5000e-04\n",
      "Epoch 506/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 942ms/step - loss: 0.3921 - val_loss: 0.6536 - learning_rate: 1.5000e-04\n",
      "Epoch 507/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1484 - val_loss: 0.0604 - learning_rate: 1.5000e-04\n",
      "Epoch 508/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1443 - val_loss: 0.5202 - learning_rate: 1.5000e-04\n",
      "Epoch 509/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 915ms/step - loss: 0.1409 - val_loss: 0.0748 - learning_rate: 1.5000e-04\n",
      "Epoch 510/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1402 - val_loss: 0.5180 - learning_rate: 1.5000e-04\n",
      "Epoch 511/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1386 - val_loss: 0.0792 - learning_rate: 1.5000e-04\n",
      "Epoch 512/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 911ms/step - loss: 0.1184 - val_loss: 0.5009 - learning_rate: 1.5000e-04\n",
      "Epoch 513/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1165 - val_loss: 0.0605 - learning_rate: 1.5000e-04\n",
      "Epoch 514/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1095 - val_loss: 0.4476 - learning_rate: 1.5000e-04\n",
      "Epoch 515/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 927ms/step - loss: 0.1083 - val_loss: 0.0477 - learning_rate: 1.5000e-04\n",
      "Epoch 516/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1194 - val_loss: 0.3976 - learning_rate: 1.5000e-04\n",
      "Epoch 517/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 935ms/step - loss: 0.1228 - val_loss: 0.0353 - learning_rate: 1.5000e-04\n",
      "Epoch 518/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1236 - val_loss: 0.3450 - learning_rate: 1.5000e-04\n",
      "Epoch 519/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1223 - val_loss: 0.0309 - learning_rate: 1.5000e-04\n",
      "Epoch 520/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 912ms/step - loss: 0.1249 - val_loss: 0.3376 - learning_rate: 1.5000e-04\n",
      "Epoch 521/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - loss: 0.1227 - val_loss: 0.0341 - learning_rate: 1.5000e-04\n",
      "Epoch 522/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 899ms/step - loss: 0.1148 - val_loss: 0.3109 - learning_rate: 1.5000e-04\n",
      "Epoch 523/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1173 - val_loss: 0.0244 - learning_rate: 1.5000e-04\n",
      "Epoch 524/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1251 - val_loss: 0.3084 - learning_rate: 1.5000e-04\n",
      "Epoch 525/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 947ms/step - loss: 0.1285 - val_loss: 0.0209 - learning_rate: 1.5000e-04\n",
      "Epoch 526/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1325 - val_loss: 0.2691 - learning_rate: 1.5000e-04\n",
      "Epoch 527/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 933ms/step - loss: 0.1342 - val_loss: 0.0215 - learning_rate: 1.5000e-04\n",
      "Epoch 528/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1365 - val_loss: 0.2931 - learning_rate: 1.5000e-04\n",
      "Epoch 529/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1403 - val_loss: 0.0275 - learning_rate: 1.5000e-04\n",
      "Epoch 530/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 930ms/step - loss: 0.1224 - val_loss: 0.3621 - learning_rate: 1.5000e-04\n",
      "Epoch 531/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1221 - val_loss: 0.0300 - learning_rate: 1.5000e-04\n",
      "Epoch 532/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1213 - val_loss: 0.3577 - learning_rate: 1.5000e-04\n",
      "Epoch 533/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 924ms/step - loss: 0.1205 - val_loss: 0.0347 - learning_rate: 1.5000e-04\n",
      "Epoch 534/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1157 - val_loss: 0.3242 - learning_rate: 1.5000e-04\n",
      "Epoch 535/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1252 - val_loss: 0.0261 - learning_rate: 1.5000e-04\n",
      "Epoch 536/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 933ms/step - loss: 0.1301 - val_loss: 0.2890 - learning_rate: 1.5000e-04\n",
      "Epoch 537/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1290 - val_loss: 0.0218 - learning_rate: 1.5000e-04\n",
      "Epoch 538/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 957ms/step - loss: 0.1207 - val_loss: 0.4038 - learning_rate: 1.5000e-04\n",
      "Epoch 539/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1317 - val_loss: 0.0478 - learning_rate: 1.5000e-04\n",
      "Epoch 540/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1330 - val_loss: 0.4603 - learning_rate: 1.5000e-04\n",
      "Epoch 541/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 955ms/step - loss: 0.1155 - val_loss: 0.0577 - learning_rate: 1.5000e-04\n",
      "Epoch 542/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1217 - val_loss: 0.4420 - learning_rate: 1.5000e-04\n",
      "Epoch 543/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1082 - val_loss: 0.0493 - learning_rate: 1.5000e-04\n",
      "Epoch 544/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 952ms/step - loss: 0.1105 - val_loss: 0.4411 - learning_rate: 1.5000e-04\n",
      "Epoch 545/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1091 - val_loss: 0.0427 - learning_rate: 1.5000e-04\n",
      "Epoch 546/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1064 - val_loss: 0.3779 - learning_rate: 1.5000e-04\n",
      "Epoch 547/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 931ms/step - loss: 0.1214 - val_loss: 0.0337 - learning_rate: 1.5000e-04\n",
      "Epoch 548/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.1160 - val_loss: 0.3616 - learning_rate: 1.5000e-04\n",
      "Epoch 549/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1230 - val_loss: 0.0284 - learning_rate: 1.5000e-04\n",
      "Epoch 550/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 946ms/step - loss: 0.1250 - val_loss: 0.3251 - learning_rate: 1.5000e-04\n",
      "Epoch 551/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1304 - val_loss: 0.0260 - learning_rate: 1.5000e-04\n",
      "Epoch 552/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1155 - val_loss: 0.2891 - learning_rate: 1.5000e-04\n",
      "Epoch 553/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 935ms/step - loss: 0.1272 - val_loss: 0.0211 - learning_rate: 1.5000e-04\n",
      "Epoch 554/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1312 - val_loss: 0.2691 - learning_rate: 1.5000e-04\n",
      "Epoch 555/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 945ms/step - loss: 0.1303 - val_loss: 0.0209 - learning_rate: 1.5000e-04\n",
      "Epoch 556/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1208 - val_loss: 0.2449 - learning_rate: 1.5000e-04\n",
      "Epoch 557/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1336 - val_loss: 0.0220 - learning_rate: 1.5000e-04\n",
      "Epoch 558/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 938ms/step - loss: 0.1304 - val_loss: 0.2459 - learning_rate: 1.5000e-04\n",
      "Epoch 559/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1212 - val_loss: 0.0228 - learning_rate: 1.5000e-04\n",
      "Epoch 560/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1300 - val_loss: 0.2704 - learning_rate: 1.5000e-04\n",
      "Epoch 561/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 933ms/step - loss: 0.1208 - val_loss: 0.0184 - learning_rate: 1.5000e-04\n",
      "Epoch 562/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1296 - val_loss: 0.2725 - learning_rate: 1.5000e-04\n",
      "Epoch 563/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1189 - val_loss: 0.0196 - learning_rate: 1.5000e-04\n",
      "Epoch 564/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 930ms/step - loss: 0.1386 - val_loss: 0.2507 - learning_rate: 1.5000e-04\n",
      "Epoch 565/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1411 - val_loss: 0.0205 - learning_rate: 1.5000e-04\n",
      "Epoch 566/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1267 - val_loss: 0.2905 - learning_rate: 1.5000e-04\n",
      "Epoch 567/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 923ms/step - loss: 0.1144 - val_loss: 0.0265 - learning_rate: 1.5000e-04\n",
      "Epoch 568/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1115 - val_loss: 0.3237 - learning_rate: 1.5000e-04\n",
      "Epoch 569/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 956ms/step - loss: 0.1151 - val_loss: 0.0261 - learning_rate: 1.5000e-04\n",
      "Epoch 570/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 928ms/step - loss: 0.1173 - val_loss: 0.3284 - learning_rate: 1.5000e-04\n",
      "Epoch 571/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1170 - val_loss: 0.0234 - learning_rate: 1.5000e-04\n",
      "Epoch 572/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 949ms/step - loss: 0.1100 - val_loss: 0.3093 - learning_rate: 1.5000e-04\n",
      "Epoch 573/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1182 - val_loss: 0.0210 - learning_rate: 1.5000e-04\n",
      "Epoch 574/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.1121 - val_loss: 0.2805 - learning_rate: 1.5000e-04\n",
      "Epoch 575/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 963ms/step - loss: 0.1198 - val_loss: 0.0205 - learning_rate: 1.5000e-04\n",
      "Epoch 576/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.1222 - val_loss: 0.2837 - learning_rate: 1.5000e-04\n",
      "Epoch 577/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.1221 - val_loss: 0.0211 - learning_rate: 1.5000e-04\n",
      "Epoch 578/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 996ms/step - loss: 0.1217 - val_loss: 0.2551 - learning_rate: 1.5000e-04\n",
      "Epoch 579/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.1344 - val_loss: 0.0199 - learning_rate: 1.5000e-04\n",
      "Epoch 580/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1250 - val_loss: 0.2636 - learning_rate: 1.5000e-04\n",
      "Epoch 581/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 957ms/step - loss: 0.1274 - val_loss: 0.0212 - learning_rate: 1.5000e-04\n",
      "Epoch 582/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1196 - val_loss: 0.2520 - learning_rate: 1.5000e-04\n",
      "Epoch 583/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1314 - val_loss: 0.0174 - learning_rate: 1.5000e-04\n",
      "Epoch 584/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 938ms/step - loss: 0.1479 - val_loss: 0.3356 - learning_rate: 1.5000e-04\n",
      "Epoch 585/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1425 - val_loss: 0.0566 - learning_rate: 1.5000e-04\n",
      "Epoch 586/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1168 - val_loss: 0.4669 - learning_rate: 1.5000e-04\n",
      "Epoch 587/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 932ms/step - loss: 0.1154 - val_loss: 0.0543 - learning_rate: 1.5000e-04\n",
      "Epoch 588/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1151 - val_loss: 0.4097 - learning_rate: 1.5000e-04\n",
      "Epoch 589/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 958ms/step - loss: 0.0933 - val_loss: 0.0397 - learning_rate: 1.5000e-04\n",
      "Epoch 590/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 949ms/step - loss: 0.1115 - val_loss: 0.4391 - learning_rate: 1.5000e-04\n",
      "Epoch 591/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6526s\u001b[0m 311s/step - loss: 0.1021 - val_loss: 0.0518 - learning_rate: 1.5000e-04\n",
      "Epoch 592/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 0.1060 - val_loss: 0.4163 - learning_rate: 1.5000e-04\n",
      "Epoch 593/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.1144 - val_loss: 0.0384 - learning_rate: 1.5000e-04\n",
      "Epoch 594/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 954ms/step - loss: 0.0974 - val_loss: 0.3761 - learning_rate: 1.5000e-04\n",
      "Epoch 595/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0972 - val_loss: 0.0352 - learning_rate: 1.5000e-04\n",
      "Epoch 596/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1084 - val_loss: 0.3650 - learning_rate: 1.5000e-04\n",
      "Epoch 597/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 923ms/step - loss: 0.1096 - val_loss: 0.0315 - learning_rate: 1.5000e-04\n",
      "Epoch 598/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.1141 - val_loss: 0.3440 - learning_rate: 1.5000e-04\n",
      "Epoch 599/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 0.1158 - val_loss: 0.0206 - learning_rate: 1.5000e-04\n",
      "Epoch 600/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 981ms/step - loss: 0.1218 - val_loss: 0.2636 - learning_rate: 1.5000e-04\n",
      "Epoch 601/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1199 - val_loss: 0.0181 - learning_rate: 1.5000e-04\n",
      "Epoch 602/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1325 - val_loss: 0.2167 - learning_rate: 1.5000e-04\n",
      "Epoch 603/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 942ms/step - loss: 0.1116 - val_loss: 0.0286 - learning_rate: 1.5000e-04\n",
      "Epoch 604/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0994 - val_loss: 0.3145 - learning_rate: 1.5000e-04\n",
      "Epoch 605/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1123 - val_loss: 0.0226 - learning_rate: 1.5000e-04\n",
      "Epoch 606/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 935ms/step - loss: 0.1136 - val_loss: 0.2680 - learning_rate: 1.5000e-04\n",
      "Epoch 607/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1045 - val_loss: 0.0202 - learning_rate: 1.5000e-04\n",
      "Epoch 608/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 929ms/step - loss: 0.1150 - val_loss: 0.2748 - learning_rate: 1.5000e-04\n",
      "Epoch 609/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1113 - val_loss: 0.0194 - learning_rate: 1.5000e-04\n",
      "Epoch 610/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1154 - val_loss: 0.2504 - learning_rate: 1.5000e-04\n",
      "Epoch 611/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 923ms/step - loss: 0.1269 - val_loss: 0.0196 - learning_rate: 1.5000e-04\n",
      "Epoch 612/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1180 - val_loss: 0.2781 - learning_rate: 1.5000e-04\n",
      "Epoch 613/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1273 - val_loss: 0.0169 - learning_rate: 1.5000e-04\n",
      "Epoch 614/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 930ms/step - loss: 0.1202 - val_loss: 0.2295 - learning_rate: 1.5000e-04\n",
      "Epoch 615/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1233 - val_loss: 0.0170 - learning_rate: 1.5000e-04\n",
      "Epoch 616/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 922ms/step - loss: 0.1138 - val_loss: 0.2550 - learning_rate: 1.5000e-04\n",
      "Epoch 617/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - loss: 0.1134 - val_loss: 0.0192 - learning_rate: 1.5000e-04\n",
      "Epoch 618/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1109 - val_loss: 0.2791 - learning_rate: 1.5000e-04\n",
      "Epoch 619/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1240 - val_loss: 0.0186 - learning_rate: 1.5000e-04\n",
      "Epoch 620/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 927ms/step - loss: 0.1205 - val_loss: 0.2572 - learning_rate: 1.5000e-04\n",
      "Epoch 621/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1194 - val_loss: 0.0193 - learning_rate: 1.5000e-04\n",
      "Epoch 622/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1169 - val_loss: 0.5448 - learning_rate: 1.5000e-04\n",
      "Epoch 623/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 925ms/step - loss: 0.1467 - val_loss: 0.1321 - learning_rate: 1.5000e-04\n",
      "Epoch 624/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1310 - val_loss: 0.0839 - learning_rate: 1.5000e-04\n",
      "Epoch 625/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 920ms/step - loss: 0.1164 - val_loss: 0.6979 - learning_rate: 1.5000e-04\n",
      "Epoch 626/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1184 - val_loss: 0.0853 - learning_rate: 1.5000e-04\n",
      "Epoch 627/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0995 - val_loss: 0.5099 - learning_rate: 1.5000e-04\n",
      "Epoch 628/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 946ms/step - loss: 0.0955 - val_loss: 0.0593 - learning_rate: 1.5000e-04\n",
      "Epoch 629/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0990 - val_loss: 0.4269 - learning_rate: 1.5000e-04\n",
      "Epoch 630/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0989 - val_loss: 0.0456 - learning_rate: 1.5000e-04\n",
      "Epoch 631/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 933ms/step - loss: 0.0944 - val_loss: 0.3579 - learning_rate: 1.5000e-04\n",
      "Epoch 632/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1074 - val_loss: 0.0293 - learning_rate: 1.5000e-04\n",
      "Epoch 633/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0982 - val_loss: 0.3097 - learning_rate: 1.5000e-04\n",
      "Epoch 634/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 947ms/step - loss: 0.1053 - val_loss: 0.0169 - learning_rate: 1.5000e-04\n",
      "Epoch 635/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1079 - val_loss: 0.2869 - learning_rate: 1.5000e-04\n",
      "Epoch 636/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 932ms/step - loss: 0.1113 - val_loss: 0.0185 - learning_rate: 1.5000e-04\n",
      "Epoch 637/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1107 - val_loss: 0.2657 - learning_rate: 1.5000e-04\n",
      "Epoch 638/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1091 - val_loss: 0.0188 - learning_rate: 1.5000e-04\n",
      "Epoch 639/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 928ms/step - loss: 0.1213 - val_loss: 0.1909 - learning_rate: 1.5000e-04\n",
      "Epoch 640/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.4356 - val_loss: 1.5309 - learning_rate: 1.5000e-04\n",
      "Epoch 641/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.4009 - val_loss: 0.3382 - learning_rate: 1.5000e-04\n",
      "Epoch 642/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 917ms/step - loss: 0.6763 - val_loss: 0.1725 - learning_rate: 1.5000e-04\n",
      "Epoch 643/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.4415 - val_loss: 0.2325 - learning_rate: 1.5000e-04\n",
      "Epoch 644/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.2125 - val_loss: 0.1208 - learning_rate: 1.5000e-04\n",
      "Epoch 645/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 921ms/step - loss: 0.1758 - val_loss: 0.0568 - learning_rate: 1.5000e-04\n",
      "Epoch 646/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1436 - val_loss: 0.1300 - learning_rate: 1.5000e-04\n",
      "Epoch 647/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 927ms/step - loss: 0.4401 - val_loss: 0.0538 - learning_rate: 1.5000e-04\n",
      "Epoch 648/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.6430 - val_loss: 0.0221 - learning_rate: 1.5000e-04\n",
      "Epoch 649/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1434 - val_loss: 0.5631 - learning_rate: 1.5000e-04\n",
      "Epoch 650/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 920ms/step - loss: 0.7064 - val_loss: 0.1368 - learning_rate: 1.5000e-04\n",
      "Epoch 651/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.4812 - val_loss: 0.0522 - learning_rate: 1.5000e-04\n",
      "Epoch 652/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.1458 - val_loss: 0.0592 - learning_rate: 1.5000e-04\n",
      "Epoch 653/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - loss: 0.6919 - val_loss: 0.0807 - learning_rate: 1.5000e-04\n",
      "Epoch 654/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.4077 - val_loss: 0.0135 - learning_rate: 1.5000e-04\n",
      "Epoch 655/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 939ms/step - loss: 0.4006 - val_loss: 0.1399 - learning_rate: 1.5000e-04\n",
      "Epoch 656/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.3935 - val_loss: 0.1645 - learning_rate: 1.5000e-04\n",
      "Epoch 657/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 941ms/step - loss: 0.5100 - val_loss: 1.2462 - learning_rate: 1.5000e-04\n",
      "Epoch 658/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.5559 - val_loss: 0.0608 - learning_rate: 1.5000e-04\n",
      "Epoch 659/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.3920 - val_loss: 0.3760 - learning_rate: 1.5000e-04\n",
      "Epoch 660/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 938ms/step - loss: 0.3233 - val_loss: 2.1108 - learning_rate: 1.5000e-04\n",
      "Epoch 661/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.7455 - val_loss: 1.6519 - learning_rate: 1.5000e-04\n",
      "Epoch 662/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.7457 - val_loss: 0.0984 - learning_rate: 1.5000e-04\n",
      "Epoch 663/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 933ms/step - loss: 0.6186 - val_loss: 0.0258 - learning_rate: 1.5000e-04\n",
      "Epoch 664/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.5751 - val_loss: 1.5455 - learning_rate: 1.5000e-04\n",
      "Epoch 665/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.5503 - val_loss: 0.7676 - learning_rate: 1.5000e-04\n",
      "Epoch 666/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 931ms/step - loss: 0.5729 - val_loss: 0.4045 - learning_rate: 1.5000e-04\n",
      "Epoch 667/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.5409 - val_loss: 0.1731 - learning_rate: 1.5000e-04\n",
      "Epoch 668/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 926ms/step - loss: 0.6592 - val_loss: 0.9526 - learning_rate: 1.5000e-04\n",
      "Epoch 669/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.5287 - val_loss: 0.0328 - learning_rate: 1.5000e-04\n",
      "Epoch 670/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.3990 - val_loss: 0.1849 - learning_rate: 1.5000e-04\n",
      "Epoch 671/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 932ms/step - loss: 0.5168 - val_loss: 0.2723 - learning_rate: 1.5000e-04\n",
      "Epoch 672/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.2417 - val_loss: 0.1688 - learning_rate: 1.5000e-04\n",
      "Epoch 673/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.3226 - val_loss: 0.3649 - learning_rate: 1.5000e-04\n",
      "Epoch 674/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 937ms/step - loss: 0.4455 - val_loss: 1.2723 - learning_rate: 1.5000e-04\n",
      "Epoch 675/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.3843 - val_loss: 0.0209 - learning_rate: 1.5000e-04\n",
      "Epoch 676/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 927ms/step - loss: 0.1883 - val_loss: 1.6048 - learning_rate: 1.5000e-04\n",
      "Epoch 677/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 933ms/step - loss: 0.4830 - val_loss: 0.7117 - learning_rate: 1.5000e-04\n",
      "Epoch 678/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.2915 - val_loss: 0.2100 - learning_rate: 1.5000e-04\n",
      "Epoch 679/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 927ms/step - loss: 0.5624 - val_loss: 0.4258 - learning_rate: 1.5000e-04\n",
      "Epoch 680/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.3852 - val_loss: 0.0367 - learning_rate: 1.5000e-04\n",
      "Epoch 681/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.3772 - val_loss: 0.3611 - learning_rate: 1.5000e-04\n",
      "Epoch 682/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 930ms/step - loss: 0.4151 - val_loss: 0.2145 - learning_rate: 1.5000e-04\n",
      "Epoch 683/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.4115 - val_loss: 1.0830 - learning_rate: 1.5000e-04\n",
      "Epoch 684/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.4299 - val_loss: 1.3830 - learning_rate: 1.5000e-04\n",
      "Epoch 685/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 933ms/step - loss: 0.5602 - val_loss: 1.1129 - learning_rate: 1.5000e-04\n",
      "Epoch 686/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.5414 - val_loss: 0.7061 - learning_rate: 1.5000e-04\n",
      "Epoch 687/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 928ms/step - loss: 0.2335 - val_loss: 0.1365 - learning_rate: 1.5000e-04\n",
      "Epoch 688/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.3957 - val_loss: 0.4513 - learning_rate: 1.5000e-04\n",
      "Epoch 689/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.4959 - val_loss: 0.3068 - learning_rate: 1.5000e-04\n",
      "Epoch 690/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 930ms/step - loss: 0.1213 - val_loss: 0.0170 - learning_rate: 1.5000e-04\n",
      "Epoch 691/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1074 - val_loss: 0.1896 - learning_rate: 1.5000e-04\n",
      "Epoch 692/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1119 - val_loss: 0.0133 - learning_rate: 1.5000e-04\n",
      "Epoch 693/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 931ms/step - loss: 0.1060 - val_loss: 0.2239 - learning_rate: 1.5000e-04\n",
      "Epoch 694/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.2124 - val_loss: 2.1938 - learning_rate: 1.5000e-04\n",
      "Epoch 695/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.5656 - val_loss: 0.5557 - learning_rate: 1.5000e-04\n",
      "Epoch 696/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 932ms/step - loss: 0.5656 - val_loss: 0.4989 - learning_rate: 1.5000e-04\n",
      "Epoch 697/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.5408 - val_loss: 0.1464 - learning_rate: 1.5000e-04\n",
      "Epoch 698/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 930ms/step - loss: 0.5928 - val_loss: 0.9812 - learning_rate: 1.5000e-04\n",
      "Epoch 699/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.6168 - val_loss: 0.4341 - learning_rate: 1.5000e-04\n",
      "Epoch 700/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.3211 - val_loss: 0.1790 - learning_rate: 1.5000e-04\n",
      "Epoch 701/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 928ms/step - loss: 0.1147 - val_loss: 0.3168 - learning_rate: 1.5000e-04\n",
      "Epoch 702/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1428 - val_loss: 0.1990 - learning_rate: 1.5000e-04\n",
      "Epoch 703/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.4791 - val_loss: 0.4916 - learning_rate: 1.5000e-04\n",
      "Epoch 704/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 929ms/step - loss: 0.4454 - val_loss: 0.5991 - learning_rate: 1.5000e-04\n",
      "Epoch 705/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.3983 - val_loss: 0.1339 - learning_rate: 1.5000e-04\n",
      "Epoch 706/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.6500 - val_loss: 0.0362 - learning_rate: 1.5000e-04\n",
      "Epoch 707/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 932ms/step - loss: 0.5597 - val_loss: 1.9221 - learning_rate: 1.5000e-04\n",
      "Epoch 708/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.5129 - val_loss: 1.0588 - learning_rate: 1.5000e-04\n",
      "Epoch 709/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 929ms/step - loss: 0.5181 - val_loss: 0.2057 - learning_rate: 1.5000e-04\n",
      "Epoch 710/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.4772 - val_loss: 0.0675 - learning_rate: 1.5000e-04\n",
      "Epoch 711/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.5287 - val_loss: 1.1774 - learning_rate: 1.5000e-04\n",
      "Epoch 712/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 920ms/step - loss: 0.5474 - val_loss: 0.5530 - learning_rate: 1.5000e-04\n",
      "Epoch 713/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.5393 - val_loss: 0.4613 - learning_rate: 1.5000e-04\n",
      "Epoch 714/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.5455 - val_loss: 0.2024 - learning_rate: 1.5000e-04\n",
      "Epoch 715/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 926ms/step - loss: 0.6253 - val_loss: 0.8413 - learning_rate: 1.5000e-04\n",
      "Epoch 716/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1090 - val_loss: 0.4611 - learning_rate: 1.5000e-04\n",
      "Epoch 717/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 920ms/step - loss: 0.3775 - val_loss: 0.0681 - learning_rate: 1.5000e-04\n",
      "Epoch 718/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 938ms/step - loss: 0.3198 - val_loss: 0.1409 - learning_rate: 1.5000e-04\n",
      "Epoch 719/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.2520 - val_loss: 0.5861 - learning_rate: 1.5000e-04\n",
      "Epoch 720/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 913ms/step - loss: 0.1543 - val_loss: 0.6514 - learning_rate: 1.5000e-04\n",
      "Epoch 721/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1521 - val_loss: 0.4568 - learning_rate: 1.5000e-04\n",
      "Epoch 722/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1230 - val_loss: 0.6147 - learning_rate: 1.5000e-04\n",
      "Epoch 723/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 916ms/step - loss: 0.5108 - val_loss: 0.8037 - learning_rate: 1.5000e-04\n",
      "Epoch 724/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.4878 - val_loss: 0.0243 - learning_rate: 1.5000e-04\n",
      "Epoch 725/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1110 - val_loss: 0.3716 - learning_rate: 1.5000e-04\n",
      "Epoch 726/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 921ms/step - loss: 0.1076 - val_loss: 0.0245 - learning_rate: 1.5000e-04\n",
      "Epoch 727/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0924 - val_loss: 0.4251 - learning_rate: 1.5000e-04\n",
      "Epoch 728/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 922ms/step - loss: 0.0876 - val_loss: 0.0585 - learning_rate: 1.5000e-04\n",
      "Epoch 729/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0888 - val_loss: 0.4627 - learning_rate: 1.5000e-04\n",
      "Epoch 730/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0879 - val_loss: 0.0744 - learning_rate: 1.5000e-04\n",
      "Epoch 731/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 921ms/step - loss: 0.0836 - val_loss: 0.4926 - learning_rate: 1.5000e-04\n",
      "Epoch 732/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0833 - val_loss: 0.0593 - learning_rate: 1.5000e-04\n",
      "Epoch 733/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0850 - val_loss: 0.3951 - learning_rate: 1.5000e-04\n",
      "Epoch 734/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 913ms/step - loss: 0.0788 - val_loss: 0.0351 - learning_rate: 1.5000e-04\n",
      "Epoch 735/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0808 - val_loss: 0.3662 - learning_rate: 1.5000e-04\n",
      "Epoch 736/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0867 - val_loss: 0.0336 - learning_rate: 1.5000e-04\n",
      "Epoch 737/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 914ms/step - loss: 0.0820 - val_loss: 0.3663 - learning_rate: 1.5000e-04\n",
      "Epoch 738/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0795 - val_loss: 0.0349 - learning_rate: 1.5000e-04\n",
      "Epoch 739/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 928ms/step - loss: 0.0818 - val_loss: 0.3185 - learning_rate: 1.5000e-04\n",
      "Epoch 740/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0758 - val_loss: 0.0184 - learning_rate: 1.5000e-04\n",
      "Epoch 741/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0863 - val_loss: 0.2710 - learning_rate: 1.5000e-04\n",
      "Epoch 742/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 919ms/step - loss: 0.0799 - val_loss: 0.0157 - learning_rate: 1.5000e-04\n",
      "Epoch 743/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0946 - val_loss: 0.2278 - learning_rate: 1.5000e-04\n",
      "Epoch 744/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0927 - val_loss: 0.0159 - learning_rate: 1.5000e-04\n",
      "Epoch 745/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 935ms/step - loss: 0.4423 - val_loss: 0.0279 - learning_rate: 1.5000e-04\n",
      "Epoch 746/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.4779 - val_loss: 0.6896 - learning_rate: 1.5000e-04\n",
      "Epoch 747/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 937ms/step - loss: 0.5845 - val_loss: 0.1684 - learning_rate: 1.5000e-04\n",
      "Epoch 748/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 927ms/step - loss: 0.4743 - val_loss: 0.9606 - learning_rate: 1.5000e-04\n",
      "Epoch 749/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.2929 - val_loss: 0.0297 - learning_rate: 1.5000e-04\n",
      "Epoch 750/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 937ms/step - loss: 0.1981 - val_loss: 0.0348 - learning_rate: 1.5000e-04\n",
      "Epoch 751/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.2878 - val_loss: 1.0909 - learning_rate: 1.5000e-04\n",
      "Epoch 752/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.9308 - val_loss: 0.0903 - learning_rate: 1.5000e-04\n",
      "Epoch 753/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 937ms/step - loss: 0.2069 - val_loss: 0.0558 - learning_rate: 1.5000e-04\n",
      "Epoch 754/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1170 - val_loss: 0.0368 - learning_rate: 1.5000e-04\n",
      "Epoch 755/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1859 - val_loss: 0.3477 - learning_rate: 1.5000e-04\n",
      "Epoch 756/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 934ms/step - loss: 0.2260 - val_loss: 0.0170 - learning_rate: 1.5000e-04\n",
      "Epoch 757/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.8291 - val_loss: 0.4228 - learning_rate: 1.5000e-04\n",
      "Epoch 758/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 933ms/step - loss: 0.5276 - val_loss: 0.6008 - learning_rate: 1.5000e-04\n",
      "Epoch 759/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 932ms/step - loss: 0.9243 - val_loss: 2.6706 - learning_rate: 1.5000e-04\n",
      "Epoch 760/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.5029 - val_loss: 2.3780 - learning_rate: 1.5000e-04\n",
      "Epoch 761/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 928ms/step - loss: 0.4780 - val_loss: 0.0171 - learning_rate: 1.5000e-04\n",
      "Epoch 762/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.3377 - val_loss: 0.1134 - learning_rate: 1.5000e-04\n",
      "Epoch 763/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1978 - val_loss: 1.1120 - learning_rate: 1.5000e-04\n",
      "Epoch 764/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 931ms/step - loss: 0.4768 - val_loss: 0.0601 - learning_rate: 1.5000e-04\n",
      "Epoch 765/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.3327 - val_loss: 0.2788 - learning_rate: 1.5000e-04\n",
      "Epoch 766/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.2169 - val_loss: 0.3337 - learning_rate: 1.5000e-04\n",
      "Epoch 767/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 931ms/step - loss: 0.2309 - val_loss: 0.2063 - learning_rate: 1.5000e-04\n",
      "Epoch 768/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1983 - val_loss: 0.1035 - learning_rate: 1.5000e-04\n",
      "Epoch 769/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 934ms/step - loss: 0.8159 - val_loss: 1.4731 - learning_rate: 1.5000e-04\n",
      "Epoch 770/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 935ms/step - loss: 0.8348 - val_loss: 0.3559 - learning_rate: 1.5000e-04\n",
      "Epoch 771/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.3225 - val_loss: 2.6024 - learning_rate: 1.5000e-04\n",
      "Epoch 772/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870ms/step - loss: 1.0859\n",
      "Epoch 772: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 933ms/step - loss: 0.6874 - val_loss: 0.0404 - learning_rate: 1.5000e-04\n",
      "Epoch 773/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1585 - val_loss: 0.6386 - learning_rate: 7.5000e-05\n",
      "Epoch 774/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1135 - val_loss: 0.0553 - learning_rate: 7.5000e-05\n",
      "Epoch 775/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 934ms/step - loss: 0.0442 - val_loss: 0.2921 - learning_rate: 7.5000e-05\n",
      "Epoch 776/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1311 - val_loss: 0.0438 - learning_rate: 7.5000e-05\n",
      "Epoch 777/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0843 - val_loss: 0.0212 - learning_rate: 7.5000e-05\n",
      "Epoch 778/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 933ms/step - loss: 0.0979 - val_loss: 0.4786 - learning_rate: 7.5000e-05\n",
      "Epoch 779/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0578 - val_loss: 0.0996 - learning_rate: 7.5000e-05\n",
      "Epoch 780/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 930ms/step - loss: 0.0417 - val_loss: 0.0561 - learning_rate: 7.5000e-05\n",
      "Epoch 781/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0783 - val_loss: 0.0172 - learning_rate: 7.5000e-05\n",
      "Epoch 782/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0787 - val_loss: 0.2077 - learning_rate: 7.5000e-05\n",
      "Epoch 783/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 940ms/step - loss: 0.0755 - val_loss: 0.2473 - learning_rate: 7.5000e-05\n",
      "Epoch 784/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0775 - val_loss: 0.0153 - learning_rate: 7.5000e-05\n",
      "Epoch 785/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0674 - val_loss: 0.2122 - learning_rate: 7.5000e-05\n",
      "Epoch 786/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 934ms/step - loss: 0.0676 - val_loss: 0.2548 - learning_rate: 7.5000e-05\n",
      "Epoch 787/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0692 - val_loss: 0.0162 - learning_rate: 7.5000e-05\n",
      "Epoch 788/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0703 - val_loss: 0.1996 - learning_rate: 7.5000e-05\n",
      "Epoch 789/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 933ms/step - loss: 0.0708 - val_loss: 0.2343 - learning_rate: 7.5000e-05\n",
      "Epoch 790/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0697 - val_loss: 0.0162 - learning_rate: 7.5000e-05\n",
      "Epoch 791/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 931ms/step - loss: 0.0677 - val_loss: 0.2120 - learning_rate: 7.5000e-05\n",
      "Epoch 792/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0648 - val_loss: 0.2477 - learning_rate: 7.5000e-05\n",
      "Epoch 793/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0675 - val_loss: 0.0157 - learning_rate: 7.5000e-05\n",
      "Epoch 794/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 933ms/step - loss: 0.0692 - val_loss: 0.1936 - learning_rate: 7.5000e-05\n",
      "Epoch 795/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0668 - val_loss: 0.2359 - learning_rate: 7.5000e-05\n",
      "Epoch 796/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0642 - val_loss: 0.0144 - learning_rate: 7.5000e-05\n",
      "Epoch 797/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 936ms/step - loss: 0.0771 - val_loss: 0.1909 - learning_rate: 7.5000e-05\n",
      "Epoch 798/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0725 - val_loss: 0.2235 - learning_rate: 7.5000e-05\n",
      "Epoch 799/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0729 - val_loss: 0.0144 - learning_rate: 7.5000e-05\n",
      "Epoch 800/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 938ms/step - loss: 0.0751 - val_loss: 0.1783 - learning_rate: 7.5000e-05\n",
      "Epoch 801/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0731 - val_loss: 0.2217 - learning_rate: 7.5000e-05\n",
      "Epoch 802/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 926ms/step - loss: 0.0669 - val_loss: 0.0135 - learning_rate: 7.5000e-05\n",
      "Epoch 803/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0701 - val_loss: 0.1799 - learning_rate: 7.5000e-05\n",
      "Epoch 804/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0737 - val_loss: 0.2026 - learning_rate: 7.5000e-05\n",
      "Epoch 805/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 928ms/step - loss: 0.0720 - val_loss: 0.0124 - learning_rate: 7.5000e-05\n",
      "Epoch 806/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0858 - val_loss: 0.1421 - learning_rate: 7.5000e-05\n",
      "Epoch 807/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0776 - val_loss: 0.1805 - learning_rate: 7.5000e-05\n",
      "Epoch 808/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 924ms/step - loss: 0.0657 - val_loss: 0.0127 - learning_rate: 7.5000e-05\n",
      "Epoch 809/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0734 - val_loss: 0.1715 - learning_rate: 7.5000e-05\n",
      "Epoch 810/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0728 - val_loss: 0.2076 - learning_rate: 7.5000e-05\n",
      "Epoch 811/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 933ms/step - loss: 0.0740 - val_loss: 0.0125 - learning_rate: 7.5000e-05\n",
      "Epoch 812/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0731 - val_loss: 0.1803 - learning_rate: 7.5000e-05\n",
      "Epoch 813/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 919ms/step - loss: 0.0684 - val_loss: 0.2031 - learning_rate: 7.5000e-05\n",
      "Epoch 814/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0733 - val_loss: 0.0124 - learning_rate: 7.5000e-05\n",
      "Epoch 815/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0718 - val_loss: 0.1817 - learning_rate: 7.5000e-05\n",
      "Epoch 816/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 913ms/step - loss: 0.0660 - val_loss: 0.2813 - learning_rate: 7.5000e-05\n",
      "Epoch 817/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0582 - val_loss: 0.0174 - learning_rate: 7.5000e-05\n",
      "Epoch 818/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0664 - val_loss: 0.2134 - learning_rate: 7.5000e-05\n",
      "Epoch 819/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 920ms/step - loss: 0.0745 - val_loss: 0.2317 - learning_rate: 7.5000e-05\n",
      "Epoch 820/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0668 - val_loss: 0.0131 - learning_rate: 7.5000e-05\n",
      "Epoch 821/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0651 - val_loss: 0.1935 - learning_rate: 7.5000e-05\n",
      "Epoch 822/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 928ms/step - loss: 0.0710 - val_loss: 0.2082 - learning_rate: 7.5000e-05\n",
      "Epoch 823/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0709 - val_loss: 0.0124 - learning_rate: 7.5000e-05\n",
      "Epoch 824/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 925ms/step - loss: 0.0671 - val_loss: 0.1661 - learning_rate: 7.5000e-05\n",
      "Epoch 825/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0700 - val_loss: 0.2024 - learning_rate: 7.5000e-05\n",
      "Epoch 826/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0679 - val_loss: 0.0131 - learning_rate: 7.5000e-05\n",
      "Epoch 827/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 922ms/step - loss: 0.0786 - val_loss: 0.1508 - learning_rate: 7.5000e-05\n",
      "Epoch 828/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0687 - val_loss: 0.0155 - learning_rate: 7.5000e-05\n",
      "Epoch 829/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0832 - val_loss: 0.1421 - learning_rate: 7.5000e-05\n",
      "Epoch 830/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 921ms/step - loss: 0.0801 - val_loss: 0.2047 - learning_rate: 7.5000e-05\n",
      "Epoch 831/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0756 - val_loss: 0.0152 - learning_rate: 7.5000e-05\n",
      "Epoch 832/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0794 - val_loss: 0.1637 - learning_rate: 7.5000e-05\n",
      "Epoch 833/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 924ms/step - loss: 0.0757 - val_loss: 0.4729 - learning_rate: 7.5000e-05\n",
      "Epoch 834/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1490 - val_loss: 1.3147 - learning_rate: 7.5000e-05\n",
      "Epoch 835/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 935ms/step - loss: 0.1770 - val_loss: 0.4734 - learning_rate: 7.5000e-05\n",
      "Epoch 836/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1271 - val_loss: 0.0745 - learning_rate: 7.5000e-05\n",
      "Epoch 837/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0922 - val_loss: 0.0674 - learning_rate: 7.5000e-05\n",
      "Epoch 838/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 935ms/step - loss: 0.1942 - val_loss: 0.4238 - learning_rate: 7.5000e-05\n",
      "Epoch 839/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1591 - val_loss: 0.1594 - learning_rate: 7.5000e-05\n",
      "Epoch 840/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0815 - val_loss: 1.0874 - learning_rate: 7.5000e-05\n",
      "Epoch 841/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 939ms/step - loss: 0.1062 - val_loss: 0.3324 - learning_rate: 7.5000e-05\n",
      "Epoch 842/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.1366 - val_loss: 0.9726 - learning_rate: 7.5000e-05\n",
      "Epoch 843/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.2113 - val_loss: 0.1912 - learning_rate: 7.5000e-05\n",
      "Epoch 844/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 938ms/step - loss: 0.2346 - val_loss: 0.1411 - learning_rate: 7.5000e-05\n",
      "Epoch 845/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.2133 - val_loss: 0.4406 - learning_rate: 7.5000e-05\n",
      "Epoch 846/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 937ms/step - loss: 0.1310 - val_loss: 0.0639 - learning_rate: 7.5000e-05\n",
      "Epoch 847/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.2028 - val_loss: 0.0706 - learning_rate: 7.5000e-05\n",
      "Epoch 848/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0718 - val_loss: 0.2757 - learning_rate: 7.5000e-05\n",
      "Epoch 849/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 931ms/step - loss: 0.0587 - val_loss: 0.1004 - learning_rate: 7.5000e-05\n",
      "Epoch 850/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0575 - val_loss: 0.2669 - learning_rate: 7.5000e-05\n",
      "Epoch 851/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0595 - val_loss: 0.1351 - learning_rate: 7.5000e-05\n",
      "Epoch 852/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 935ms/step - loss: 0.0855 - val_loss: 0.2202 - learning_rate: 7.5000e-05\n",
      "Epoch 853/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0722 - val_loss: 0.0177 - learning_rate: 7.5000e-05\n",
      "Epoch 854/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0683 - val_loss: 0.2449 - learning_rate: 7.5000e-05\n",
      "Epoch 855/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 941ms/step - loss: 0.0655 - val_loss: 0.3329 - learning_rate: 7.5000e-05\n",
      "Epoch 856/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0724 - val_loss: 0.3495 - learning_rate: 7.5000e-05\n",
      "Epoch 857/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 940ms/step - loss: 0.0734 - val_loss: 0.3393 - learning_rate: 7.5000e-05\n",
      "Epoch 858/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 931ms/step - loss: 0.0725 - val_loss: 0.0295 - learning_rate: 7.5000e-05\n",
      "Epoch 859/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0738 - val_loss: 0.2742 - learning_rate: 7.5000e-05\n",
      "Epoch 860/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 926ms/step - loss: 0.0660 - val_loss: 0.3170 - learning_rate: 7.5000e-05\n",
      "Epoch 861/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0669 - val_loss: 0.0246 - learning_rate: 7.5000e-05\n",
      "Epoch 862/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0689 - val_loss: 0.2444 - learning_rate: 7.5000e-05\n",
      "Epoch 863/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 925ms/step - loss: 0.0644 - val_loss: 0.2865 - learning_rate: 7.5000e-05\n",
      "Epoch 864/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0655 - val_loss: 0.0195 - learning_rate: 7.5000e-05\n",
      "Epoch 865/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0655 - val_loss: 0.2184 - learning_rate: 7.5000e-05\n",
      "Epoch 866/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 926ms/step - loss: 0.0628 - val_loss: 0.2480 - learning_rate: 7.5000e-05\n",
      "Epoch 867/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0646 - val_loss: 0.0182 - learning_rate: 7.5000e-05\n",
      "Epoch 868/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 949ms/step - loss: 0.0643 - val_loss: 0.2230 - learning_rate: 7.5000e-05\n",
      "Epoch 869/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 922ms/step - loss: 0.0633 - val_loss: 0.2541 - learning_rate: 7.5000e-05\n",
      "Epoch 870/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0644 - val_loss: 0.0159 - learning_rate: 7.5000e-05\n",
      "Epoch 871/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 933ms/step - loss: 0.0663 - val_loss: 0.1963 - learning_rate: 7.5000e-05\n",
      "Epoch 872/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 0.0722 - val_loss: 0.2114 - learning_rate: 7.5000e-05\n",
      "Epoch 873/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.0644 - val_loss: 0.1383 - learning_rate: 7.5000e-05\n",
      "Epoch 874/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 928ms/step - loss: 0.1571 - val_loss: 0.6401 - learning_rate: 7.5000e-05\n",
      "Epoch 875/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 0.1309 - val_loss: 0.0136 - learning_rate: 7.5000e-05\n",
      "Epoch 876/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 964ms/step - loss: 0.0698 - learning_rate: 7.5000e-05\n",
      "Epoch 877/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 22:07:29.650493: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/home/yizhou_chen/miniconda3/envs/base-ml/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "/home/yizhou_chen/miniconda3/envs/base-ml/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:99: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "  current = self.get_monitor_value(logs)\n",
      "/home/yizhou_chen/miniconda3/envs/base-ml/lib/python3.12/site-packages/keras/src/callbacks/callback_list.py:145: UserWarning: Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,learning_rate.\n",
      "  callback.on_epoch_end(epoch, logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 883ms/step - loss: 0.1157 - learning_rate: 7.5000e-05\n",
      "Epoch 878/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 22:07:49.107332: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 957ms/step - loss: 0.1169 - learning_rate: 7.5000e-05\n",
      "Epoch 879/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 883ms/step - loss: 0.1116 - learning_rate: 7.5000e-05\n",
      "Epoch 880/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 22:08:29.535261: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 956ms/step - loss: 0.0936 - learning_rate: 7.5000e-05\n",
      "Epoch 881/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 953ms/step - loss: 0.0988 - learning_rate: 7.5000e-05\n",
      "Epoch 882/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 880ms/step - loss: 0.0934 - learning_rate: 7.5000e-05\n",
      "Epoch 883/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 957ms/step - loss: 0.0524 - learning_rate: 7.5000e-05\n",
      "Epoch 884/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 22:09:51.741787: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 878ms/step - loss: 0.0417 - learning_rate: 7.5000e-05\n",
      "Epoch 885/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 958ms/step - loss: 0.0408 - learning_rate: 7.5000e-05\n",
      "Epoch 886/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 957ms/step - loss: 0.0376 - learning_rate: 7.5000e-05\n",
      "Epoch 887/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 875ms/step - loss: 0.0373 - learning_rate: 7.5000e-05\n",
      "Epoch 888/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 958ms/step - loss: 0.0395 - learning_rate: 7.5000e-05\n",
      "Epoch 889/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 0.0365 - learning_rate: 7.5000e-05\n",
      "Epoch 890/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 965ms/step - loss: 0.0346 - learning_rate: 7.5000e-05\n",
      "Epoch 891/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 887ms/step - loss: 0.0373 - learning_rate: 7.5000e-05\n",
      "Epoch 892/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 22:12:55.332849: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 966ms/step - loss: 0.0319 - learning_rate: 7.5000e-05\n",
      "Epoch 893/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 888ms/step - loss: 0.0343 - learning_rate: 7.5000e-05\n",
      "Epoch 894/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 968ms/step - loss: 0.0340 - learning_rate: 7.5000e-05\n",
      "Epoch 895/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 972ms/step - loss: 0.0392 - learning_rate: 7.5000e-05\n",
      "Epoch 896/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 889ms/step - loss: 0.0423 - learning_rate: 7.5000e-05\n",
      "Epoch 897/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 966ms/step - loss: 0.0357 - learning_rate: 7.5000e-05\n",
      "Epoch 898/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - loss: 0.0364 - learning_rate: 7.5000e-05\n",
      "Epoch 899/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 879ms/step - loss: 0.0343 - learning_rate: 7.5000e-05\n",
      "Epoch 900/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 966ms/step - loss: 0.0351 - learning_rate: 7.5000e-05\n",
      "Epoch 901/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 962ms/step - loss: 0.0346 - learning_rate: 7.5000e-05\n",
      "Epoch 902/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 889ms/step - loss: 0.0346 - learning_rate: 7.5000e-05\n",
      "Epoch 903/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 967ms/step - loss: 0.0368 - learning_rate: 7.5000e-05\n",
      "Epoch 904/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 865ms/step - loss: 0.0381 - learning_rate: 7.5000e-05\n",
      "Epoch 905/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 972ms/step - loss: 0.0370 - learning_rate: 7.5000e-05\n",
      "Epoch 906/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 947ms/step - loss: 0.0378 - learning_rate: 7.5000e-05\n",
      "Epoch 907/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 875ms/step - loss: 0.0379 - learning_rate: 7.5000e-05\n",
      "Epoch 908/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 22:19:06.051188: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 981ms/step - loss: 0.0385 - learning_rate: 7.5000e-05\n",
      "Epoch 909/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 872ms/step - loss: 0.0377 - learning_rate: 7.5000e-05\n",
      "Epoch 910/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 933ms/step - loss: 0.0345 - learning_rate: 7.5000e-05\n",
      "Epoch 911/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 973ms/step - loss: 0.0322 - learning_rate: 7.5000e-05\n",
      "Epoch 912/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 874ms/step - loss: 0.0340 - learning_rate: 7.5000e-05\n",
      "Epoch 913/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 966ms/step - loss: 0.0353 - learning_rate: 7.5000e-05\n",
      "Epoch 914/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 870ms/step - loss: 0.0404 - learning_rate: 7.5000e-05\n",
      "Epoch 915/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 959ms/step - loss: 0.0349 - learning_rate: 7.5000e-05\n",
      "Epoch 916/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 960ms/step - loss: 0.0364 - learning_rate: 7.5000e-05\n",
      "Epoch 917/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 881ms/step - loss: 0.0349 - learning_rate: 7.5000e-05\n",
      "Epoch 918/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 959ms/step - loss: 0.0348 - learning_rate: 7.5000e-05\n",
      "Epoch 919/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 876ms/step - loss: 0.0341 - learning_rate: 7.5000e-05\n",
      "Epoch 920/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 965ms/step - loss: 0.0361 - learning_rate: 7.5000e-05\n",
      "Epoch 921/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 967ms/step - loss: 0.0352 - learning_rate: 7.5000e-05\n",
      "Epoch 922/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 869ms/step - loss: 0.0398 - learning_rate: 7.5000e-05\n",
      "Epoch 923/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 968ms/step - loss: 0.0404 - learning_rate: 7.5000e-05\n",
      "Epoch 924/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 874ms/step - loss: 0.1163 - learning_rate: 7.5000e-05\n",
      "Epoch 925/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 958ms/step - loss: 0.1433 - learning_rate: 7.5000e-05\n",
      "Epoch 926/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 960ms/step - loss: 0.1343 - learning_rate: 7.5000e-05\n",
      "Epoch 927/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 882ms/step - loss: 0.1419 - learning_rate: 7.5000e-05\n",
      "Epoch 928/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 954ms/step - loss: 0.1320 - learning_rate: 7.5000e-05\n",
      "Epoch 929/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 876ms/step - loss: 0.1442 - learning_rate: 7.5000e-05\n",
      "Epoch 930/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 960ms/step - loss: 0.1371 - learning_rate: 7.5000e-05\n",
      "Epoch 931/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 957ms/step - loss: 0.1408 - learning_rate: 7.5000e-05\n",
      "Epoch 932/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 873ms/step - loss: 0.1244 - learning_rate: 7.5000e-05\n",
      "Epoch 933/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 967ms/step - loss: 0.1360 - learning_rate: 7.5000e-05\n",
      "Epoch 934/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3s/step - loss: 0.1326 - learning_rate: 7.5000e-05\n",
      "Epoch 935/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 878ms/step - loss: 0.1416 - learning_rate: 7.5000e-05\n",
      "Epoch 936/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 954ms/step - loss: 0.1208 - learning_rate: 7.5000e-05\n",
      "Epoch 937/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 881ms/step - loss: 0.0389 - learning_rate: 7.5000e-05\n",
      "Epoch 938/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 958ms/step - loss: 0.1300 - learning_rate: 7.5000e-05\n",
      "Epoch 939/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 955ms/step - loss: 0.1391 - learning_rate: 7.5000e-05\n",
      "Epoch 940/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 22:30:42.151166: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 880ms/step - loss: 0.1444 - learning_rate: 7.5000e-05\n",
      "Epoch 941/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 960ms/step - loss: 0.0459 - learning_rate: 7.5000e-05\n",
      "Epoch 942/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 874ms/step - loss: 0.0409 - learning_rate: 7.5000e-05\n",
      "Epoch 943/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 0.0519 - learning_rate: 7.5000e-05\n",
      "Epoch 944/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 876ms/step - loss: 0.1092 - learning_rate: 7.5000e-05\n",
      "Epoch 945/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 960ms/step - loss: 0.1023 - learning_rate: 7.5000e-05\n",
      "Epoch 946/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 878ms/step - loss: 0.1210 - learning_rate: 7.5000e-05\n",
      "Epoch 947/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 962ms/step - loss: 0.1332 - learning_rate: 7.5000e-05\n",
      "Epoch 948/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 963ms/step - loss: 0.1143 - learning_rate: 7.5000e-05\n",
      "Epoch 949/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 881ms/step - loss: 0.2292 - learning_rate: 7.5000e-05\n",
      "Epoch 950/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 955ms/step - loss: 0.0654 - learning_rate: 7.5000e-05\n",
      "Epoch 951/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 880ms/step - loss: 0.0653 - learning_rate: 7.5000e-05\n",
      "Epoch 952/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 963ms/step - loss: 0.0681 - learning_rate: 7.5000e-05\n",
      "Epoch 953/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 954ms/step - loss: 0.1259 - learning_rate: 7.5000e-05\n",
      "Epoch 954/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 884ms/step - loss: 0.1666 - learning_rate: 7.5000e-05\n",
      "Epoch 955/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 956ms/step - loss: 0.0701 - learning_rate: 7.5000e-05\n",
      "Epoch 956/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 874ms/step - loss: 0.0941 - learning_rate: 7.5000e-05\n",
      "Epoch 957/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 959ms/step - loss: 0.1540 - learning_rate: 7.5000e-05\n",
      "Epoch 958/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 961ms/step - loss: 0.2035 - learning_rate: 7.5000e-05\n",
      "Epoch 959/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 877ms/step - loss: 0.1691 - learning_rate: 7.5000e-05\n",
      "Epoch 960/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 959ms/step - loss: 0.1996 - learning_rate: 7.5000e-05\n",
      "Epoch 961/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 884ms/step - loss: 0.1223 - learning_rate: 7.5000e-05\n",
      "Epoch 962/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 956ms/step - loss: 0.1257 - learning_rate: 7.5000e-05\n",
      "Epoch 963/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 955ms/step - loss: 0.1158 - learning_rate: 7.5000e-05\n",
      "Epoch 964/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 881ms/step - loss: 0.0727 - learning_rate: 7.5000e-05\n",
      "Epoch 965/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 958ms/step - loss: 0.0951 - learning_rate: 7.5000e-05\n",
      "Epoch 966/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 883ms/step - loss: 0.0702 - learning_rate: 7.5000e-05\n",
      "Epoch 967/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 960ms/step - loss: 0.0624 - learning_rate: 7.5000e-05\n",
      "Epoch 968/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 958ms/step - loss: 0.1104 - learning_rate: 7.5000e-05\n",
      "Epoch 969/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 876ms/step - loss: 0.1075 - learning_rate: 7.5000e-05\n",
      "Epoch 970/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - loss: 0.1579 - learning_rate: 7.5000e-05\n",
      "Epoch 971/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 961ms/step - loss: 0.1479 - learning_rate: 7.5000e-05\n",
      "Epoch 972/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 879ms/step - loss: 0.1569 - learning_rate: 7.5000e-05\n",
      "Epoch 973/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 957ms/step - loss: 0.2047 - learning_rate: 7.5000e-05\n",
      "Epoch 974/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 882ms/step - loss: 0.2552 - learning_rate: 7.5000e-05\n",
      "Epoch 975/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 959ms/step - loss: 0.2798 - learning_rate: 7.5000e-05\n",
      "Epoch 976/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 954ms/step - loss: 0.1237 - learning_rate: 7.5000e-05\n",
      "Epoch 977/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 885ms/step - loss: 0.1315 - learning_rate: 7.5000e-05\n",
      "Epoch 978/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 960ms/step - loss: 0.1119 - learning_rate: 7.5000e-05\n",
      "Epoch 979/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 883ms/step - loss: 0.0399 - learning_rate: 7.5000e-05\n",
      "Epoch 980/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 960ms/step - loss: 0.0745 - learning_rate: 7.5000e-05\n",
      "Epoch 981/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 962ms/step - loss: 0.1280 - learning_rate: 7.5000e-05\n",
      "Epoch 982/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 878ms/step - loss: 0.1337 - learning_rate: 7.5000e-05\n",
      "Epoch 983/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 960ms/step - loss: 0.1230 - learning_rate: 7.5000e-05\n",
      "Epoch 984/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 884ms/step - loss: 0.1244 - learning_rate: 7.5000e-05\n",
      "Epoch 985/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 878ms/step - loss: 0.1302 - learning_rate: 7.5000e-05\n",
      "Epoch 986/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 958ms/step - loss: 0.1249 - learning_rate: 7.5000e-05\n",
      "Epoch 987/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 880ms/step - loss: 0.1682 - learning_rate: 7.5000e-05\n",
      "Epoch 988/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 958ms/step - loss: 0.1812 - learning_rate: 7.5000e-05\n",
      "Epoch 989/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 878ms/step - loss: 0.2072 - learning_rate: 7.5000e-05\n",
      "Epoch 990/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 889ms/step - loss: 0.1002 - learning_rate: 7.5000e-05\n",
      "Epoch 991/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 957ms/step - loss: 0.1066 - learning_rate: 7.5000e-05\n",
      "Epoch 992/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 871ms/step - loss: 0.2122 - learning_rate: 7.5000e-05\n",
      "Epoch 993/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 975ms/step - loss: 0.1099 - learning_rate: 7.5000e-05\n",
      "Epoch 994/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 868ms/step - loss: 0.1634 - learning_rate: 7.5000e-05\n",
      "Epoch 995/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 885ms/step - loss: 0.1953 - learning_rate: 7.5000e-05\n",
      "Epoch 996/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 970ms/step - loss: 0.0611 - learning_rate: 7.5000e-05\n",
      "Epoch 997/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 866ms/step - loss: 0.0593 - learning_rate: 7.5000e-05\n",
      "Epoch 998/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 967ms/step - loss: 0.0646 - learning_rate: 7.5000e-05\n",
      "Epoch 999/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 875ms/step - loss: 0.1186 - learning_rate: 7.5000e-05\n",
      "Epoch 1000/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 884ms/step - loss: 0.2466 - learning_rate: 7.5000e-05\n",
      "Epoch 1001/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1002/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1003/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1004/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1005/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 22:51:51.413994: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1006/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1007/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1008/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1009/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1010/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1011/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1012/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1013/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1014/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1015/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1016/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1017/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1018/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1019/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1020/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1021/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1022/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1023/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1024/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1025/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1026/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1027/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1028/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1029/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1030/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1031/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1032/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1033/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1034/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1035/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1036/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1037/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1038/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1039/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1040/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1041/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1042/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1043/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1044/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1045/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1046/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1047/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1048/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1049/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1050/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1051/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1052/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1053/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1054/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1055/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1056/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1057/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1058/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1059/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1060/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1061/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1062/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1063/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1064/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1065/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1066/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1067/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1068/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1069/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1070/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 22:51:54.651890: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1071/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1072/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1073/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1074/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1075/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1076/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1077/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1078/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1079/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1080/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1081/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1082/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1083/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1084/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1085/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1086/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1087/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1088/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1089/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1090/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1091/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1092/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1093/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1094/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1095/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1096/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1097/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1098/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1099/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1100/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1101/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1102/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1103/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1104/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1105/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1106/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1107/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1108/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1109/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1110/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1111/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1112/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1113/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1114/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1115/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1116/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1117/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1118/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1119/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1120/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1121/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1122/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1123/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1124/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1125/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1126/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1127/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1128/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1129/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1130/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1131/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1132/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1133/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1134/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1135/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1136/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1137/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1138/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1139/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1140/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1141/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1142/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1143/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1144/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1145/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1146/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1147/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1148/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1149/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1150/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1151/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1152/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1153/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1154/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1155/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1156/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1157/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1158/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1159/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1160/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1161/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1162/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1163/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1164/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1165/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1166/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1167/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1168/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1169/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1170/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1171/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1172/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1173/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1174/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1175/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1176/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1177/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1178/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1179/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1180/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1181/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1182/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1183/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1184/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1185/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1186/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1187/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1188/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1189/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1190/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1191/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1192/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1193/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1194/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1195/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1196/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1197/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1198/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 22:52:01.005503: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1199/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1200/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1201/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1202/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1203/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1204/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1205/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1206/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1207/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1208/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1209/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1210/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1211/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1212/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1213/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1214/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1215/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1216/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1217/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1218/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1219/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1220/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1221/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1222/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1223/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1224/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1225/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1226/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1227/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1228/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1229/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1230/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1231/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1232/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1233/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1234/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1235/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1236/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1237/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1238/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1239/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1240/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1241/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1242/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1243/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1244/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1245/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1246/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1247/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1248/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1249/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1250/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1251/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1252/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1253/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1254/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1255/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1256/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1257/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1258/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1259/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1260/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1261/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1262/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1263/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1264/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1265/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1266/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1267/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1268/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1269/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1270/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1271/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1272/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1273/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1274/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1275/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1276/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1277/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1278/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1279/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1280/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1281/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1282/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1283/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1284/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1285/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1286/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1287/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1288/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1289/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1290/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1291/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1292/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1293/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1294/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1295/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1296/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1297/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1298/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1299/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1300/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1301/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1302/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1303/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1304/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1305/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1306/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1307/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1308/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1309/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1310/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1311/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1312/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1313/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1314/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1315/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1316/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1317/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1318/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1319/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1320/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1321/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1322/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1323/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1324/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1325/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1326/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1327/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1328/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1329/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1330/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1331/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1332/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1333/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1334/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1335/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1336/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1337/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1338/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1339/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1340/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1341/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1342/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1343/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1344/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1345/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1346/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1347/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1348/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1349/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1350/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1351/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1352/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1353/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1354/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1355/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1356/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1357/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1358/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1359/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1360/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1361/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1362/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1363/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1364/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1365/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1366/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1367/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1368/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1369/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1370/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1371/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1372/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1373/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1374/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1375/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1376/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1377/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1378/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1379/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1380/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1381/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1382/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1383/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1384/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1385/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1386/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1387/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1388/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1389/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1390/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1391/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1392/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1393/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1394/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1395/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1396/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1397/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1398/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1399/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1400/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1401/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1402/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1403/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1404/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1405/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1406/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1407/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1408/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1409/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1410/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1411/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1412/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1413/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1414/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1415/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1416/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1417/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1418/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1419/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1420/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1421/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1422/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1423/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1424/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1425/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1426/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1427/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1428/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1429/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1430/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1431/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1432/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1433/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1434/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1435/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1436/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1437/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1438/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1439/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1440/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1441/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1442/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1443/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1444/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1445/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1446/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1447/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1448/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1449/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1450/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1451/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1452/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1453/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1454/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 22:52:15.403583: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1455/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1456/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1457/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1458/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1459/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1460/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1461/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1462/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1463/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1464/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1465/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1466/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1467/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1468/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1469/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1470/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1471/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1472/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1473/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1474/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1475/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1476/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1477/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1478/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1479/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1480/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1481/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1482/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1483/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1484/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1485/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1486/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1487/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1488/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1489/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1490/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1491/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1492/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1493/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1494/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1495/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1496/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1497/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1498/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1499/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1500/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1501/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1502/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1503/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1504/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1505/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1506/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1507/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1508/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1509/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1510/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1511/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1512/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1513/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1514/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1515/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1516/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1517/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1518/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1519/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1520/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1521/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1522/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1523/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1524/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1525/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1526/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1527/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1528/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1529/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1530/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1531/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1532/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1533/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1534/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1535/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1536/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1537/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1538/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1539/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1540/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1541/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1542/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1543/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1544/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1545/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1546/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1547/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1548/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1549/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1550/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1551/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1552/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1553/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1554/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1555/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1556/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1557/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1558/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1559/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1560/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1561/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1562/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1563/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1564/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1565/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1566/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1567/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1568/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1569/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1570/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1571/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1572/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1573/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1574/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1575/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1576/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1577/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1578/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1579/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1580/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1581/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1582/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1583/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1584/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1585/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1586/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1587/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1588/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1589/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1590/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1591/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1592/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1593/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1594/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1595/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1596/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1597/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1598/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1599/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1600/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1601/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1602/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1603/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1604/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1605/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1606/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1607/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1608/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1609/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1610/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1611/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1612/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1613/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1614/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1615/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1616/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1617/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1618/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1619/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1620/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1621/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1622/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1623/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1624/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1625/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1626/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1627/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1628/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1629/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1630/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1631/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1632/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1633/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1634/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1635/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1636/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1637/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1638/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1639/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1640/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1641/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1642/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1643/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1644/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1645/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1646/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1647/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1648/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1649/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1650/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1651/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1652/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1653/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1654/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1655/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1656/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1657/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1658/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1659/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1660/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1661/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1662/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1663/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1664/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1665/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1666/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1667/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1668/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1669/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1670/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1671/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1672/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1673/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1674/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1675/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1676/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1677/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1678/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1679/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1680/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1681/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1682/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1683/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1684/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1685/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1686/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1687/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1688/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1689/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1690/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1691/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1692/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1693/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1694/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1695/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1696/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1697/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1698/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1699/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1700/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1701/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1702/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1703/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1704/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1705/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1706/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1707/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1708/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1709/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1710/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1711/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1712/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1713/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1714/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1715/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1716/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1717/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1718/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1719/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1720/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1721/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1722/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1723/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1724/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1725/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1726/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1727/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1728/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1729/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1730/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1731/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1732/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1733/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1734/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1735/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1736/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1737/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1738/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1739/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1740/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1741/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1742/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1743/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1744/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1745/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1746/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1747/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1748/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1749/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1750/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1751/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1752/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1753/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1754/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1755/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1756/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1757/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1758/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1759/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1760/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1761/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1762/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1763/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1764/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1765/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1766/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1767/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1768/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1769/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1770/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1771/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1772/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1773/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1774/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1775/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1776/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1777/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1778/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1779/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1780/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1781/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1782/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1783/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1784/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1785/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1786/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1787/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1788/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1789/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1790/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1791/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1792/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1793/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1794/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1795/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1796/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1797/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1798/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1799/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1800/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1801/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1802/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1803/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1804/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1805/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1806/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1807/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1808/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1809/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1810/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1811/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1812/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1813/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1814/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1815/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1816/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1817/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1818/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1819/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1820/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1821/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1822/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1823/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1824/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1825/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1826/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1827/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1828/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1829/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1830/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1831/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1832/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1833/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1834/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1835/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1836/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1837/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1838/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1839/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1840/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1841/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1842/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1843/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1844/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1845/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1846/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1847/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1848/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1849/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1850/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1851/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1852/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1853/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1854/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1855/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1856/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1857/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1858/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1859/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1860/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1861/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1862/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1863/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1864/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1865/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1866/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1867/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1868/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1869/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1870/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1871/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1872/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1873/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1874/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1875/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1876/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1877/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1878/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1879/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1880/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1881/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1882/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1883/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1884/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1885/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1886/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1887/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1888/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1889/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1890/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1891/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1892/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1893/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1894/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1895/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1896/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1897/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1898/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1899/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1900/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1901/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1902/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1903/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1904/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1905/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1906/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1907/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1908/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1909/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1910/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1911/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1912/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1913/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1914/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1915/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1916/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1917/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1918/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1919/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1920/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1921/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1922/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1923/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1924/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1925/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1926/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1927/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1928/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1929/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1930/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1931/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1932/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1933/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1934/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1935/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1936/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1937/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1938/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1939/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1940/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1941/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1942/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1943/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1944/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1945/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1946/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1947/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1948/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1949/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1950/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1951/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1952/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1953/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1954/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1955/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1956/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1957/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1958/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1959/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1960/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1961/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1962/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1963/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1964/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1965/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1966/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 22:52:41.111758: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1967/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1968/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1969/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1970/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1971/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1972/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1973/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1974/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1975/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1976/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1977/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1978/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1979/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1980/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1981/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1982/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1983/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1984/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1985/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1986/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1987/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1988/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1989/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1990/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1991/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1992/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1993/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1994/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1995/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1996/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1997/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1998/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 1999/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2000/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2001/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2002/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2003/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2004/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2005/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2006/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2007/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2008/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2009/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2010/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2011/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2012/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2013/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2014/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2015/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2016/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2017/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2018/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2019/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2020/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2021/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2022/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2023/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2024/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2025/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2026/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2027/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2028/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2029/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2030/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2031/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2032/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2033/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2034/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2035/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2036/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2037/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2038/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2039/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2040/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2041/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2042/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2043/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2044/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2045/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2046/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2047/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2048/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2049/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2050/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2051/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2052/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2053/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2054/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2055/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2056/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2057/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2058/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2059/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2060/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2061/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2062/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2063/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2064/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2065/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2066/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2067/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2068/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2069/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2070/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2071/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2072/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2073/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2074/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2075/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2076/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2077/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2078/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2079/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2080/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2081/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2082/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2083/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2084/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2085/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2086/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2087/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2088/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2089/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2090/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2091/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2092/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2093/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2094/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2095/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2096/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2097/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2098/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2099/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2100/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2101/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2102/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2103/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2104/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2105/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2106/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2107/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2108/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2109/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2110/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2111/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2112/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2113/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2114/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2115/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2116/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2117/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2118/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2119/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2120/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2121/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2122/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2123/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2124/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2125/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2126/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2127/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2128/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2129/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2130/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2131/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2132/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2133/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2134/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2135/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2136/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2137/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2138/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2139/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2140/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2141/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2142/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2143/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2144/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2145/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2146/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2147/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2148/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2149/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2150/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2151/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2152/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2153/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2154/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2155/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2156/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2157/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2158/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2159/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2160/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2161/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2162/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2163/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2164/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2165/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2166/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2167/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2168/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2169/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2170/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2171/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2172/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2173/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2174/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2175/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2176/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2177/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2178/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2179/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2180/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2181/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2182/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2183/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2184/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2185/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2186/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2187/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2188/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2189/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2190/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2191/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2192/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2193/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2194/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2195/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2196/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2197/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2198/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2199/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2200/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2201/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2202/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2203/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2204/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2205/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2206/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2207/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2208/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2209/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2210/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2211/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2212/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2213/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2214/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2215/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2216/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2217/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2218/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2219/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2220/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2221/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2222/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2223/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2224/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2225/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2226/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2227/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2228/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2229/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2230/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2231/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2232/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2233/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2234/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2235/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2236/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2237/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2238/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2239/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2240/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2241/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2242/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2243/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2244/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2245/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2246/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2247/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2248/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2249/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2250/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2251/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2252/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2253/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2254/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2255/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2256/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2257/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2258/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2259/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2260/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2261/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2262/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2263/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2264/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2265/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2266/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2267/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2268/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2269/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2270/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2271/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2272/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2273/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2274/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2275/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2276/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2277/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2278/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2279/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2280/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2281/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2282/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2283/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2284/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2285/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2286/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2287/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2288/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2289/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2290/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2291/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2292/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2293/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2294/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2295/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2296/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2297/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2298/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2299/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2300/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2301/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2302/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2303/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2304/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2305/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2306/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2307/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2308/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2309/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2310/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2311/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2312/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2313/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2314/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2315/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2316/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2317/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2318/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2319/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2320/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2321/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2322/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2323/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2324/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2325/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2326/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2327/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2328/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2329/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2330/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2331/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2332/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2333/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2334/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2335/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2336/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2337/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2338/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2339/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2340/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2341/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2342/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2343/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2344/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2345/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2346/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2347/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2348/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2349/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2350/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2351/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2352/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2353/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2354/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2355/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2356/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2357/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2358/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2359/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2360/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2361/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2362/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2363/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2364/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2365/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2366/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2367/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2368/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2369/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2370/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2371/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2372/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2373/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2374/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2375/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2376/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2377/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2378/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2379/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2380/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2381/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2382/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2383/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2384/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2385/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2386/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2387/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2388/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2389/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2390/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2391/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2392/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2393/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2394/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2395/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2396/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2397/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2398/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2399/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2400/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2401/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2402/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2403/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2404/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2405/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2406/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2407/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2408/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2409/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2410/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2411/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2412/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2413/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2414/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2415/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2416/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2417/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2418/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2419/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2420/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2421/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2422/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2423/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2424/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2425/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2426/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2427/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2428/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2429/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2430/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2431/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2432/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2433/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2434/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2435/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2436/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2437/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2438/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2439/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2440/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2441/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2442/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2443/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2444/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2445/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2446/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2447/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2448/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2449/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2450/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2451/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2452/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2453/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2454/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2455/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2456/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2457/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2458/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2459/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2460/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2461/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2462/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2463/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2464/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2465/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2466/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2467/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2468/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2469/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2470/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2471/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2472/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2473/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2474/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2475/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2476/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2477/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2478/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2479/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2480/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2481/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2482/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2483/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2484/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2485/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2486/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2487/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2488/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2489/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2490/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2491/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2492/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2493/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2494/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2495/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2496/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2497/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2498/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2499/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2500/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2501/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2502/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2503/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2504/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2505/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2506/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2507/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2508/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2509/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2510/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2511/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2512/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2513/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2514/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2515/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2516/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2517/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2518/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2519/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2520/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2521/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2522/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2523/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2524/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2525/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2526/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2527/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2528/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2529/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2530/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2531/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2532/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2533/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2534/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2535/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2536/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2537/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2538/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2539/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2540/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2541/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2542/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2543/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2544/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2545/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2546/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2547/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2548/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2549/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2550/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2551/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2552/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2553/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2554/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2555/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2556/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2557/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2558/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2559/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2560/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2561/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2562/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2563/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2564/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2565/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2566/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2567/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2568/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2569/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2570/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2571/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2572/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2573/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2574/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2575/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2576/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2577/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2578/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2579/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2580/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2581/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2582/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2583/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2584/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2585/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2586/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2587/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2588/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2589/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2590/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2591/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2592/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2593/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2594/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2595/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2596/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2597/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2598/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2599/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2600/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2601/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2602/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2603/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2604/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2605/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2606/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2607/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2608/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2609/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2610/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2611/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2612/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2613/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2614/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2615/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2616/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2617/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2618/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2619/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2620/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2621/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2622/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2623/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2624/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2625/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2626/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2627/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2628/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2629/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2630/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2631/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2632/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2633/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2634/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2635/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2636/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2637/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2638/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2639/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2640/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2641/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2642/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2643/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2644/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2645/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2646/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2647/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2648/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2649/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2650/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2651/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2652/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2653/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2654/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2655/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2656/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2657/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2658/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2659/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2660/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2661/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2662/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2663/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2664/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2665/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2666/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2667/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2668/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2669/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2670/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2671/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2672/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2673/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2674/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2675/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2676/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2677/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2678/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2679/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2680/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2681/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2682/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2683/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2684/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2685/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2686/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2687/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2688/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2689/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2690/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2691/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2692/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2693/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2694/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2695/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2696/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2697/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2698/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2699/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2700/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2701/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2702/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2703/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2704/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2705/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2706/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2707/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2708/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2709/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2710/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2711/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2712/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2713/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2714/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2715/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2716/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2717/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2718/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2719/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2720/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2721/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2722/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2723/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2724/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2725/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2726/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2727/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2728/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2729/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2730/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2731/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2732/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2733/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2734/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2735/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2736/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2737/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2738/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2739/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2740/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2741/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2742/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2743/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2744/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2745/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2746/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2747/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2748/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2749/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2750/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2751/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2752/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2753/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2754/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2755/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2756/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2757/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2758/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2759/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2760/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2761/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2762/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2763/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2764/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2765/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2766/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2767/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2768/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2769/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2770/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2771/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2772/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2773/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2774/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2775/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2776/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2777/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2778/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2779/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2780/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2781/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2782/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2783/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2784/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2785/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2786/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2787/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2788/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2789/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2790/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2791/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2792/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2793/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2794/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2795/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2796/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2797/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2798/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2799/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2800/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2801/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2802/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2803/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2804/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2805/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2806/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2807/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2808/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2809/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2810/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2811/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2812/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2813/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2814/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2815/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2816/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2817/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2818/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2819/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2820/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2821/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2822/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2823/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2824/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2825/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2826/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2827/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2828/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2829/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2830/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2831/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2832/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2833/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2834/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2835/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2836/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2837/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2838/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2839/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2840/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2841/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2842/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2843/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2844/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2845/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2846/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2847/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2848/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2849/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2850/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2851/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2852/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2853/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2854/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2855/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2856/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2857/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2858/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2859/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2860/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2861/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2862/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2863/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2864/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2865/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2866/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2867/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2868/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2869/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2870/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2871/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2872/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2873/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2874/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2875/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2876/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2877/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2878/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2879/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2880/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2881/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2882/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2883/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2884/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2885/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2886/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2887/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2888/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2889/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2890/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2891/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2892/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2893/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2894/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2895/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2896/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2897/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2898/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2899/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2900/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2901/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2902/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2903/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2904/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2905/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2906/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2907/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2908/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2909/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2910/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2911/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2912/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2913/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2914/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2915/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2916/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2917/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2918/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2919/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2920/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2921/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2922/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2923/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2924/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2925/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2926/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2927/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2928/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2929/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2930/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2931/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2932/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2933/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2934/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2935/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2936/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2937/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2938/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2939/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2940/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2941/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2942/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2943/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2944/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2945/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2946/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2947/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2948/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2949/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2950/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2951/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2952/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2953/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2954/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2955/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2956/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2957/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2958/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2959/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2960/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2961/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2962/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2963/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2964/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2965/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2966/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2967/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2968/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2969/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2970/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2971/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2972/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2973/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2974/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2975/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2976/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2977/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2978/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2979/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2980/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2981/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2982/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2983/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2984/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2985/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2986/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2987/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2988/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2989/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2990/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 22:53:31.587369: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2991/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2992/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2993/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2994/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2995/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2996/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2997/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2998/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 2999/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3000/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3001/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3002/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3003/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3004/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3005/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3006/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3007/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3008/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3009/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3010/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3011/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3012/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3013/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3014/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3015/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3016/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3017/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3018/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3019/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3020/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3021/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3022/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3023/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3024/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3025/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3026/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3027/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3028/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3029/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3030/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3031/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3032/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3033/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3034/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3035/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3036/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3037/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3038/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3039/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3040/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3041/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3042/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3043/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3044/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3045/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3046/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3047/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3048/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3049/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3050/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3051/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3052/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3053/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3054/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3055/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3056/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3057/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3058/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3059/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3060/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3061/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3062/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3063/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3064/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3065/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3066/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3067/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3068/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3069/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3070/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3071/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3072/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3073/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3074/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3075/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3076/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3077/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3078/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3079/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3080/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3081/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3082/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3083/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3084/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3085/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3086/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3087/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3088/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3089/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3090/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3091/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3092/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3093/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3094/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3095/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3096/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3097/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3098/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3099/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3100/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3101/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3102/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3103/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3104/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3105/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3106/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3107/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3108/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3109/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3110/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3111/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3112/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3113/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3114/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3115/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3116/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3117/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3118/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3119/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3120/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3121/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3122/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3123/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3124/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3125/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3126/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3127/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3128/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3129/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3130/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3131/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3132/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3133/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3134/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3135/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3136/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3137/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3138/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3139/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3140/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3141/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3142/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3143/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3144/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3145/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3146/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3147/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3148/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3149/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3150/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3151/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3152/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3153/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3154/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3155/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3156/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3157/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3158/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3159/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3160/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3161/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3162/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3163/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3164/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3165/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3166/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3167/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3168/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3169/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3170/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3171/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3172/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3173/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3174/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3175/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3176/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3177/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3178/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3179/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3180/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3181/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3182/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3183/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3184/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3185/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3186/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3187/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3188/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3189/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3190/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3191/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3192/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3193/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3194/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3195/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3196/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3197/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3198/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3199/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3200/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3201/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3202/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3203/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3204/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3205/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3206/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3207/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3208/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3209/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3210/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3211/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3212/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3213/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3214/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3215/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3216/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3217/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3218/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3219/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3220/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3221/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3222/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3223/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3224/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3225/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3226/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3227/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3228/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3229/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3230/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3231/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3232/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3233/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3234/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3235/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3236/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3237/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3238/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3239/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3240/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3241/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3242/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3243/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3244/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3245/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3246/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3247/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3248/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3249/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3250/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3251/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3252/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3253/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3254/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3255/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3256/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3257/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3258/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3259/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3260/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3261/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3262/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3263/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3264/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3265/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3266/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3267/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3268/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3269/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3270/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3271/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3272/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3273/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3274/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3275/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3276/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3277/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3278/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3279/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3280/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3281/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3282/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3283/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3284/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3285/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3286/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3287/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3288/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3289/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3290/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3291/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3292/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3293/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3294/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3295/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3296/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3297/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3298/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3299/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3300/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3301/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3302/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3303/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3304/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3305/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3306/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3307/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3308/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3309/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3310/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3311/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3312/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3313/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3314/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3315/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3316/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3317/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3318/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3319/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3320/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3321/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3322/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3323/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3324/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3325/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3326/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3327/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3328/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3329/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3330/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3331/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3332/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3333/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3334/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3335/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3336/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3337/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3338/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3339/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3340/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3341/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3342/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3343/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3344/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3345/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3346/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3347/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3348/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3349/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3350/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3351/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3352/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3353/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3354/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3355/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3356/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3357/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3358/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3359/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3360/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3361/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3362/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3363/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3364/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3365/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3366/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3367/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3368/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3369/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3370/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3371/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3372/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3373/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3374/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3375/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3376/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3377/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3378/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3379/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3380/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3381/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3382/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3383/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3384/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3385/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3386/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3387/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3388/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3389/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3390/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3391/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3392/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3393/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3394/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3395/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3396/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3397/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3398/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3399/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3400/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3401/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3402/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3403/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3404/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3405/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3406/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3407/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3408/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3409/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3410/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3411/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3412/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3413/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3414/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3415/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3416/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3417/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3418/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3419/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3420/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3421/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3422/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3423/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3424/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3425/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3426/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3427/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3428/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3429/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3430/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3431/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3432/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3433/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3434/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3435/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3436/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3437/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3438/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3439/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3440/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3441/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3442/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3443/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3444/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3445/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3446/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3447/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3448/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3449/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3450/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3451/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3452/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3453/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3454/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3455/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3456/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3457/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3458/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3459/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3460/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3461/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3462/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3463/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3464/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3465/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3466/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3467/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3468/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3469/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3470/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3471/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3472/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3473/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3474/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3475/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3476/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3477/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3478/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3479/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3480/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3481/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3482/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3483/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3484/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3485/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3486/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3487/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3488/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3489/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3490/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3491/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3492/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3493/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3494/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3495/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3496/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3497/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3498/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3499/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3500/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3501/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3502/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3503/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3504/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3505/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3506/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3507/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3508/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3509/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3510/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3511/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3512/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3513/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3514/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3515/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3516/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3517/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3518/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3519/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3520/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3521/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3522/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3523/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3524/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3525/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3526/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3527/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3528/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3529/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3530/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3531/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3532/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3533/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3534/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3535/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3536/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3537/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3538/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3539/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3540/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3541/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3542/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3543/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3544/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3545/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3546/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3547/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3548/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3549/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3550/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3551/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3552/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3553/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3554/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3555/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3556/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3557/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3558/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3559/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3560/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3561/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3562/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3563/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3564/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3565/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3566/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3567/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3568/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3569/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3570/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3571/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3572/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3573/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3574/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3575/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3576/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3577/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3578/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3579/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3580/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3581/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3582/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3583/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3584/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3585/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3586/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3587/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3588/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3589/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3590/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3591/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3592/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3593/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3594/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3595/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3596/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3597/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3598/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3599/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3600/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3601/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3602/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3603/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3604/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3605/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3606/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3607/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3608/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3609/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3610/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3611/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3612/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3613/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3614/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3615/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3616/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3617/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3618/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3619/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3620/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3621/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3622/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3623/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3624/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3625/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3626/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3627/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3628/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3629/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3630/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3631/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3632/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3633/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3634/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3635/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3636/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3637/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3638/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3639/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3640/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3641/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3642/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3643/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3644/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3645/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3646/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3647/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3648/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3649/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3650/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3651/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3652/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3653/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3654/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3655/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3656/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3657/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3658/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3659/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3660/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3661/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3662/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3663/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3664/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3665/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3666/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3667/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3668/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3669/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3670/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3671/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3672/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3673/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3674/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3675/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3676/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3677/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3678/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3679/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3680/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3681/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3682/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3683/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3684/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3685/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3686/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3687/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3688/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3689/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3690/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3691/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3692/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3693/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3694/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3695/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3696/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3697/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3698/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3699/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3700/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3701/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3702/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3703/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3704/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3705/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3706/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3707/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3708/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3709/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3710/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3711/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3712/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3713/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3714/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3715/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3716/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3717/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3718/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3719/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3720/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3721/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3722/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3723/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3724/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3725/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3726/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3727/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3728/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3729/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3730/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3731/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3732/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3733/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3734/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3735/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3736/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3737/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3738/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3739/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3740/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3741/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3742/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3743/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3744/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3745/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3746/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3747/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3748/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3749/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3750/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3751/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3752/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3753/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3754/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3755/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3756/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3757/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3758/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3759/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3760/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3761/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3762/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3763/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3764/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3765/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3766/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3767/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3768/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3769/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3770/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3771/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3772/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3773/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3774/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3775/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3776/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3777/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3778/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3779/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3780/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3781/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3782/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3783/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3784/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3785/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3786/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3787/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3788/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3789/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3790/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3791/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3792/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3793/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3794/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3795/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3796/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3797/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3798/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3799/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3800/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3801/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3802/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3803/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3804/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3805/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3806/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3807/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3808/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3809/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3810/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3811/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3812/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3813/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3814/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3815/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3816/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3817/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3818/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3819/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3820/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3821/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3822/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3823/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3824/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3825/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3826/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3827/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3828/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3829/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3830/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3831/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3832/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3833/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3834/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3835/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3836/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3837/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3838/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3839/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3840/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3841/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3842/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3843/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3844/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3845/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3846/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3847/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3848/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3849/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3850/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3851/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3852/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3853/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3854/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3855/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3856/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3857/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3858/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3859/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3860/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3861/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3862/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3863/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3864/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3865/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3866/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3867/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3868/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3869/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3870/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3871/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3872/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3873/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3874/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3875/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3876/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3877/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3878/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3879/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3880/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3881/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3882/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3883/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3884/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3885/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3886/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3887/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3888/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3889/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3890/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3891/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3892/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3893/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3894/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3895/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3896/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3897/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3898/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3899/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3900/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3901/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3902/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3903/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3904/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3905/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3906/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3907/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3908/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3909/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3910/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3911/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3912/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3913/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3914/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3915/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3916/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3917/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3918/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3919/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3920/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3921/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3922/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3923/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3924/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3925/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3926/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3927/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3928/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3929/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3930/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3931/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3932/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3933/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3934/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3935/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3936/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3937/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3938/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3939/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3940/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3941/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3942/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3943/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3944/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3945/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3946/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3947/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3948/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3949/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3950/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3951/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3952/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3953/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3954/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3955/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3956/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3957/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3958/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3959/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3960/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3961/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3962/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3963/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3964/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3965/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3966/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3967/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3968/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3969/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3970/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3971/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3972/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3973/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3974/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3975/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3976/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3977/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3978/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3979/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3980/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3981/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3982/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3983/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3984/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3985/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3986/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3987/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3988/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3989/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3990/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3991/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3992/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3993/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3994/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3995/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3996/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3997/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3998/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 3999/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4000/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4001/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4002/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4003/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4004/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4005/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4006/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4007/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4008/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4009/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4010/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4011/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4012/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4013/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4014/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4015/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4016/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4017/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4018/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4019/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4020/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4021/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4022/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4023/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4024/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4025/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4026/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4027/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4028/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4029/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4030/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4031/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4032/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4033/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4034/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4035/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4036/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4037/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4038/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4039/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4040/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4041/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4042/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4043/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4044/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4045/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4046/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4047/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4048/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4049/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4050/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4051/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4052/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4053/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4054/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4055/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4056/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4057/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4058/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4059/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4060/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4061/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4062/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4063/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4064/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4065/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4066/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4067/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4068/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4069/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4070/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4071/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4072/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4073/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4074/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4075/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4076/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4077/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4078/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4079/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4080/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4081/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4082/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4083/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4084/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4085/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4086/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4087/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4088/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4089/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4090/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4091/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4092/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4093/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4094/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4095/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4096/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4097/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4098/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4099/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4100/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4101/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4102/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4103/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4104/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4105/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4106/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4107/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4108/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4109/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4110/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4111/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4112/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4113/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4114/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4115/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4116/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4117/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4118/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4119/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4120/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4121/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4122/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4123/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4124/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4125/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4126/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4127/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4128/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4129/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4130/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4131/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4132/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4133/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4134/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4135/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4136/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4137/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4138/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4139/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4140/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4141/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4142/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4143/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4144/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4145/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4146/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4147/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4148/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4149/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4150/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4151/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4152/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4153/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4154/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4155/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4156/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4157/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4158/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4159/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4160/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4161/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4162/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4163/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4164/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4165/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4166/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4167/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4168/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4169/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4170/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4171/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4172/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4173/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4174/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4175/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4176/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4177/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4178/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4179/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4180/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4181/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4182/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4183/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4184/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4185/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4186/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4187/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4188/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4189/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4190/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4191/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4192/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4193/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4194/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4195/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4196/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4197/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4198/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4199/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4200/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4201/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4202/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4203/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4204/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4205/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4206/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4207/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4208/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4209/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4210/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4211/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4212/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4213/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4214/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4215/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4216/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4217/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4218/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4219/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4220/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4221/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4222/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4223/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4224/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4225/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4226/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4227/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4228/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4229/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4230/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4231/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4232/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4233/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4234/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4235/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4236/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4237/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4238/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4239/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4240/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4241/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4242/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4243/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4244/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4245/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4246/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4247/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4248/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4249/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4250/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4251/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4252/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4253/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4254/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4255/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4256/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4257/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4258/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4259/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4260/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4261/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4262/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4263/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4264/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4265/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4266/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4267/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4268/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4269/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4270/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4271/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4272/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4273/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4274/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4275/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4276/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4277/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4278/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4279/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4280/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4281/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4282/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4283/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4284/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4285/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4286/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4287/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4288/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4289/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4290/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4291/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4292/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4293/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4294/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4295/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4296/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4297/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4298/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4299/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4300/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4301/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4302/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4303/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4304/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4305/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4306/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4307/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4308/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4309/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4310/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4311/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4312/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4313/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4314/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4315/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4316/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4317/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4318/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4319/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4320/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4321/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4322/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4323/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4324/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4325/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4326/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4327/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4328/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4329/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4330/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4331/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4332/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4333/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4334/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4335/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4336/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4337/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4338/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4339/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4340/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4341/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4342/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4343/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4344/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4345/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4346/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4347/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4348/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4349/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4350/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4351/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4352/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4353/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4354/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4355/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4356/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4357/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4358/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4359/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4360/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4361/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4362/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4363/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4364/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4365/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4366/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4367/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4368/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4369/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4370/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4371/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4372/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4373/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4374/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4375/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4376/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4377/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4378/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4379/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4380/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4381/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4382/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4383/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4384/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4385/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4386/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4387/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4388/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4389/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4390/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4391/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4392/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4393/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4394/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4395/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4396/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4397/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4398/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4399/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4400/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4401/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4402/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4403/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4404/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4405/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4406/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4407/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4408/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4409/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4410/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4411/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4412/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4413/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4414/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4415/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4416/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4417/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4418/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4419/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4420/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4421/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4422/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4423/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4424/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4425/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4426/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4427/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4428/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4429/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4430/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4431/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4432/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4433/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4434/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4435/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4436/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4437/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4438/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4439/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4440/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4441/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4442/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4443/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4444/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4445/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4446/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4447/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4448/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4449/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4450/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4451/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4452/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4453/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4454/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4455/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4456/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4457/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4458/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4459/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4460/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4461/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4462/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4463/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4464/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4465/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4466/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4467/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4468/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4469/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4470/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4471/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4472/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4473/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4474/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4475/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4476/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4477/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4478/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4479/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4480/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4481/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4482/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4483/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4484/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4485/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4486/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4487/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4488/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4489/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4490/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4491/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4492/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4493/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4494/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4495/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4496/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4497/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4498/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4499/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4500/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4501/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4502/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4503/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4504/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4505/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4506/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4507/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4508/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4509/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4510/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4511/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4512/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4513/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4514/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4515/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4516/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4517/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4518/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4519/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4520/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4521/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4522/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4523/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4524/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4525/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4526/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4527/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4528/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4529/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4530/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4531/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4532/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4533/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4534/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4535/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4536/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4537/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4538/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4539/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4540/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4541/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4542/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4543/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4544/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4545/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4546/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4547/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4548/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4549/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4550/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4551/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4552/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4553/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4554/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4555/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4556/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4557/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4558/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4559/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4560/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4561/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4562/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4563/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4564/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4565/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4566/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4567/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4568/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4569/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4570/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4571/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4572/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4573/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4574/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4575/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4576/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4577/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4578/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4579/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4580/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4581/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4582/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4583/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4584/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4585/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4586/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4587/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4588/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4589/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4590/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4591/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4592/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4593/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4594/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4595/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4596/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4597/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4598/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4599/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4600/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4601/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4602/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4603/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4604/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4605/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4606/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4607/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4608/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4609/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4610/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4611/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4612/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4613/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4614/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4615/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4616/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4617/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4618/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4619/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4620/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4621/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4622/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4623/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4624/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4625/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4626/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4627/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4628/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4629/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4630/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4631/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4632/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4633/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4634/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4635/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4636/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4637/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4638/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4639/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4640/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4641/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4642/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4643/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4644/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4645/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4646/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4647/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4648/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4649/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4650/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4651/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4652/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4653/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4654/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4655/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4656/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4657/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4658/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4659/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4660/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4661/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4662/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4663/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4664/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4665/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4666/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4667/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4668/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4669/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4670/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4671/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4672/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4673/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4674/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4675/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4676/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4677/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4678/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4679/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4680/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4681/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4682/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4683/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4684/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4685/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4686/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4687/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4688/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4689/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4690/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4691/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4692/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4693/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4694/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4695/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4696/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4697/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4698/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4699/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4700/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4701/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4702/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4703/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4704/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4705/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4706/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4707/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4708/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4709/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4710/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4711/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4712/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4713/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4714/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4715/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4716/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4717/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4718/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4719/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4720/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4721/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4722/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4723/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4724/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4725/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4726/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4727/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4728/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4729/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4730/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4731/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4732/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4733/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4734/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4735/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4736/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4737/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4738/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4739/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4740/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4741/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4742/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4743/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4744/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4745/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4746/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4747/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4748/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4749/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4750/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4751/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4752/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4753/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4754/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4755/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4756/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4757/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4758/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4759/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4760/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4761/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4762/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4763/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4764/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4765/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4766/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4767/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4768/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4769/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4770/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4771/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4772/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4773/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4774/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4775/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4776/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4777/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4778/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4779/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4780/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4781/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4782/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4783/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4784/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4785/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4786/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4787/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4788/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4789/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4790/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4791/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4792/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4793/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4794/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4795/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4796/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4797/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4798/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4799/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4800/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4801/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4802/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4803/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4804/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4805/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4806/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4807/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4808/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4809/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4810/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4811/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4812/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4813/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4814/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4815/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4816/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4817/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4818/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4819/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4820/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4821/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4822/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4823/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4824/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4825/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4826/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4827/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4828/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4829/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4830/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4831/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4832/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4833/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4834/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4835/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4836/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4837/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4838/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4839/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4840/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4841/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4842/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4843/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4844/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4845/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4846/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4847/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4848/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4849/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4850/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4851/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4852/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4853/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4854/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4855/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4856/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4857/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4858/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4859/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4860/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4861/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4862/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4863/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4864/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4865/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4866/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4867/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4868/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4869/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4870/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4871/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4872/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4873/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4874/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4875/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4876/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4877/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4878/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4879/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4880/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4881/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4882/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4883/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4884/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4885/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4886/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4887/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4888/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4889/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4890/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4891/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4892/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4893/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4894/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4895/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4896/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4897/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4898/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4899/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4900/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4901/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4902/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4903/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4904/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4905/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4906/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4907/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4908/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4909/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4910/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4911/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4912/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4913/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4914/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4915/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4916/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4917/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4918/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4919/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4920/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4921/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4922/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4923/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4924/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4925/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4926/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4927/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4928/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4929/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4930/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4931/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4932/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4933/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4934/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4935/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4936/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4937/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4938/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4939/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4940/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4941/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4942/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4943/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4944/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4945/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4946/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4947/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4948/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4949/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4950/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4951/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4952/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4953/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4954/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4955/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4956/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4957/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4958/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4959/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4960/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4961/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4962/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4963/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4964/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4965/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4966/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4967/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4968/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4969/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4970/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4971/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4972/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4973/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4974/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4975/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4976/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4977/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4978/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4979/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4980/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4981/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4982/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4983/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4984/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4985/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4986/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4987/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4988/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4989/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4990/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4991/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4992/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4993/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4994/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4995/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4996/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4997/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4998/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 4999/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n",
      "Epoch 5000/5000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0000e+00 - learning_rate: 7.5000e-05\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to list.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 4) Evaluate\u001b[39;00m\n\u001b[32m     32\u001b[39m val_loss = model.evaluate(val_loader.load(), steps=val_loader.steps_per_epoch, verbose=\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVal MSE: \u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mval_loss\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m.6f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: unsupported format string passed to list.__format__"
     ]
    }
   ],
   "source": [
    "# compute cutoff\n",
    "c_nodes_full, c_edges = compute_cutoffs_any(x_train, pct=99.5, expected_channels=7)\n",
    "c_nodes = c_nodes_full[[0, 1, 2, 4, 6]]   # len = 5\n",
    "\n",
    "# 2) Model + compile (assumes y_train_s exists; otherwise set y_bias=0.0)\n",
    "tf.config.optimizer.set_jit(False)  # avoid sparse/XLA quirks\n",
    "y_bias = float(np.mean(y_train_s)) if 'y_train_s' in locals() else 0.0\n",
    "\n",
    "model = OrbNetModel(\n",
    "    d_h=128, n_e=64, heads=4, L=3, nr=8, mr=8,\n",
    "    c_nodes=c_nodes, c_edges=c_edges,\n",
    "    dropout=0.10, y_bias=y_bias\n",
    ")\n",
    "\n",
    "opt = tf.keras.optimizers.AdamW(learning_rate=3e-4, weight_decay=1e-4, global_clipnorm=1.0)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "# 3) Train (your loaders must already exist)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=80, min_lr=1e-6, verbose=1),\n",
    "]\n",
    "history = model.fit(\n",
    "    train_loader.load(), steps_per_epoch=train_loader.steps_per_epoch,\n",
    "    validation_data=val_loader.load(), validation_steps=val_loader.steps_per_epoch,\n",
    "    epochs=5000, callbacks=callbacks, verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00ba510a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "64a64017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 7, 48, 48) (99,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape, y_test_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "beee94a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step - loss: 0.0107\n",
      "Test MSE loss: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss = model.evaluate(test_loader.load(), steps=test_loader.steps_per_epoch)\n",
    "print(f\"Test MSE loss: {test_loss:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "01e2d8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 176ms/step\n",
      "y_pred shape: (99,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CRITICAL: **Re‐instantiate** the loader for prediction\n",
    "pred_loader = DisjointLoader(test_dataset, batch_size=32, epochs=1, shuffle=False)\n",
    "y_pred = model.predict(pred_loader.load(), steps=pred_loader.steps_per_epoch).flatten()\n",
    "y_pred   = (y_pred * y_sd) + y_mu\n",
    "\n",
    "# 3) Now y_pred.shape == y_true.shape == 99\n",
    "print(\"y_pred shape:\", y_pred.shape)\n",
    "\n",
    "# 4) Plot\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "mn, mx = y_test.min(), y_test.max()\n",
    "plt.plot([mn, mx], [mn, mx], 'r--')\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Predicted vs True on Test Set\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7e0f5e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 9.139520e+02\n",
      "R²:  -1.6578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# y_true and y_pred should be 1D NumPy arrays (e.g., from your test set)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print(f\"MSE: {mse:.6e}\")\n",
    "print(f\"MAE: {mae:.6e}\")\n",
    "print(f\"R²:  {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0327e016",
   "metadata": {},
   "source": [
    "### Save / load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3b35b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path('./gnn_model/')\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model.save(model_dir / 'met_gnn_model_orbnet_5_577e1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8a3db0ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[97]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmet_gnn_model_orbnet_5_577e1.keras\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOrbNetModel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mOrbNetModel\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# safe even with @register\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/base-ml/lib/python3.12/site-packages/keras/src/saving/saving_api.py:189\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    186\u001b[39m         is_keras_zip = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir \u001b[38;5;129;01mor\u001b[39;00m is_hf:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith((\u001b[33m\"\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.hdf5\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format.load_model_from_hdf5(\n\u001b[32m    197\u001b[39m         filepath, custom_objects=custom_objects, \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m\n\u001b[32m    198\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/base-ml/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:365\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    361\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    363\u001b[39m     )\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_fileobj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/base-ml/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:442\u001b[39m, in \u001b[36m_load_model_from_fileobj\u001b[39m\u001b[34m(fileobj, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m zf.open(_CONFIG_FILENAME, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    440\u001b[39m     config_json = f.read()\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m model = \u001b[43m_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m all_filenames = zf.namelist()\n\u001b[32m    447\u001b[39m extract_dir = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/base-ml/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:431\u001b[39m, in \u001b[36m_model_from_config\u001b[39m\u001b[34m(config_json, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m     model = \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/base-ml/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:733\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(config, custom_objects, safe_mode, **kwargs)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[32m    732\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m         instance = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    735\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    736\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m could not be deserialized properly. Please\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    737\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m ensure that components that are Python object\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    741\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    742\u001b[39m         )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 209\u001b[39m, in \u001b[36mOrbNetModel.from_config\u001b[39m\u001b[34m(cls, config)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_config\u001b[39m(\u001b[38;5;28mcls\u001b[39m, config):\n\u001b[32m    208\u001b[39m     \u001b[38;5;66;03m# Keras may pass trainable/dtype/name in `base`; they’re handled by super().__init__(**kwargs)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 158\u001b[39m, in \u001b[36mOrbNetModel.__init__\u001b[39m\u001b[34m(self, d_h, n_e, heads, L, nr, mr, c_nodes, c_edges, dropout, y_bias, **kwargs)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28mself\u001b[39m.y_bias_init = \u001b[38;5;28mfloat\u001b[39m(y_bias)\n\u001b[32m    157\u001b[39m \u001b[38;5;66;03m# embeddings (custom layers must be serializable/registered, see note below)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;28mself\u001b[39m.node_rbf = \u001b[43mNodeSineRBF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28mself\u001b[39m.edge_rbf = EdgeBesselRBF(mr, c_edges)\n\u001b[32m    160\u001b[39m \u001b[38;5;28mself\u001b[39m.Ench = ResidualMLP3(d_h, dropout)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mNodeSineRBF.__init__\u001b[39m\u001b[34m(self, nr, c_nodes)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m     50\u001b[39m \u001b[38;5;28mself\u001b[39m.nr = \u001b[38;5;28mint\u001b[39m(nr)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28mself\u001b[39m.c_nodes = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28mself\u001b[39m.d_node = \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m.c_nodes.shape[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/base-ml/lib/python3.12/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[39m, in \u001b[36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    141\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m    144\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/base-ml/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[39m, in \u001b[36mconstant\u001b[39m\u001b[34m(value, dtype, shape, name)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mconstant\u001b[39m\u001b[33m\"\u001b[39m, v1=[])\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconstant\u001b[39m(\n\u001b[32m    179\u001b[39m     value, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, shape=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[33m\"\u001b[39m\u001b[33mConst\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m ) -> Union[ops.Operation, ops._EagerTensorBase]:\n\u001b[32m    181\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[32m    182\u001b[39m \n\u001b[32m    183\u001b[39m \u001b[33;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m \u001b[33;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/base-ml/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[39m, in \u001b[36m_constant_impl\u001b[39m\u001b[34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[39m\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m trace.Trace(\u001b[33m\"\u001b[39m\u001b[33mtf.constant\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    288\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m const_tensor = ops._create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    292\u001b[39m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[32m    293\u001b[39m )\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/base-ml/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[39m, in \u001b[36m_constant_eager_impl\u001b[39m\u001b[34m(ctx, value, dtype, shape, verify_shape)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_constant_eager_impl\u001b[39m(\n\u001b[32m    298\u001b[39m     ctx, value, dtype, shape, verify_shape\n\u001b[32m    299\u001b[39m ) -> ops._EagerTensorBase:\n\u001b[32m    300\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m   t = \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/base-ml/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[39m, in \u001b[36mconvert_to_eager_tensor\u001b[39m\u001b[34m(value, ctx, dtype)\u001b[39m\n\u001b[32m    106\u001b[39m     dtype = dtypes.as_dtype(dtype).as_datatype_enum\n\u001b[32m    107\u001b[39m ctx.ensure_initialized()\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\n",
    "    str(model_dir / 'met_gnn_model_orbnet_5_577e1.keras'),\n",
    "    custom_objects={\"OrbNetModel\": OrbNetModel},  # safe even with @register\n",
    "    compile=False,\n",
    "    safe_mode=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3bfc2c",
   "metadata": {},
   "source": [
    "## Test on translational invariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2f4bada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on: CNN, GNN. We have x_test, y_test\n",
    "from numpy.random import default_rng\n",
    "\n",
    "def translation(X, offset=10.0):\n",
    "    '''\n",
    "    Offset: a (3,) vector (tuple) or a scaler. \n",
    "    '''\n",
    "    off = np.asarray(offset)\n",
    "    if off.ndim == 0:\n",
    "        off = np.array([off, off, off])\n",
    "    return X + off  # broadcasting: (N,n_atoms,3) + (3,) → (N,n_atoms,3)\n",
    "\n",
    "def rotate_180_y_axis(X):\n",
    "    R = np.array([[-1, 0, 0],\n",
    "              [ 0, 1, 0],\n",
    "              [ 0, 0,-1]])\n",
    "    return X @ R.T\n",
    "\n",
    "def permutation(X, seed=None):\n",
    "    N, n_atoms, xyz = X.shape\n",
    "    rng = default_rng(seed)          # create a Generator with seed 42\n",
    "    perm = rng.permutation(n_atoms)\n",
    "    return X[:, perm, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80251d22",
   "metadata": {},
   "source": [
    "Step 1: save test dataset's energies and xyz coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "520ec029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99, 7, 24, 24), (99,), (99, 6, 3))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape, c_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "373c5410",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'./test_xyz_{molecule}.npy', c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e26c7199",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_t = np.load('./features/test_matrices_h2o_permutated.npy')\n",
    "y_test_s = y_test_s\n",
    "# c_test =np.load('./test_xyz_h2o_permutated.npy')permutated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4511eb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 7, 48, 48) (99,) (99, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape, y_test.shape, c_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1c4f45da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "y_pred shape: (99,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CRITICAL: **Re‐instantiate** the loader for prediction\n",
    "test_dataset_2 = SCFAtomGraphDataset(X=x_test_t, Y=y_test_s, tau=1e-4)\n",
    "pred_loader = DisjointLoader(test_dataset_2, batch_size=32, epochs=1, shuffle=False)\n",
    "y_pred = model.predict(pred_loader.load(), steps=pred_loader.steps_per_epoch).flatten()\n",
    "y_pred   = (y_pred * y_sd) + y_mu\n",
    "\n",
    "# 3) Now y_pred.shape == y_true.shape == 99\n",
    "print(\"y_pred shape:\", y_pred.shape)\n",
    "\n",
    "# 4) Plot\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "mn, mx = y_test.min(), y_test.max()\n",
    "plt.plot([mn, mx], [mn, mx], 'r--')\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Predicted vs True on Test Set\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "30f0372d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 9.139520e+02\n",
      "R²:  -1.6578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# y_true and y_pred should be 1D NumPy arrays (e.g., from your test set)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print(f\"MSE: {mse:.6e}\")\n",
    "print(f\"MAE: {mae:.6e}\")\n",
    "print(f\"R²:  {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
